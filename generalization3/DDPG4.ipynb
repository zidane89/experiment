{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "\n",
    "from vehicle_model_DDPG4 import Environment \n",
    "from cell_model import CellModel \n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_nimh_6_240_panasonic_MY01_Prius.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_pm_95_145_X2.mat\"\n",
    "cell_model = CellModel()\n",
    "env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):      \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    inputs_batchnorm = layers.BatchNormalization()(inputs)\n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs_batchnorm)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_input_batchnorm = layers.BatchNormalization()(state_input)\n",
    "    \n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input_batchnorm)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 500\n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 10000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "\n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_model, critic_model, target_actor, target_critic, root): \n",
    "    actor_model.save_weights(\"./{}/actor_model_checkpoint\".format(root))\n",
    "    critic_model.save_weights(\"./{}/critic_model_checkpoint\".format(root))\n",
    "    target_actor.save_weights(\"./{}/target_actor_checkpoint\".format(root))\n",
    "    target_critic.save_weights(\"./{}/target_critic_checkpoint\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_env(driving_path, reward_factor):\n",
    "    env = Environment(cell_model, driving_path, battery_path, motor_path, reward_factor)\n",
    "    return env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "Trial 0\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 15.673\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -1015.5785012252499 SOC: 0.6618 Cumulative_SOC_deviation: 96.7532 Fuel Consumption: 48.0468\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 18.399\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -2742.2959722705045 SOC: 1.0000 Cumulative_SOC_deviation: 269.4660 Fuel Consumption: 47.6356\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 15.518\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -1054.7722689533127 SOC: 0.6683 Cumulative_SOC_deviation: 100.6446 Fuel Consumption: 48.3260\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 7.854\n",
      "Episode: 4 Exploration P: 1.0000 Total reward: -1722.4400874180324 SOC: 0.0710 Cumulative_SOC_deviation: 169.8374 Fuel Consumption: 24.0665\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 16.525\n",
      "Episode: 5 Exploration P: 1.0000 Total reward: -2792.1612284936045 SOC: 1.0000 Cumulative_SOC_deviation: 274.3418 Fuel Consumption: 48.7430\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 7.991\n",
      "Episode: 6 Exploration P: 1.0000 Total reward: -1692.559606850665 SOC: 0.0872 Cumulative_SOC_deviation: 166.7617 Fuel Consumption: 24.9427\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 17.250\n",
      "Episode: 7 Exploration P: 1.0000 Total reward: -2820.4809395384423 SOC: 1.0000 Cumulative_SOC_deviation: 277.0428 Fuel Consumption: 50.0525\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 30.243\n",
      "Episode: 8 Exploration P: 1.0000 Total reward: -2130.5835954171052 SOC: 0.7711 Cumulative_SOC_deviation: 204.5642 Fuel Consumption: 84.9420\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 15.793\n",
      "Episode: 9 Exploration P: 1.0000 Total reward: -2762.2103532803303 SOC: 1.0000 Cumulative_SOC_deviation: 271.3217 Fuel Consumption: 48.9933\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "WARNING:tensorflow:Layer batch_normalization_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 56.263\n",
      "Episode: 10 Exploration P: 0.9896 Total reward: -2737.791630218962 SOC: 1.0000 Cumulative_SOC_deviation: 268.8875 Fuel Consumption: 48.9163\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 185.188\n",
      "Episode: 11 Exploration P: 0.9535 Total reward: -1852.232135562417 SOC: 0.7309 Cumulative_SOC_deviation: 177.0314 Fuel Consumption: 81.9185\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.624\n",
      "Episode: 12 Exploration P: 0.9337 Total reward: -982.6291785777513 SOC: 0.6339 Cumulative_SOC_deviation: 93.6633 Fuel Consumption: 45.9958\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.810\n",
      "Episode: 13 Exploration P: 0.9143 Total reward: -1040.839925289945 SOC: 0.6126 Cumulative_SOC_deviation: 99.6404 Fuel Consumption: 44.4359\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 165.687\n",
      "Episode: 14 Exploration P: 0.8810 Total reward: -1333.9288992074607 SOC: 0.6449 Cumulative_SOC_deviation: 125.8211 Fuel Consumption: 75.7175\n",
      "\n",
      "training\\cudec_freeway.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment\\generalization3\\vehicle_model_DDPG4.py:251: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n",
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment\\generalization3\\vehicle_model_DDPG4.py:277: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOC is nan...\n",
      "elapsed_time: 22.512\n",
      "Episode: 15 Exploration P: 0.8766 Total reward: -1366.8036974516763 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 9.9557\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.923\n",
      "Episode: 16 Exploration P: 0.8584 Total reward: -1024.8244509799333 SOC: 0.5853 Cumulative_SOC_deviation: 98.2372 Fuel Consumption: 42.4524\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 138.268\n",
      "Episode: 17 Exploration P: 0.8354 Total reward: -916.7419048796183 SOC: 0.7028 Cumulative_SOC_deviation: 86.3962 Fuel Consumption: 52.7798\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.844\n",
      "Episode: 18 Exploration P: 0.8176 Total reward: -2271.0552706611593 SOC: 1.0000 Cumulative_SOC_deviation: 223.0385 Fuel Consumption: 40.6700\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.609\n",
      "Episode: 19 Exploration P: 0.8002 Total reward: -2129.529117834643 SOC: 0.9800 Cumulative_SOC_deviation: 209.2128 Fuel Consumption: 37.4010\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 162.952\n",
      "Episode: 20 Exploration P: 0.7711 Total reward: -1610.343513946356 SOC: 0.6758 Cumulative_SOC_deviation: 153.2450 Fuel Consumption: 77.8940\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 42.946\n",
      "Episode: 21 Exploration P: 0.7629 Total reward: -1558.5704695493068 SOC: 0.1486 Cumulative_SOC_deviation: 152.9677 Fuel Consumption: 28.8939\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.195\n",
      "Episode: 22 Exploration P: 0.7467 Total reward: -2141.7715789707668 SOC: 1.0000 Cumulative_SOC_deviation: 210.1977 Fuel Consumption: 39.7944\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 187.147\n",
      "Episode: 23 Exploration P: 0.7196 Total reward: -1327.8595995159776 SOC: 0.5444 Cumulative_SOC_deviation: 125.9384 Fuel Consumption: 68.4757\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 184.273\n",
      "Episode: 24 Exploration P: 0.6934 Total reward: -1183.504729000127 SOC: 0.5408 Cumulative_SOC_deviation: 111.5679 Fuel Consumption: 67.8261\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.405\n",
      "Episode: 25 Exploration P: 0.6787 Total reward: -2181.654500669031 SOC: 0.9910 Cumulative_SOC_deviation: 214.3275 Fuel Consumption: 38.3794\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.223\n",
      "Episode: 26 Exploration P: 0.6647 Total reward: -1168.4198182783164 SOC: 0.4756 Cumulative_SOC_deviation: 113.3432 Fuel Consumption: 34.9881\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 123.431\n",
      "Episode: 27 Exploration P: 0.6469 Total reward: -951.6418830292713 SOC: 0.6223 Cumulative_SOC_deviation: 90.4737 Fuel Consumption: 46.9046\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.789\n",
      "Episode: 28 Exploration P: 0.6437 Total reward: -1401.3454295601996 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 9.2940\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 146.457\n",
      "Episode: 29 Exploration P: 0.6204 Total reward: -1018.2997017010564 SOC: 0.5239 Cumulative_SOC_deviation: 95.2152 Fuel Consumption: 66.1476\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 42.214\n",
      "Episode: 30 Exploration P: 0.6138 Total reward: -1706.9976911236342 SOC: 0.0858 Cumulative_SOC_deviation: 168.2083 Fuel Consumption: 24.9146\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 146.419\n",
      "Episode: 31 Exploration P: 0.5916 Total reward: -1217.2805246801647 SOC: 0.5183 Cumulative_SOC_deviation: 115.1269 Fuel Consumption: 66.0116\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 146.388\n",
      "Episode: 32 Exploration P: 0.5702 Total reward: -1117.7261956689124 SOC: 0.5686 Cumulative_SOC_deviation: 104.8445 Fuel Consumption: 69.2808\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 42.675\n",
      "Episode: 33 Exploration P: 0.5641 Total reward: -1876.2110139677498 SOC: 0.0258 Cumulative_SOC_deviation: 185.5041 Fuel Consumption: 21.1696\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 146.694\n",
      "Episode: 34 Exploration P: 0.5437 Total reward: -1445.0639066728195 SOC: 0.4432 Cumulative_SOC_deviation: 138.4288 Fuel Consumption: 60.7760\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.665\n",
      "Episode: 35 Exploration P: 0.5325 Total reward: -1233.1878715199866 SOC: 0.4227 Cumulative_SOC_deviation: 120.2150 Fuel Consumption: 31.0378\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 146.952\n",
      "Episode: 36 Exploration P: 0.5133 Total reward: -1341.1384104995857 SOC: 0.4588 Cumulative_SOC_deviation: 127.8994 Fuel Consumption: 62.1443\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.203\n",
      "Episode: 37 Exploration P: 0.5027 Total reward: -1293.3376673015182 SOC: 0.3960 Cumulative_SOC_deviation: 126.3989 Fuel Consumption: 29.3487\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.053\n",
      "Episode: 38 Exploration P: 0.4924 Total reward: -1345.3276626336171 SOC: 0.3557 Cumulative_SOC_deviation: 131.9198 Fuel Consumption: 26.1294\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 20.113\n",
      "Episode: 39 Exploration P: 0.4899 Total reward: -1400.0267791380477 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 8.2341\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 148.346\n",
      "Episode: 40 Exploration P: 0.4723 Total reward: -1742.6160172616703 SOC: 0.3983 Cumulative_SOC_deviation: 168.4069 Fuel Consumption: 58.5466\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.910\n",
      "Episode: 41 Exploration P: 0.4597 Total reward: -2033.972232403983 SOC: 0.4945 Cumulative_SOC_deviation: 199.6374 Fuel Consumption: 37.5987\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.132\n",
      "Episode: 42 Exploration P: 0.4503 Total reward: -1366.0835247652192 SOC: 0.3612 Cumulative_SOC_deviation: 133.9033 Fuel Consumption: 27.0507\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.627\n",
      "Episode: 43 Exploration P: 0.4408 Total reward: -1029.056749371569 SOC: 0.7763 Cumulative_SOC_deviation: 100.7265 Fuel Consumption: 21.7921\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.604\n",
      "Episode: 44 Exploration P: 0.4318 Total reward: -1494.9284966338314 SOC: 0.3099 Cumulative_SOC_deviation: 147.1502 Fuel Consumption: 23.4269\n",
      "\n",
      "training\\cudec_freeway.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment\\generalization3\\vehicle_model_DDPG4.py:252: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  2 * r_dis)) * (v_dis - (v_dis ** 2 - 4 * r_dis * p_bat) ** (0.5)) * (p_bat >= 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOC is nan...\n",
      "elapsed_time: 19.957\n",
      "Episode: 45 Exploration P: 0.4296 Total reward: -1445.3502760682868 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 7.0684\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.192\n",
      "Episode: 46 Exploration P: 0.4208 Total reward: -1439.811139527521 SOC: 0.3108 Cumulative_SOC_deviation: 141.6436 Fuel Consumption: 23.3752\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 147.543\n",
      "Episode: 47 Exploration P: 0.4057 Total reward: -3209.0427699319025 SOC: 0.3525 Cumulative_SOC_deviation: 315.4838 Fuel Consumption: 54.2052\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.604\n",
      "Episode: 48 Exploration P: 0.3971 Total reward: -753.6492355788733 SOC: 0.7401 Cumulative_SOC_deviation: 73.4611 Fuel Consumption: 19.0380\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 42.788\n",
      "Episode: 49 Exploration P: 0.3930 Total reward: -1688.674990890636 SOC: 0.0604 Cumulative_SOC_deviation: 166.6093 Fuel Consumption: 22.5815\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 42.742\n",
      "Episode: 50 Exploration P: 0.3888 Total reward: -1865.9574885468528 SOC: 0.0469 Cumulative_SOC_deviation: 184.3969 Fuel Consumption: 21.9887\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.048\n",
      "Episode: 51 Exploration P: 0.3848 Total reward: -1619.7524257053906 SOC: 0.1238 Cumulative_SOC_deviation: 159.2559 Fuel Consumption: 27.1933\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.245\n",
      "Episode: 52 Exploration P: 0.3769 Total reward: -1102.867292996241 SOC: 0.4038 Cumulative_SOC_deviation: 107.4395 Fuel Consumption: 28.4727\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 42.907\n",
      "Episode: 53 Exploration P: 0.3729 Total reward: -1966.0442506477505 SOC: -0.0396 Cumulative_SOC_deviation: 194.8846 Fuel Consumption: 17.1985\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 20.016\n",
      "Episode: 54 Exploration P: 0.3711 Total reward: -1424.9907189609733 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 8.6849\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.296\n",
      "Episode: 55 Exploration P: 0.3635 Total reward: -937.7150761170585 SOC: 0.4890 Cumulative_SOC_deviation: 90.2853 Fuel Consumption: 34.8625\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.760\n",
      "Episode: 56 Exploration P: 0.3559 Total reward: -645.756438804538 SOC: 0.7156 Cumulative_SOC_deviation: 62.8643 Fuel Consumption: 17.1130\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.564\n",
      "Episode: 57 Exploration P: 0.3522 Total reward: -1699.6334669145683 SOC: 0.1671 Cumulative_SOC_deviation: 166.9286 Fuel Consumption: 30.3476\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 147.907\n",
      "Episode: 58 Exploration P: 0.3396 Total reward: -1158.2776159156817 SOC: 0.5314 Cumulative_SOC_deviation: 109.0189 Fuel Consumption: 68.0881\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 147.673\n",
      "Episode: 59 Exploration P: 0.3274 Total reward: -3448.1363772627064 SOC: 0.3919 Cumulative_SOC_deviation: 339.0990 Fuel Consumption: 57.1468\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 148.161\n",
      "Episode: 60 Exploration P: 0.3157 Total reward: -1176.1302970015595 SOC: 0.5068 Cumulative_SOC_deviation: 111.1405 Fuel Consumption: 64.7252\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.113\n",
      "Episode: 61 Exploration P: 0.3092 Total reward: -543.8909958674388 SOC: 0.6875 Cumulative_SOC_deviation: 52.8801 Fuel Consumption: 15.0901\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.514\n",
      "Episode: 62 Exploration P: 0.3011 Total reward: -3217.8202584379283 SOC: 0.3004 Cumulative_SOC_deviation: 319.3784 Fuel Consumption: 24.0361\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 147.869\n",
      "Episode: 63 Exploration P: 0.2903 Total reward: -1309.1483338761807 SOC: 0.5134 Cumulative_SOC_deviation: 124.3463 Fuel Consumption: 65.6849\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.119\n",
      "Episode: 64 Exploration P: 0.2827 Total reward: -1009.216844790381 SOC: 0.5705 Cumulative_SOC_deviation: 96.7224 Fuel Consumption: 41.9932\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.525\n",
      "Episode: 65 Exploration P: 0.2769 Total reward: -381.3806898702828 SOC: 0.6645 Cumulative_SOC_deviation: 36.7966 Fuel Consumption: 13.4147\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 147.928\n",
      "Episode: 66 Exploration P: 0.2670 Total reward: -1372.2537142120636 SOC: 0.4696 Cumulative_SOC_deviation: 131.0079 Fuel Consumption: 62.1746\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.233\n",
      "Episode: 67 Exploration P: 0.2587 Total reward: -5128.1383753688615 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 26.3938\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 148.539\n",
      "Episode: 68 Exploration P: 0.2496 Total reward: -2392.2706314393026 SOC: 0.4913 Cumulative_SOC_deviation: 232.6502 Fuel Consumption: 65.7682\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.393\n",
      "Episode: 69 Exploration P: 0.2444 Total reward: -272.5052010425208 SOC: 0.6605 Cumulative_SOC_deviation: 25.9447 Fuel Consumption: 13.0584\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 42.855\n",
      "Episode: 70 Exploration P: 0.2419 Total reward: -1730.4241109577408 SOC: 0.0072 Cumulative_SOC_deviation: 171.0559 Fuel Consumption: 19.8654\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 148.870\n",
      "Episode: 71 Exploration P: 0.2333 Total reward: -1747.123915345881 SOC: 0.3100 Cumulative_SOC_deviation: 169.5273 Fuel Consumption: 51.8506\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.975\n",
      "Episode: 72 Exploration P: 0.2286 Total reward: -610.4425712979935 SOC: 0.6106 Cumulative_SOC_deviation: 56.5738 Fuel Consumption: 44.7043\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.303\n",
      "Episode: 73 Exploration P: 0.2241 Total reward: -569.310371275702 SOC: 0.6037 Cumulative_SOC_deviation: 52.5876 Fuel Consumption: 43.4347\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 148.555\n",
      "Episode: 74 Exploration P: 0.2162 Total reward: -683.1203628540018 SOC: 0.5160 Cumulative_SOC_deviation: 61.7678 Fuel Consumption: 65.4421\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.163\n",
      "Episode: 75 Exploration P: 0.2140 Total reward: -1691.7059973682901 SOC: 0.1737 Cumulative_SOC_deviation: 166.1095 Fuel Consumption: 30.6109\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.795\n",
      "Episode: 76 Exploration P: 0.2097 Total reward: -848.7675745285916 SOC: 0.5462 Cumulative_SOC_deviation: 80.8865 Fuel Consumption: 39.9027\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.611\n",
      "Episode: 77 Exploration P: 0.2054 Total reward: -127.69078750679509 SOC: 0.6186 Cumulative_SOC_deviation: 11.7733 Fuel Consumption: 9.9579\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.558\n",
      "Episode: 78 Exploration P: 0.2013 Total reward: -690.696332540204 SOC: 0.5888 Cumulative_SOC_deviation: 64.7753 Fuel Consumption: 42.9433\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.056\n",
      "Episode: 79 Exploration P: 0.1992 Total reward: -1205.4071805337674 SOC: 0.3163 Cumulative_SOC_deviation: 116.5327 Fuel Consumption: 40.0803\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 148.990\n",
      "Episode: 80 Exploration P: 0.1922 Total reward: -925.5706534148586 SOC: 0.4703 Cumulative_SOC_deviation: 86.2219 Fuel Consumption: 63.3519\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 148.974\n",
      "Episode: 81 Exploration P: 0.1855 Total reward: -3077.6671036487896 SOC: 0.5449 Cumulative_SOC_deviation: 300.6759 Fuel Consumption: 70.9086\n",
      "\n",
      "training\\FTP_75_cycle.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 148.447\n",
      "Episode: 82 Exploration P: 0.1791 Total reward: -843.7136308527839 SOC: 0.5779 Cumulative_SOC_deviation: 77.2859 Fuel Consumption: 70.8548\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.552\n",
      "Episode: 83 Exploration P: 0.1755 Total reward: -2084.5580762095437 SOC: 0.1122 Cumulative_SOC_deviation: 207.3911 Fuel Consumption: 10.6473\n",
      "\n",
      "training\\cudec_freeway.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment\\generalization3\\vehicle_model_DDPG4.py:278: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  2 * r_dis)) * (v_dis - (v_dis ** 2 - 4 * r_dis * p_bat) ** (0.5)) * (p_bat >= 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOC is nan...\n",
      "elapsed_time: 20.296\n",
      "Episode: 84 Exploration P: 0.1747 Total reward: -1503.39242209794 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 3.3188\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 20.174\n",
      "Episode: 85 Exploration P: 0.1738 Total reward: -1503.5370932444462 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 3.1192\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.410\n",
      "Episode: 86 Exploration P: 0.1703 Total reward: -68.74625235705754 SOC: 0.6124 Cumulative_SOC_deviation: 5.9250 Fuel Consumption: 9.4958\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.178\n",
      "Episode: 87 Exploration P: 0.1669 Total reward: -68.16176068757936 SOC: 0.6074 Cumulative_SOC_deviation: 5.9070 Fuel Consumption: 9.0913\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 124.180\n",
      "Episode: 88 Exploration P: 0.1620 Total reward: -6487.864148745761 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 13.7421\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.681\n",
      "Episode: 89 Exploration P: 0.1579 Total reward: -4573.612292000765 SOC: 0.1118 Cumulative_SOC_deviation: 456.2208 Fuel Consumption: 11.4046\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.010\n",
      "Episode: 90 Exploration P: 0.1548 Total reward: -2207.7895187937506 SOC: 0.0742 Cumulative_SOC_deviation: 219.9497 Fuel Consumption: 8.2924\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.697\n",
      "Episode: 91 Exploration P: 0.1517 Total reward: -106.97541920460377 SOC: 0.5820 Cumulative_SOC_deviation: 9.9781 Fuel Consumption: 7.1945\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.912\n",
      "Episode: 92 Exploration P: 0.1478 Total reward: -2554.136858161762 SOC: 0.3943 Cumulative_SOC_deviation: 252.3393 Fuel Consumption: 30.7439\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 131.426\n",
      "Episode: 93 Exploration P: 0.1434 Total reward: -5052.423140800287 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 27.9646\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.084\n",
      "Episode: 94 Exploration P: 0.1398 Total reward: -4308.057534342847 SOC: 0.2434 Cumulative_SOC_deviation: 428.8057 Fuel Consumption: 20.0005\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.953\n",
      "Episode: 95 Exploration P: 0.1356 Total reward: -3861.93536185442 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 28.8618\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.081\n",
      "Episode: 96 Exploration P: 0.1329 Total reward: -2313.48117226285 SOC: 0.0595 Cumulative_SOC_deviation: 230.6122 Fuel Consumption: 7.3593\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 20.440\n",
      "Episode: 97 Exploration P: 0.1323 Total reward: -1511.7861749625984 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.3146\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 20.458\n",
      "Episode: 98 Exploration P: 0.1317 Total reward: -1518.7043842776757 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.2097\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 124.498\n",
      "Episode: 99 Exploration P: 0.1279 Total reward: -6528.727191863362 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 19.2035\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 20.083\n",
      "Episode: 100 Exploration P: 0.1273 Total reward: -1516.7340037686904 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 4.7820\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 123.898\n",
      "Episode: 101 Exploration P: 0.1237 Total reward: -5642.973658075492 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 16.5548\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 42.888\n",
      "Episode: 102 Exploration P: 0.1225 Total reward: -1526.3127994234244 SOC: 0.2327 Cumulative_SOC_deviation: 149.1724 Fuel Consumption: 34.5885\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.630\n",
      "Episode: 103 Exploration P: 0.1201 Total reward: -109.4179165015442 SOC: 0.5832 Cumulative_SOC_deviation: 10.2127 Fuel Consumption: 7.2907\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.106\n",
      "Episode: 104 Exploration P: 0.1178 Total reward: -1357.2956848588813 SOC: 0.4646 Cumulative_SOC_deviation: 132.3272 Fuel Consumption: 34.0233\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.294\n",
      "Episode: 105 Exploration P: 0.1154 Total reward: -111.91000335049732 SOC: 0.5858 Cumulative_SOC_deviation: 10.4427 Fuel Consumption: 7.4833\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 149.302\n",
      "Episode: 106 Exploration P: 0.1116 Total reward: -2324.1312528530093 SOC: 0.4060 Cumulative_SOC_deviation: 226.5968 Fuel Consumption: 58.1630\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.010\n",
      "Episode: 107 Exploration P: 0.1105 Total reward: -1874.2018261969356 SOC: 0.0199 Cumulative_SOC_deviation: 185.4123 Fuel Consumption: 20.0786\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 42.921\n",
      "Episode: 108 Exploration P: 0.1094 Total reward: -1228.8273147742702 SOC: 0.2846 Cumulative_SOC_deviation: 119.1404 Fuel Consumption: 37.4233\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.296\n",
      "Episode: 109 Exploration P: 0.1083 Total reward: -1687.7977155659166 SOC: 0.1691 Cumulative_SOC_deviation: 165.8130 Fuel Consumption: 29.6677\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.771\n",
      "Episode: 110 Exploration P: 0.1062 Total reward: -147.75882875224252 SOC: 0.5849 Cumulative_SOC_deviation: 14.0448 Fuel Consumption: 7.3111\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 149.269\n",
      "Episode: 111 Exploration P: 0.1026 Total reward: -1067.2292603747521 SOC: 0.5438 Cumulative_SOC_deviation: 99.8425 Fuel Consumption: 68.8042\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.970\n",
      "Episode: 112 Exploration P: 0.1007 Total reward: -787.8005859115207 SOC: 0.5318 Cumulative_SOC_deviation: 74.9412 Fuel Consumption: 38.3881\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 149.639\n",
      "Episode: 113 Exploration P: 0.0974 Total reward: -816.5943922648021 SOC: 0.5820 Cumulative_SOC_deviation: 74.3444 Fuel Consumption: 73.1501\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.622\n",
      "Episode: 114 Exploration P: 0.0955 Total reward: -219.42812955470842 SOC: 0.6062 Cumulative_SOC_deviation: 21.0165 Fuel Consumption: 9.2628\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.425\n",
      "Episode: 115 Exploration P: 0.0946 Total reward: -1593.6302651449262 SOC: 0.1543 Cumulative_SOC_deviation: 156.4719 Fuel Consumption: 28.9108\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.683\n",
      "Episode: 116 Exploration P: 0.0923 Total reward: -634.8917017639556 SOC: 0.5755 Cumulative_SOC_deviation: 59.0258 Fuel Consumption: 44.6332\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.712\n",
      "Episode: 117 Exploration P: 0.0905 Total reward: -131.54650332808643 SOC: 0.6260 Cumulative_SOC_deviation: 12.0598 Fuel Consumption: 10.9484\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 150.022\n",
      "Episode: 118 Exploration P: 0.0875 Total reward: -862.1509349300136 SOC: 0.6115 Cumulative_SOC_deviation: 78.6677 Fuel Consumption: 75.4736\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.032\n",
      "Episode: 119 Exploration P: 0.0859 Total reward: -150.3769307772014 SOC: 0.6150 Cumulative_SOC_deviation: 14.0790 Fuel Consumption: 9.5870\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.227\n",
      "Episode: 120 Exploration P: 0.0838 Total reward: -362.6672672774314 SOC: 0.6173 Cumulative_SOC_deviation: 31.6693 Fuel Consumption: 45.9746\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.393\n",
      "Episode: 121 Exploration P: 0.0818 Total reward: -412.8963811257326 SOC: 0.6191 Cumulative_SOC_deviation: 36.5948 Fuel Consumption: 46.9487\n",
      "\n",
      "training\\FTP_75_cycle.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 149.156\n",
      "Episode: 122 Exploration P: 0.0792 Total reward: -572.7546041262812 SOC: 0.6002 Cumulative_SOC_deviation: 49.9742 Fuel Consumption: 73.0124\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.513\n",
      "Episode: 123 Exploration P: 0.0773 Total reward: -365.3028781348447 SOC: 0.6103 Cumulative_SOC_deviation: 31.9655 Fuel Consumption: 45.6480\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.406\n",
      "Episode: 124 Exploration P: 0.0755 Total reward: -377.52145076715675 SOC: 0.6183 Cumulative_SOC_deviation: 33.1661 Fuel Consumption: 45.8605\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.671\n",
      "Episode: 125 Exploration P: 0.0741 Total reward: -617.5817844993206 SOC: 0.5972 Cumulative_SOC_deviation: 57.3430 Fuel Consumption: 44.1516\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.419\n",
      "Episode: 126 Exploration P: 0.0724 Total reward: -424.8972836873059 SOC: 0.6101 Cumulative_SOC_deviation: 37.7959 Fuel Consumption: 46.9383\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.622\n",
      "Episode: 127 Exploration P: 0.0717 Total reward: -1258.4760455476119 SOC: 0.3160 Cumulative_SOC_deviation: 121.7526 Fuel Consumption: 40.9497\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.373\n",
      "Episode: 128 Exploration P: 0.0700 Total reward: -429.3696333663042 SOC: 0.5916 Cumulative_SOC_deviation: 38.4579 Fuel Consumption: 44.7908\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.650\n",
      "Episode: 129 Exploration P: 0.0688 Total reward: -518.1583581514145 SOC: 0.5914 Cumulative_SOC_deviation: 47.5351 Fuel Consumption: 42.8074\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.005\n",
      "Episode: 130 Exploration P: 0.0681 Total reward: -1050.4268989762688 SOC: 0.3628 Cumulative_SOC_deviation: 100.6998 Fuel Consumption: 43.4294\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.922\n",
      "Episode: 131 Exploration P: 0.0669 Total reward: -63.253804583320466 SOC: 0.5939 Cumulative_SOC_deviation: 5.5255 Fuel Consumption: 7.9991\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.650\n",
      "Episode: 132 Exploration P: 0.0656 Total reward: -163.53207241276678 SOC: 0.5705 Cumulative_SOC_deviation: 15.7204 Fuel Consumption: 6.3281\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.652\n",
      "Episode: 133 Exploration P: 0.0644 Total reward: -170.13293995317835 SOC: 0.5700 Cumulative_SOC_deviation: 16.3968 Fuel Consumption: 6.1649\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.824\n",
      "Episode: 134 Exploration P: 0.0633 Total reward: -222.0498272207583 SOC: 0.5577 Cumulative_SOC_deviation: 21.6652 Fuel Consumption: 5.3983\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.196\n",
      "Episode: 135 Exploration P: 0.0621 Total reward: -298.45309561276594 SOC: 0.5421 Cumulative_SOC_deviation: 29.4224 Fuel Consumption: 4.2288\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.465\n",
      "Episode: 136 Exploration P: 0.0607 Total reward: -1257.5573708475558 SOC: 0.5059 Cumulative_SOC_deviation: 122.0476 Fuel Consumption: 37.0816\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.827\n",
      "Episode: 137 Exploration P: 0.0596 Total reward: -1005.5128548239622 SOC: 0.4971 Cumulative_SOC_deviation: 96.9961 Fuel Consumption: 35.5518\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.556\n",
      "Episode: 138 Exploration P: 0.0591 Total reward: -1266.071262942888 SOC: 0.3148 Cumulative_SOC_deviation: 122.6035 Fuel Consumption: 40.0366\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.987\n",
      "Episode: 139 Exploration P: 0.0580 Total reward: -329.3913609611603 SOC: 0.5471 Cumulative_SOC_deviation: 32.4867 Fuel Consumption: 4.5239\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.545\n",
      "Episode: 140 Exploration P: 0.0570 Total reward: -342.23592087630584 SOC: 0.5514 Cumulative_SOC_deviation: 33.7441 Fuel Consumption: 4.7954\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.688\n",
      "Episode: 141 Exploration P: 0.0560 Total reward: -870.1076818700225 SOC: 0.5497 Cumulative_SOC_deviation: 83.0232 Fuel Consumption: 39.8758\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.154\n",
      "Episode: 142 Exploration P: 0.0555 Total reward: -1174.1512622469552 SOC: 0.3374 Cumulative_SOC_deviation: 113.2663 Fuel Consumption: 41.4878\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.630\n",
      "Episode: 143 Exploration P: 0.0550 Total reward: -1203.2008790673106 SOC: 0.3326 Cumulative_SOC_deviation: 116.1957 Fuel Consumption: 41.2440\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.891\n",
      "Episode: 144 Exploration P: 0.0541 Total reward: -655.0336953954932 SOC: 0.5605 Cumulative_SOC_deviation: 61.4904 Fuel Consumption: 40.1293\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.907\n",
      "Episode: 145 Exploration P: 0.0529 Total reward: -579.263261707957 SOC: 0.5724 Cumulative_SOC_deviation: 53.6635 Fuel Consumption: 42.6279\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 150.811\n",
      "Episode: 146 Exploration P: 0.0513 Total reward: -1173.4636816443099 SOC: 0.5624 Cumulative_SOC_deviation: 110.3446 Fuel Consumption: 70.0172\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 149.651\n",
      "Episode: 147 Exploration P: 0.0498 Total reward: -972.0391330420783 SOC: 0.5731 Cumulative_SOC_deviation: 90.0710 Fuel Consumption: 71.3289\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.620\n",
      "Episode: 148 Exploration P: 0.0490 Total reward: -592.8612367659999 SOC: 0.5772 Cumulative_SOC_deviation: 55.1218 Fuel Consumption: 41.6436\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.742\n",
      "Episode: 149 Exploration P: 0.0481 Total reward: -128.49225020602768 SOC: 0.5774 Cumulative_SOC_deviation: 12.1845 Fuel Consumption: 6.6469\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.724\n",
      "Episode: 150 Exploration P: 0.0473 Total reward: -699.1345233107784 SOC: 0.5258 Cumulative_SOC_deviation: 66.0870 Fuel Consumption: 38.2641\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.816\n",
      "Episode: 151 Exploration P: 0.0465 Total reward: -958.2933628163478 SOC: 0.5125 Cumulative_SOC_deviation: 92.1342 Fuel Consumption: 36.9516\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 42.967\n",
      "Episode: 152 Exploration P: 0.0461 Total reward: -1280.4286063990246 SOC: 0.3178 Cumulative_SOC_deviation: 124.0198 Fuel Consumption: 40.2303\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.402\n",
      "Episode: 153 Exploration P: 0.0454 Total reward: -339.5387169251632 SOC: 0.5609 Cumulative_SOC_deviation: 33.4090 Fuel Consumption: 5.4487\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.890\n",
      "Episode: 154 Exploration P: 0.0446 Total reward: -47.479734114093574 SOC: 0.5981 Cumulative_SOC_deviation: 3.9056 Fuel Consumption: 8.4242\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 149.643\n",
      "Episode: 155 Exploration P: 0.0433 Total reward: -760.1894713097304 SOC: 0.5569 Cumulative_SOC_deviation: 69.0314 Fuel Consumption: 69.8752\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.339\n",
      "Episode: 156 Exploration P: 0.0424 Total reward: -1548.7545775960682 SOC: 0.4938 Cumulative_SOC_deviation: 151.2489 Fuel Consumption: 36.2654\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.097\n",
      "Episode: 157 Exploration P: 0.0421 Total reward: -1410.6071286550116 SOC: 0.2845 Cumulative_SOC_deviation: 137.2634 Fuel Consumption: 37.9736\n",
      "\n",
      "training\\07_manhattan.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.745\n",
      "Episode: 158 Exploration P: 0.0414 Total reward: -425.45775432993156 SOC: 0.5261 Cumulative_SOC_deviation: 42.2452 Fuel Consumption: 3.0059\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.727\n",
      "Episode: 159 Exploration P: 0.0407 Total reward: -1805.0832523321312 SOC: 0.2762 Cumulative_SOC_deviation: 178.5543 Fuel Consumption: 19.5407\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.765\n",
      "Episode: 160 Exploration P: 0.0401 Total reward: -394.5880827077741 SOC: 0.5283 Cumulative_SOC_deviation: 39.1390 Fuel Consumption: 3.1985\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.031\n",
      "Episode: 161 Exploration P: 0.0397 Total reward: -1315.7736174498855 SOC: 0.3077 Cumulative_SOC_deviation: 127.6267 Fuel Consumption: 39.5066\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.838\n",
      "Episode: 162 Exploration P: 0.0391 Total reward: -269.56389248427735 SOC: 0.5783 Cumulative_SOC_deviation: 26.2428 Fuel Consumption: 7.1360\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 43.343\n",
      "Episode: 163 Exploration P: 0.0388 Total reward: -1241.9402242396009 SOC: 0.3269 Cumulative_SOC_deviation: 120.0942 Fuel Consumption: 40.9982\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.174\n",
      "Episode: 164 Exploration P: 0.0382 Total reward: -707.324234001284 SOC: 0.5859 Cumulative_SOC_deviation: 66.4279 Fuel Consumption: 43.0456\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.683\n",
      "Episode: 165 Exploration P: 0.0376 Total reward: -855.2958347217037 SOC: 0.5138 Cumulative_SOC_deviation: 81.7852 Fuel Consumption: 37.4438\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.313\n",
      "Episode: 166 Exploration P: 0.0370 Total reward: -902.146990165486 SOC: 0.5621 Cumulative_SOC_deviation: 86.1022 Fuel Consumption: 41.1253\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 150.354\n",
      "Episode: 167 Exploration P: 0.0360 Total reward: -881.5790372476362 SOC: 0.5863 Cumulative_SOC_deviation: 80.9819 Fuel Consumption: 71.7596\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.198\n",
      "Episode: 168 Exploration P: 0.0355 Total reward: -483.8818654286307 SOC: 0.5814 Cumulative_SOC_deviation: 44.1624 Fuel Consumption: 42.2578\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.391\n",
      "Episode: 169 Exploration P: 0.0349 Total reward: -339.2320857396718 SOC: 0.5764 Cumulative_SOC_deviation: 33.2583 Fuel Consumption: 6.6486\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.444\n",
      "Episode: 170 Exploration P: 0.0346 Total reward: -1063.450010992558 SOC: 0.3640 Cumulative_SOC_deviation: 102.0182 Fuel Consumption: 43.2685\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.928\n",
      "Episode: 171 Exploration P: 0.0341 Total reward: -158.46425395116722 SOC: 0.5935 Cumulative_SOC_deviation: 15.0202 Fuel Consumption: 8.2619\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.439\n",
      "Episode: 172 Exploration P: 0.0336 Total reward: -489.42613875411513 SOC: 0.5933 Cumulative_SOC_deviation: 44.6252 Fuel Consumption: 43.1739\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.999\n",
      "Episode: 173 Exploration P: 0.0331 Total reward: -270.43343702173314 SOC: 0.5445 Cumulative_SOC_deviation: 26.6128 Fuel Consumption: 4.3058\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.386\n",
      "Episode: 174 Exploration P: 0.0323 Total reward: -976.6840538796864 SOC: 0.5900 Cumulative_SOC_deviation: 90.4920 Fuel Consumption: 71.7638\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.387\n",
      "Episode: 175 Exploration P: 0.0318 Total reward: -103.6377181851528 SOC: 0.5927 Cumulative_SOC_deviation: 9.5999 Fuel Consumption: 7.6391\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.703\n",
      "Episode: 176 Exploration P: 0.0313 Total reward: -548.3272094712553 SOC: 0.5848 Cumulative_SOC_deviation: 50.5853 Fuel Consumption: 42.4739\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.114\n",
      "Episode: 177 Exploration P: 0.0311 Total reward: -1076.3786201851312 SOC: 0.3611 Cumulative_SOC_deviation: 103.3046 Fuel Consumption: 43.3324\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.129\n",
      "Episode: 178 Exploration P: 0.0303 Total reward: -666.3493191461038 SOC: 0.5855 Cumulative_SOC_deviation: 59.6045 Fuel Consumption: 70.3043\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.192\n",
      "Episode: 179 Exploration P: 0.0296 Total reward: -655.9265853322062 SOC: 0.6034 Cumulative_SOC_deviation: 58.4515 Fuel Consumption: 71.4120\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.359\n",
      "Episode: 180 Exploration P: 0.0291 Total reward: -211.33975773472312 SOC: 0.5902 Cumulative_SOC_deviation: 20.3943 Fuel Consumption: 7.3964\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.693\n",
      "Episode: 181 Exploration P: 0.0287 Total reward: -79.20008877450573 SOC: 0.5932 Cumulative_SOC_deviation: 7.1467 Fuel Consumption: 7.7328\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.909\n",
      "Episode: 182 Exploration P: 0.0280 Total reward: -700.2107164643575 SOC: 0.4806 Cumulative_SOC_deviation: 63.6852 Fuel Consumption: 63.3589\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.756\n",
      "Episode: 183 Exploration P: 0.0276 Total reward: -451.9888695585254 SOC: 0.5215 Cumulative_SOC_deviation: 44.9310 Fuel Consumption: 2.6785\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.942\n",
      "Episode: 184 Exploration P: 0.0273 Total reward: -2610.4300513822022 SOC: 0.0049 Cumulative_SOC_deviation: 260.6769 Fuel Consumption: 3.6615\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.939\n",
      "Episode: 185 Exploration P: 0.0266 Total reward: -1702.9691232885264 SOC: 0.5541 Cumulative_SOC_deviation: 163.3138 Fuel Consumption: 69.8309\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.809\n",
      "Episode: 186 Exploration P: 0.0262 Total reward: -620.0529285890938 SOC: 0.6015 Cumulative_SOC_deviation: 57.4774 Fuel Consumption: 45.2787\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.314\n",
      "Episode: 187 Exploration P: 0.0256 Total reward: -482.86931989110064 SOC: 0.6065 Cumulative_SOC_deviation: 41.0352 Fuel Consumption: 72.5171\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.785\n",
      "Episode: 188 Exploration P: 0.0253 Total reward: -395.6080750848421 SOC: 0.5970 Cumulative_SOC_deviation: 35.2692 Fuel Consumption: 42.9163\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.778\n",
      "Episode: 189 Exploration P: 0.0249 Total reward: -539.2877048445885 SOC: 0.5970 Cumulative_SOC_deviation: 49.6215 Fuel Consumption: 43.0723\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.458\n",
      "Episode: 190 Exploration P: 0.0245 Total reward: -297.2546309247489 SOC: 0.5959 Cumulative_SOC_deviation: 25.3683 Fuel Consumption: 43.5715\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.838\n",
      "Episode: 191 Exploration P: 0.0242 Total reward: -417.24286770602237 SOC: 0.5939 Cumulative_SOC_deviation: 37.4493 Fuel Consumption: 42.7502\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.090\n",
      "Episode: 192 Exploration P: 0.0241 Total reward: -992.413412608865 SOC: 0.3800 Cumulative_SOC_deviation: 94.7981 Fuel Consumption: 44.4325\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.581\n",
      "Episode: 193 Exploration P: 0.0239 Total reward: -1001.1529126714563 SOC: 0.3793 Cumulative_SOC_deviation: 95.6802 Fuel Consumption: 44.3511\n",
      "\n",
      "training\\FTP_75_cycle.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 156.750\n",
      "Episode: 194 Exploration P: 0.0234 Total reward: -1002.804564549522 SOC: 0.5511 Cumulative_SOC_deviation: 93.4384 Fuel Consumption: 68.4202\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.623\n",
      "Episode: 195 Exploration P: 0.0229 Total reward: -1131.1993111439022 SOC: 0.5998 Cumulative_SOC_deviation: 105.9368 Fuel Consumption: 71.8314\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.772\n",
      "Episode: 196 Exploration P: 0.0228 Total reward: -1006.1747417622831 SOC: 0.3783 Cumulative_SOC_deviation: 96.1721 Fuel Consumption: 44.4533\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.732\n",
      "Episode: 197 Exploration P: 0.0225 Total reward: -421.5174839136283 SOC: 0.5995 Cumulative_SOC_deviation: 37.8168 Fuel Consumption: 43.3492\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.669\n",
      "Episode: 198 Exploration P: 0.0224 Total reward: -1013.3332155296275 SOC: 0.3747 Cumulative_SOC_deviation: 96.9298 Fuel Consumption: 44.0354\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.377\n",
      "Episode: 199 Exploration P: 0.0221 Total reward: -34.68833930702222 SOC: 0.6020 Cumulative_SOC_deviation: 2.6465 Fuel Consumption: 8.2232\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.227\n",
      "Episode: 200 Exploration P: 0.0220 Total reward: -971.3950007583998 SOC: 0.3847 Cumulative_SOC_deviation: 92.6705 Fuel Consumption: 44.6896\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.281\n",
      "Episode: 201 Exploration P: 0.0217 Total reward: -631.9089423917568 SOC: 0.5689 Cumulative_SOC_deviation: 59.1202 Fuel Consumption: 40.7070\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.014\n",
      "Episode: 202 Exploration P: 0.0215 Total reward: -53.32049812390369 SOC: 0.6029 Cumulative_SOC_deviation: 4.4975 Fuel Consumption: 8.3458\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.528\n",
      "Episode: 203 Exploration P: 0.0211 Total reward: -450.055863866649 SOC: 0.5940 Cumulative_SOC_deviation: 37.8802 Fuel Consumption: 71.2535\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.023\n",
      "Episode: 204 Exploration P: 0.0209 Total reward: -1068.8698127186244 SOC: 0.3642 Cumulative_SOC_deviation: 102.5253 Fuel Consumption: 43.6172\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.532\n",
      "Episode: 205 Exploration P: 0.0207 Total reward: -364.22555324100716 SOC: 0.6029 Cumulative_SOC_deviation: 32.0889 Fuel Consumption: 43.3363\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.577\n",
      "Episode: 206 Exploration P: 0.0203 Total reward: -2780.0372364609225 SOC: 0.2395 Cumulative_SOC_deviation: 273.4741 Fuel Consumption: 45.2961\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.092\n",
      "Episode: 207 Exploration P: 0.0201 Total reward: -483.00008215190053 SOC: 0.5147 Cumulative_SOC_deviation: 48.0831 Fuel Consumption: 2.1693\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.110\n",
      "Episode: 208 Exploration P: 0.0199 Total reward: -409.3462633802688 SOC: 0.5349 Cumulative_SOC_deviation: 40.5784 Fuel Consumption: 3.5625\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.793\n",
      "Episode: 209 Exploration P: 0.0197 Total reward: -700.8140344386323 SOC: 0.5672 Cumulative_SOC_deviation: 66.0028 Fuel Consumption: 40.7863\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.223\n",
      "Episode: 210 Exploration P: 0.0195 Total reward: -294.7497130556179 SOC: 0.5942 Cumulative_SOC_deviation: 28.6900 Fuel Consumption: 7.8496\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.405\n",
      "Episode: 211 Exploration P: 0.0192 Total reward: -241.40484653023964 SOC: 0.5901 Cumulative_SOC_deviation: 19.8287 Fuel Consumption: 43.1178\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.692\n",
      "Episode: 212 Exploration P: 0.0189 Total reward: -385.31304567698254 SOC: 0.6053 Cumulative_SOC_deviation: 31.3535 Fuel Consumption: 71.7784\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.165\n",
      "Episode: 213 Exploration P: 0.0188 Total reward: -994.0954342888267 SOC: 0.3812 Cumulative_SOC_deviation: 94.9644 Fuel Consumption: 44.4519\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.743\n",
      "Episode: 214 Exploration P: 0.0185 Total reward: -218.33413344435078 SOC: 0.6019 Cumulative_SOC_deviation: 17.4126 Fuel Consumption: 44.2085\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.049\n",
      "Episode: 215 Exploration P: 0.0182 Total reward: -636.77703346025 SOC: 0.5958 Cumulative_SOC_deviation: 56.5340 Fuel Consumption: 71.4371\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.690\n",
      "Episode: 216 Exploration P: 0.0180 Total reward: -353.65957956271603 SOC: 0.5905 Cumulative_SOC_deviation: 31.0077 Fuel Consumption: 43.5830\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.663\n",
      "Episode: 217 Exploration P: 0.0178 Total reward: -336.3473262432797 SOC: 0.5770 Cumulative_SOC_deviation: 29.4043 Fuel Consumption: 42.3043\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.041\n",
      "Episode: 218 Exploration P: 0.0176 Total reward: -250.77460276756054 SOC: 0.5683 Cumulative_SOC_deviation: 24.4829 Fuel Consumption: 5.9456\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.721\n",
      "Episode: 219 Exploration P: 0.0174 Total reward: -657.7291675938275 SOC: 0.6086 Cumulative_SOC_deviation: 61.2984 Fuel Consumption: 44.7451\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.218\n",
      "Episode: 220 Exploration P: 0.0173 Total reward: -913.0389744479517 SOC: 0.3986 Cumulative_SOC_deviation: 86.7328 Fuel Consumption: 45.7109\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.995\n",
      "Episode: 221 Exploration P: 0.0171 Total reward: -298.04744141418996 SOC: 0.5966 Cumulative_SOC_deviation: 25.4159 Fuel Consumption: 43.8883\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.855\n",
      "Episode: 222 Exploration P: 0.0169 Total reward: -353.8635986871219 SOC: 0.5696 Cumulative_SOC_deviation: 31.2226 Fuel Consumption: 41.6371\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.092\n",
      "Episode: 223 Exploration P: 0.0168 Total reward: -629.798810892963 SOC: 0.5765 Cumulative_SOC_deviation: 58.8517 Fuel Consumption: 41.2816\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.954\n",
      "Episode: 224 Exploration P: 0.0166 Total reward: -617.8050712531335 SOC: 0.5564 Cumulative_SOC_deviation: 57.6880 Fuel Consumption: 40.9255\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.775\n",
      "Episode: 225 Exploration P: 0.0165 Total reward: -160.38019842635936 SOC: 0.5838 Cumulative_SOC_deviation: 15.3229 Fuel Consumption: 7.1508\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.511\n",
      "Episode: 226 Exploration P: 0.0163 Total reward: -673.9136534983201 SOC: 0.5686 Cumulative_SOC_deviation: 63.3032 Fuel Consumption: 40.8817\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.977\n",
      "Episode: 227 Exploration P: 0.0162 Total reward: -363.83676742824883 SOC: 0.5981 Cumulative_SOC_deviation: 32.0866 Fuel Consumption: 42.9707\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.100\n",
      "Episode: 228 Exploration P: 0.0161 Total reward: -492.5120777992685 SOC: 0.5905 Cumulative_SOC_deviation: 45.0119 Fuel Consumption: 42.3931\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.338\n",
      "Episode: 229 Exploration P: 0.0159 Total reward: -50.564552227514895 SOC: 0.6011 Cumulative_SOC_deviation: 4.2199 Fuel Consumption: 8.3659\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.598\n",
      "Episode: 230 Exploration P: 0.0158 Total reward: -719.2215600241378 SOC: 0.5567 Cumulative_SOC_deviation: 67.7859 Fuel Consumption: 41.3623\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.346\n",
      "Episode: 231 Exploration P: 0.0156 Total reward: -287.71231671418326 SOC: 0.5833 Cumulative_SOC_deviation: 28.0736 Fuel Consumption: 6.9765\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.638\n",
      "Episode: 232 Exploration P: 0.0155 Total reward: -421.6053774433835 SOC: 0.5668 Cumulative_SOC_deviation: 37.9594 Fuel Consumption: 42.0111\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.510\n",
      "Episode: 233 Exploration P: 0.0154 Total reward: -1128.9290413889016 SOC: 0.3527 Cumulative_SOC_deviation: 108.6367 Fuel Consumption: 42.5621\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.380\n",
      "Episode: 234 Exploration P: 0.0153 Total reward: -710.9892533075794 SOC: 0.5621 Cumulative_SOC_deviation: 67.0525 Fuel Consumption: 40.4639\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.723\n",
      "Episode: 235 Exploration P: 0.0152 Total reward: -674.8158131449325 SOC: 0.5582 Cumulative_SOC_deviation: 63.4777 Fuel Consumption: 40.0385\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.384\n",
      "Episode: 236 Exploration P: 0.0151 Total reward: -348.3781963475256 SOC: 0.5617 Cumulative_SOC_deviation: 34.2932 Fuel Consumption: 5.4463\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.877\n",
      "Episode: 237 Exploration P: 0.0150 Total reward: -759.1502262764959 SOC: 0.5552 Cumulative_SOC_deviation: 71.9204 Fuel Consumption: 39.9464\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.504\n",
      "Episode: 238 Exploration P: 0.0149 Total reward: -767.661536636001 SOC: 0.5395 Cumulative_SOC_deviation: 72.8955 Fuel Consumption: 38.7063\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.236\n",
      "Episode: 239 Exploration P: 0.0148 Total reward: -312.13946489846705 SOC: 0.5710 Cumulative_SOC_deviation: 30.5971 Fuel Consumption: 6.1684\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.134\n",
      "Episode: 240 Exploration P: 0.0147 Total reward: -1137.897654353161 SOC: 0.3511 Cumulative_SOC_deviation: 109.5425 Fuel Consumption: 42.4723\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.992\n",
      "Episode: 241 Exploration P: 0.0146 Total reward: -627.9097403789021 SOC: 0.5686 Cumulative_SOC_deviation: 58.5803 Fuel Consumption: 42.1065\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.700\n",
      "Episode: 242 Exploration P: 0.0146 Total reward: -1127.3143960090272 SOC: 0.3549 Cumulative_SOC_deviation: 108.4573 Fuel Consumption: 42.7413\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.507\n",
      "Episode: 243 Exploration P: 0.0144 Total reward: -868.5377721842142 SOC: 0.5511 Cumulative_SOC_deviation: 80.0850 Fuel Consumption: 67.6878\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.402\n",
      "Episode: 244 Exploration P: 0.0143 Total reward: -331.9198400843996 SOC: 0.5564 Cumulative_SOC_deviation: 32.6833 Fuel Consumption: 5.0868\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 44.954\n",
      "Episode: 245 Exploration P: 0.0142 Total reward: -1216.2664497831677 SOC: 0.3349 Cumulative_SOC_deviation: 117.4871 Fuel Consumption: 41.3958\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.482\n",
      "Episode: 246 Exploration P: 0.0142 Total reward: -127.66120531061492 SOC: 0.6117 Cumulative_SOC_deviation: 11.8496 Fuel Consumption: 9.1656\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.269\n",
      "Episode: 247 Exploration P: 0.0141 Total reward: -912.7695354227897 SOC: 0.3992 Cumulative_SOC_deviation: 86.6929 Fuel Consumption: 45.8409\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.772\n",
      "Episode: 248 Exploration P: 0.0140 Total reward: -287.39204422427775 SOC: 0.5842 Cumulative_SOC_deviation: 24.4405 Fuel Consumption: 42.9874\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.182\n",
      "Episode: 249 Exploration P: 0.0139 Total reward: -313.6520747728342 SOC: 0.6068 Cumulative_SOC_deviation: 26.8811 Fuel Consumption: 44.8408\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.294\n",
      "Episode: 250 Exploration P: 0.0138 Total reward: -383.62011303974214 SOC: 0.6015 Cumulative_SOC_deviation: 34.0202 Fuel Consumption: 43.4185\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.354\n",
      "Episode: 251 Exploration P: 0.0138 Total reward: -1035.5044457047984 SOC: 0.3684 Cumulative_SOC_deviation: 99.1591 Fuel Consumption: 43.9137\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.272\n",
      "Episode: 252 Exploration P: 0.0137 Total reward: -64.65449464856647 SOC: 0.6040 Cumulative_SOC_deviation: 5.6202 Fuel Consumption: 8.4526\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.624\n",
      "Episode: 253 Exploration P: 0.0136 Total reward: -404.2010677518251 SOC: 0.5994 Cumulative_SOC_deviation: 36.1045 Fuel Consumption: 43.1561\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.316\n",
      "Episode: 254 Exploration P: 0.0135 Total reward: -280.4341737630322 SOC: 0.5904 Cumulative_SOC_deviation: 23.6609 Fuel Consumption: 43.8250\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.915\n",
      "Episode: 255 Exploration P: 0.0134 Total reward: -1025.0851186152872 SOC: 0.5139 Cumulative_SOC_deviation: 98.6537 Fuel Consumption: 38.5481\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.559\n",
      "Episode: 256 Exploration P: 0.0133 Total reward: -518.0501457166373 SOC: 0.5080 Cumulative_SOC_deviation: 51.6392 Fuel Consumption: 1.6579\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.529\n",
      "Episode: 257 Exploration P: 0.0133 Total reward: -1419.474428690148 SOC: 0.2890 Cumulative_SOC_deviation: 138.0831 Fuel Consumption: 38.6437\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.272\n",
      "Episode: 258 Exploration P: 0.0132 Total reward: -483.6964313678915 SOC: 0.5370 Cumulative_SOC_deviation: 47.9937 Fuel Consumption: 3.7599\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 156.934\n",
      "Episode: 259 Exploration P: 0.0131 Total reward: -550.0365054668174 SOC: 0.5734 Cumulative_SOC_deviation: 48.0170 Fuel Consumption: 69.8666\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.698\n",
      "Episode: 260 Exploration P: 0.0130 Total reward: -400.2868663860955 SOC: 0.6049 Cumulative_SOC_deviation: 35.5910 Fuel Consumption: 44.3769\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.149\n",
      "Episode: 261 Exploration P: 0.0130 Total reward: -1092.2168124024142 SOC: 0.3583 Cumulative_SOC_deviation: 104.9322 Fuel Consumption: 42.8949\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.919\n",
      "Episode: 262 Exploration P: 0.0129 Total reward: -677.9750700963201 SOC: 0.5876 Cumulative_SOC_deviation: 60.7266 Fuel Consumption: 70.7089\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 156.837\n",
      "Episode: 263 Exploration P: 0.0128 Total reward: -2212.8125713553186 SOC: 0.4584 Cumulative_SOC_deviation: 215.1463 Fuel Consumption: 61.3497\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.309\n",
      "Episode: 264 Exploration P: 0.0127 Total reward: -1396.073224865746 SOC: 0.2958 Cumulative_SOC_deviation: 135.6949 Fuel Consumption: 39.1238\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.869\n",
      "Episode: 265 Exploration P: 0.0127 Total reward: -1238.6717742135133 SOC: 0.4282 Cumulative_SOC_deviation: 120.8179 Fuel Consumption: 30.4930\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.517\n",
      "Episode: 266 Exploration P: 0.0126 Total reward: -2198.0922088399866 SOC: 0.4283 Cumulative_SOC_deviation: 216.6251 Fuel Consumption: 31.8416\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.420\n",
      "Episode: 267 Exploration P: 0.0126 Total reward: -1456.1423352934298 SOC: 0.3792 Cumulative_SOC_deviation: 142.9214 Fuel Consumption: 26.9286\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.732\n",
      "Episode: 268 Exploration P: 0.0125 Total reward: -1550.056423081311 SOC: 0.3740 Cumulative_SOC_deviation: 152.2970 Fuel Consumption: 27.0868\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.339\n",
      "Episode: 269 Exploration P: 0.0125 Total reward: -1616.3721599143305 SOC: 0.2421 Cumulative_SOC_deviation: 158.0427 Fuel Consumption: 35.9452\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.211\n",
      "Episode: 270 Exploration P: 0.0124 Total reward: -2787.7672021860053 SOC: 0.3477 Cumulative_SOC_deviation: 276.1906 Fuel Consumption: 25.8613\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 21.218\n",
      "Episode: 271 Exploration P: 0.0124 Total reward: -1529.1664458648097 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 4.7432\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 21.257\n",
      "Episode: 272 Exploration P: 0.0124 Total reward: -1545.9032884035782 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.2097\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.467\n",
      "Episode: 273 Exploration P: 0.0123 Total reward: -1648.6609701358148 SOC: 0.4084 Cumulative_SOC_deviation: 161.8264 Fuel Consumption: 30.3966\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.271\n",
      "Episode: 274 Exploration P: 0.0123 Total reward: -1534.31589463854 SOC: 0.2623 Cumulative_SOC_deviation: 149.7244 Fuel Consumption: 37.0714\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.421\n",
      "Episode: 275 Exploration P: 0.0123 Total reward: -486.7713184035174 SOC: 0.5151 Cumulative_SOC_deviation: 48.4545 Fuel Consumption: 2.2260\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.033\n",
      "Episode: 276 Exploration P: 0.0122 Total reward: -1640.050151288386 SOC: 0.3431 Cumulative_SOC_deviation: 161.5111 Fuel Consumption: 24.9396\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.979\n",
      "Episode: 277 Exploration P: 0.0122 Total reward: -2524.9471369029443 SOC: 0.0466 Cumulative_SOC_deviation: 251.9412 Fuel Consumption: 5.5355\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.943\n",
      "Episode: 278 Exploration P: 0.0121 Total reward: -3183.893814598461 SOC: 0.3489 Cumulative_SOC_deviation: 315.6302 Fuel Consumption: 27.5919\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 156.915\n",
      "Episode: 279 Exploration P: 0.0120 Total reward: -5048.136726057288 SOC: 0.3695 Cumulative_SOC_deviation: 499.2427 Fuel Consumption: 55.7092\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 156.746\n",
      "Episode: 280 Exploration P: 0.0120 Total reward: -3899.9907549838035 SOC: 0.4300 Cumulative_SOC_deviation: 384.0126 Fuel Consumption: 59.8649\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.451\n",
      "Episode: 281 Exploration P: 0.0119 Total reward: -1393.179181329139 SOC: 0.2962 Cumulative_SOC_deviation: 135.4234 Fuel Consumption: 38.9456\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.296\n",
      "Episode: 282 Exploration P: 0.0119 Total reward: -1337.0922703072931 SOC: 0.3092 Cumulative_SOC_deviation: 129.7376 Fuel Consumption: 39.7163\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 46.208\n",
      "Episode: 283 Exploration P: 0.0119 Total reward: -1311.0239318241931 SOC: 0.3144 Cumulative_SOC_deviation: 127.0993 Fuel Consumption: 40.0308\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.135\n",
      "Episode: 284 Exploration P: 0.0119 Total reward: -555.6882669124601 SOC: 0.5899 Cumulative_SOC_deviation: 51.2814 Fuel Consumption: 42.8746\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.771\n",
      "Episode: 285 Exploration P: 0.0118 Total reward: -312.4661175649147 SOC: 0.5837 Cumulative_SOC_deviation: 26.9453 Fuel Consumption: 43.0131\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.068\n",
      "Episode: 286 Exploration P: 0.0118 Total reward: -733.7551556940058 SOC: 0.5436 Cumulative_SOC_deviation: 69.4648 Fuel Consumption: 39.1073\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.325\n",
      "Episode: 287 Exploration P: 0.0117 Total reward: -220.53182144251494 SOC: 0.5770 Cumulative_SOC_deviation: 21.3837 Fuel Consumption: 6.6945\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 45.165\n",
      "Episode: 288 Exploration P: 0.0117 Total reward: -1005.6798624149127 SOC: 0.3797 Cumulative_SOC_deviation: 96.1033 Fuel Consumption: 44.6468\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.533\n",
      "Episode: 289 Exploration P: 0.0117 Total reward: -346.7176203250849 SOC: 0.6039 Cumulative_SOC_deviation: 30.3290 Fuel Consumption: 43.4281\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.172\n",
      "Episode: 290 Exploration P: 0.0116 Total reward: -525.3225552197164 SOC: 0.5856 Cumulative_SOC_deviation: 45.4684 Fuel Consumption: 70.6387\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.952\n",
      "Episode: 291 Exploration P: 0.0116 Total reward: -391.5650066678303 SOC: 0.5746 Cumulative_SOC_deviation: 34.8996 Fuel Consumption: 42.5685\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.503\n",
      "Episode: 292 Exploration P: 0.0115 Total reward: -83.64866367661752 SOC: 0.5907 Cumulative_SOC_deviation: 7.6115 Fuel Consumption: 7.5340\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.232\n",
      "Episode: 293 Exploration P: 0.0115 Total reward: -594.2066928866805 SOC: 0.5349 Cumulative_SOC_deviation: 55.4600 Fuel Consumption: 39.6070\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.077\n",
      "Episode: 294 Exploration P: 0.0115 Total reward: -3447.8041496170235 SOC: 0.1729 Cumulative_SOC_deviation: 343.2736 Fuel Consumption: 15.0682\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 131.622\n",
      "Episode: 295 Exploration P: 0.0114 Total reward: -7700.733429896875 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.9171\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.595\n",
      "Episode: 296 Exploration P: 0.0114 Total reward: -1440.088616861174 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7359\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 128.798\n",
      "Episode: 297 Exploration P: 0.0114 Total reward: -7760.195334461687 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6571\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 18.505\n",
      "Episode: 298 Exploration P: 0.0114 Total reward: -1442.840936099586 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6396\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 57.162\n",
      "Episode: 299 Exploration P: 0.0113 Total reward: -1646.5024030318677 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.1299\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 18.826\n",
      "Episode: 300 Exploration P: 0.0113 Total reward: -1440.107249649067 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.8419\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 118.403\n",
      "Episode: 301 Exploration P: 0.0113 Total reward: -5500.0701374323 SOC: -0.0342 Cumulative_SOC_deviation: 549.8073 Fuel Consumption: 1.9972\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 63.608\n",
      "Episode: 302 Exploration P: 0.0113 Total reward: -1642.5998422276798 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.2550\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 64.550\n",
      "Episode: 303 Exploration P: 0.0113 Total reward: -1624.9933225736338 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.4861\n",
      "\n",
      "training\\06_udds_truck.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOC is nan...\n",
      "elapsed_time: 64.799\n",
      "Episode: 304 Exploration P: 0.0112 Total reward: -1645.3108139303786 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.2069\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 65.028\n",
      "Episode: 305 Exploration P: 0.0112 Total reward: -1641.915998514293 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.2839\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 141.592\n",
      "Episode: 306 Exploration P: 0.0112 Total reward: -7773.929783764252 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6956\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 134.843\n",
      "Episode: 307 Exploration P: 0.0111 Total reward: -7756.188346298844 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6474\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.259\n",
      "Episode: 308 Exploration P: 0.0111 Total reward: -5522.957979890181 SOC: -0.0347 Cumulative_SOC_deviation: 552.0990 Fuel Consumption: 1.9683\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.994\n",
      "Episode: 309 Exploration P: 0.0111 Total reward: -1650.7987010349084 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.0817\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.713\n",
      "Episode: 310 Exploration P: 0.0111 Total reward: -1646.2140361848137 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.2358\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.450\n",
      "Episode: 311 Exploration P: 0.0111 Total reward: -525.6772157144898 SOC: 0.5082 Cumulative_SOC_deviation: 52.4000 Fuel Consumption: 1.6771\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.665\n",
      "Episode: 312 Exploration P: 0.0110 Total reward: -1633.0086280943192 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.2550\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 131.019\n",
      "Episode: 313 Exploration P: 0.0110 Total reward: -7719.77294405376 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 10.0482\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.771\n",
      "Episode: 314 Exploration P: 0.0110 Total reward: -523.9595781439829 SOC: 0.5090 Cumulative_SOC_deviation: 52.2205 Fuel Consumption: 1.7542\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 131.304\n",
      "Episode: 315 Exploration P: 0.0110 Total reward: -7778.024245185595 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.5897\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.522\n",
      "Episode: 316 Exploration P: 0.0109 Total reward: -510.9331652220568 SOC: 0.5085 Cumulative_SOC_deviation: 50.9218 Fuel Consumption: 1.7156\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.692\n",
      "Episode: 317 Exploration P: 0.0109 Total reward: -7828.983232143662 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.1179\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.994\n",
      "Episode: 318 Exploration P: 0.0109 Total reward: -1649.2794740932752 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.0625\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.330\n",
      "Episode: 319 Exploration P: 0.0109 Total reward: -520.2901534294423 SOC: 0.5066 Cumulative_SOC_deviation: 51.8729 Fuel Consumption: 1.5616\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.434\n",
      "Episode: 320 Exploration P: 0.0109 Total reward: -530.6286789943427 SOC: 0.5059 Cumulative_SOC_deviation: 52.9135 Fuel Consumption: 1.4942\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.569\n",
      "Episode: 321 Exploration P: 0.0108 Total reward: -525.5776000581288 SOC: 0.5072 Cumulative_SOC_deviation: 52.3949 Fuel Consumption: 1.6290\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.735\n",
      "Episode: 322 Exploration P: 0.0108 Total reward: -530.5771421417619 SOC: 0.5068 Cumulative_SOC_deviation: 52.8996 Fuel Consumption: 1.5808\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.457\n",
      "Episode: 323 Exploration P: 0.0108 Total reward: -1439.578510767215 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.8419\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 116.306\n",
      "Episode: 324 Exploration P: 0.0108 Total reward: -5531.362183917985 SOC: -0.0346 Cumulative_SOC_deviation: 552.9355 Fuel Consumption: 2.0068\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.723\n",
      "Episode: 325 Exploration P: 0.0108 Total reward: -7751.960074824011 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.7630\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.630\n",
      "Episode: 326 Exploration P: 0.0108 Total reward: -1650.1013423288323 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.0143\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.949\n",
      "Episode: 327 Exploration P: 0.0108 Total reward: -1624.483953243051 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.6017\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.505\n",
      "Episode: 328 Exploration P: 0.0107 Total reward: -7756.720921087547 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.7480\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.184\n",
      "Episode: 329 Exploration P: 0.0107 Total reward: -1442.1752899655132 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7167\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.391\n",
      "Episode: 330 Exploration P: 0.0107 Total reward: -5445.975512863865 SOC: -0.0224 Cumulative_SOC_deviation: 544.3189 Fuel Consumption: 2.7868\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.647\n",
      "Episode: 331 Exploration P: 0.0107 Total reward: -7712.884784073436 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 3.0219\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.320\n",
      "Episode: 332 Exploration P: 0.0107 Total reward: -1441.7409729359326 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6921\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 60.043\n",
      "Episode: 333 Exploration P: 0.0107 Total reward: -1627.9562646151057 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.4958\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.411\n",
      "Episode: 334 Exploration P: 0.0107 Total reward: -1439.3677823630899 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7745\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.305\n",
      "Episode: 335 Exploration P: 0.0107 Total reward: -1441.9992918187845 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6782\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.748\n",
      "Episode: 336 Exploration P: 0.0107 Total reward: -511.1788857633347 SOC: 0.5097 Cumulative_SOC_deviation: 50.9377 Fuel Consumption: 1.8023\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.497\n",
      "Episode: 337 Exploration P: 0.0106 Total reward: -514.6020587374367 SOC: 0.5089 Cumulative_SOC_deviation: 51.2848 Fuel Consumption: 1.7542\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.004\n",
      "Episode: 338 Exploration P: 0.0106 Total reward: -5530.944372224012 SOC: -0.0341 Cumulative_SOC_deviation: 552.8938 Fuel Consumption: 2.0068\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 131.161\n",
      "Episode: 339 Exploration P: 0.0106 Total reward: -7793.474114995721 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.4549\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 131.598\n",
      "Episode: 340 Exploration P: 0.0106 Total reward: -7749.93842234279 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.5897\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.921\n",
      "Episode: 341 Exploration P: 0.0106 Total reward: -1441.290027500476 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7071\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 131.226\n",
      "Episode: 342 Exploration P: 0.0106 Total reward: -7776.872258019071 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.5319\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.357\n",
      "Episode: 343 Exploration P: 0.0105 Total reward: -534.6283689394794 SOC: 0.5070 Cumulative_SOC_deviation: 53.3028 Fuel Consumption: 1.6001\n",
      "\n",
      "training\\cudec_freeway.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOC is nan...\n",
      "elapsed_time: 19.244\n",
      "Episode: 344 Exploration P: 0.0105 Total reward: -1440.2066183092927 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.8515\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.834\n",
      "Episode: 345 Exploration P: 0.0105 Total reward: -1638.054933808637 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.2262\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.452\n",
      "Episode: 346 Exploration P: 0.0105 Total reward: -525.626730667108 SOC: 0.5060 Cumulative_SOC_deviation: 52.4094 Fuel Consumption: 1.5327\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.595\n",
      "Episode: 347 Exploration P: 0.0105 Total reward: -5547.9623256739505 SOC: -0.0371 Cumulative_SOC_deviation: 554.6138 Fuel Consumption: 1.8239\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.598\n",
      "Episode: 348 Exploration P: 0.0105 Total reward: -7772.077074928931 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6378\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 131.309\n",
      "Episode: 349 Exploration P: 0.0105 Total reward: -7779.953430823936 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6860\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.362\n",
      "Episode: 350 Exploration P: 0.0105 Total reward: -1623.5149729178895 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.7076\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.027\n",
      "Episode: 351 Exploration P: 0.0105 Total reward: -5524.079984195487 SOC: -0.0340 Cumulative_SOC_deviation: 552.2064 Fuel Consumption: 2.0165\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.886\n",
      "Episode: 352 Exploration P: 0.0104 Total reward: -7751.52491256358 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6956\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.219\n",
      "Episode: 353 Exploration P: 0.0104 Total reward: -522.8559021570228 SOC: 0.5069 Cumulative_SOC_deviation: 52.1275 Fuel Consumption: 1.5808\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.472\n",
      "Episode: 354 Exploration P: 0.0104 Total reward: -509.7973597262579 SOC: 0.5111 Cumulative_SOC_deviation: 50.7908 Fuel Consumption: 1.8890\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 132.192\n",
      "Episode: 355 Exploration P: 0.0104 Total reward: -7771.341597719052 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.5897\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.822\n",
      "Episode: 356 Exploration P: 0.0104 Total reward: -506.91346755643366 SOC: 0.5092 Cumulative_SOC_deviation: 50.5140 Fuel Consumption: 1.7734\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.717\n",
      "Episode: 357 Exploration P: 0.0104 Total reward: -1436.5267581611674 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.8707\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.744\n",
      "Episode: 358 Exploration P: 0.0104 Total reward: -5523.505639182333 SOC: -0.0347 Cumulative_SOC_deviation: 552.1557 Fuel Consumption: 1.9491\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 21.129\n",
      "Episode: 359 Exploration P: 0.0104 Total reward: -1546.9291956011243 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.8777\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.304\n",
      "Episode: 360 Exploration P: 0.0104 Total reward: -507.1738916537758 SOC: 0.5104 Cumulative_SOC_deviation: 50.5333 Fuel Consumption: 1.8408\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.370\n",
      "Episode: 361 Exploration P: 0.0104 Total reward: -1442.4818675540741 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6589\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.971\n",
      "Episode: 362 Exploration P: 0.0104 Total reward: -7816.259018989192 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.3104\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.118\n",
      "Episode: 363 Exploration P: 0.0104 Total reward: -5515.485236429753 SOC: -0.0307 Cumulative_SOC_deviation: 551.3267 Fuel Consumption: 2.2187\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.203\n",
      "Episode: 364 Exploration P: 0.0104 Total reward: -516.2958723551126 SOC: 0.5083 Cumulative_SOC_deviation: 51.4599 Fuel Consumption: 1.6964\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.055\n",
      "Episode: 365 Exploration P: 0.0103 Total reward: -520.8204383146564 SOC: 0.5068 Cumulative_SOC_deviation: 51.9220 Fuel Consumption: 1.6001\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 60.299\n",
      "Episode: 366 Exploration P: 0.0103 Total reward: -1632.4711973833523 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.4380\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.375\n",
      "Episode: 367 Exploration P: 0.0103 Total reward: -1654.6446450616133 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.2069\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.439\n",
      "Episode: 368 Exploration P: 0.0103 Total reward: -1441.6853510631277 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7648\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.802\n",
      "Episode: 369 Exploration P: 0.0103 Total reward: -1442.6156988286607 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6493\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.423\n",
      "Episode: 370 Exploration P: 0.0103 Total reward: -1438.0850201829317 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.8611\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.900\n",
      "Episode: 371 Exploration P: 0.0103 Total reward: -7814.545070101608 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.3104\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.491\n",
      "Episode: 372 Exploration P: 0.0103 Total reward: -1652.629344873746 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.1202\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.742\n",
      "Episode: 373 Exploration P: 0.0103 Total reward: -1438.3259568991002 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.8419\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.330\n",
      "Episode: 374 Exploration P: 0.0103 Total reward: -1649.051098011654 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.0914\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.606\n",
      "Episode: 375 Exploration P: 0.0103 Total reward: -7765.682103255455 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.7630\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 60.045\n",
      "Episode: 376 Exploration P: 0.0103 Total reward: -1655.5300320421134 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.1395\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.021\n",
      "Episode: 377 Exploration P: 0.0103 Total reward: -5517.954858443235 SOC: -0.0313 Cumulative_SOC_deviation: 551.5736 Fuel Consumption: 2.2187\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.484\n",
      "Episode: 378 Exploration P: 0.0103 Total reward: -1440.4039134374116 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7648\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 131.109\n",
      "Episode: 379 Exploration P: 0.0103 Total reward: -7796.225947654585 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6186\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.393\n",
      "Episode: 380 Exploration P: 0.0103 Total reward: -516.0122538160914 SOC: 0.5094 Cumulative_SOC_deviation: 51.4239 Fuel Consumption: 1.7734\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.382\n",
      "Episode: 381 Exploration P: 0.0103 Total reward: -1440.288490417664 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7648\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 131.124\n",
      "Episode: 382 Exploration P: 0.0103 Total reward: -7781.775896446903 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6956\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.903\n",
      "Episode: 383 Exploration P: 0.0103 Total reward: -7763.273761755683 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6667\n",
      "\n",
      "training\\06_udds_truck.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOC is nan...\n",
      "elapsed_time: 59.790\n",
      "Episode: 384 Exploration P: 0.0103 Total reward: -1652.1260748455925 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.1588\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.792\n",
      "Episode: 385 Exploration P: 0.0102 Total reward: -5538.219285670242 SOC: -0.0350 Cumulative_SOC_deviation: 553.6261 Fuel Consumption: 1.9587\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.839\n",
      "Episode: 386 Exploration P: 0.0102 Total reward: -1639.1873794029618 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.3706\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.467\n",
      "Episode: 387 Exploration P: 0.0102 Total reward: -483.4015176621905 SOC: 0.5127 Cumulative_SOC_deviation: 48.1378 Fuel Consumption: 2.0238\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.655\n",
      "Episode: 388 Exploration P: 0.0102 Total reward: -5525.551588371215 SOC: -0.0337 Cumulative_SOC_deviation: 552.3468 Fuel Consumption: 2.0839\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.308\n",
      "Episode: 389 Exploration P: 0.0102 Total reward: -1438.5729314855275 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.8515\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.625\n",
      "Episode: 390 Exploration P: 0.0102 Total reward: -537.0958717160772 SOC: 0.5088 Cumulative_SOC_deviation: 53.5351 Fuel Consumption: 1.7445\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.035\n",
      "Episode: 391 Exploration P: 0.0102 Total reward: -503.58413088011656 SOC: 0.5105 Cumulative_SOC_deviation: 50.1705 Fuel Consumption: 1.8793\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 60.125\n",
      "Episode: 392 Exploration P: 0.0102 Total reward: -1645.1648229472019 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.0721\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.527\n",
      "Episode: 393 Exploration P: 0.0102 Total reward: -7745.092975804543 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6571\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.922\n",
      "Episode: 394 Exploration P: 0.0102 Total reward: -5537.775777528587 SOC: -0.0362 Cumulative_SOC_deviation: 553.5884 Fuel Consumption: 1.8913\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.312\n",
      "Episode: 395 Exploration P: 0.0102 Total reward: -528.2352907186126 SOC: 0.5073 Cumulative_SOC_deviation: 52.6606 Fuel Consumption: 1.6290\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.280\n",
      "Episode: 396 Exploration P: 0.0102 Total reward: -5529.096882451355 SOC: -0.0340 Cumulative_SOC_deviation: 552.7061 Fuel Consumption: 2.0357\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 61.036\n",
      "Episode: 397 Exploration P: 0.0102 Total reward: -1646.9855405458677 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.1010\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.497\n",
      "Episode: 398 Exploration P: 0.0102 Total reward: -7806.265668817914 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.5223\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.503\n",
      "Episode: 399 Exploration P: 0.0102 Total reward: -529.3318916466745 SOC: 0.5066 Cumulative_SOC_deviation: 52.7761 Fuel Consumption: 1.5712\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.977\n",
      "Episode: 400 Exploration P: 0.0102 Total reward: -1651.1078457513295 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.1010\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.747\n",
      "Episode: 401 Exploration P: 0.0102 Total reward: -1442.840936099586 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6396\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.342\n",
      "Episode: 402 Exploration P: 0.0102 Total reward: -1439.4063610152775 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7456\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.574\n",
      "Episode: 403 Exploration P: 0.0102 Total reward: -1655.499153874428 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.0143\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.989\n",
      "Episode: 404 Exploration P: 0.0102 Total reward: -7789.070159726358 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.5415\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.655\n",
      "Episode: 405 Exploration P: 0.0102 Total reward: -7800.207802161613 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.4452\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.810\n",
      "Episode: 406 Exploration P: 0.0102 Total reward: -1441.6570079490348 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6974\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.012\n",
      "Episode: 407 Exploration P: 0.0102 Total reward: -510.75893762802764 SOC: 0.5097 Cumulative_SOC_deviation: 50.8957 Fuel Consumption: 1.8023\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.584\n",
      "Episode: 408 Exploration P: 0.0102 Total reward: -1441.8048849658094 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6878\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.432\n",
      "Episode: 409 Exploration P: 0.0102 Total reward: -1439.1397066902482 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7745\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.496\n",
      "Episode: 410 Exploration P: 0.0102 Total reward: -1440.7839040095037 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7648\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.298\n",
      "Episode: 411 Exploration P: 0.0102 Total reward: -1441.986882480221 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6974\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.070\n",
      "Episode: 412 Exploration P: 0.0102 Total reward: -525.49030751275 SOC: 0.5065 Cumulative_SOC_deviation: 52.3929 Fuel Consumption: 1.5616\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.528\n",
      "Episode: 413 Exploration P: 0.0102 Total reward: -1442.0619010393457 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7167\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.523\n",
      "Episode: 414 Exploration P: 0.0101 Total reward: -1636.5427403505546 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.2743\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.802\n",
      "Episode: 415 Exploration P: 0.0101 Total reward: -1439.7875382703587 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7648\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 131.274\n",
      "Episode: 416 Exploration P: 0.0101 Total reward: -7732.357278361088 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.7919\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 60.399\n",
      "Episode: 417 Exploration P: 0.0101 Total reward: -1653.68555523321 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.9758\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 58.758\n",
      "Episode: 418 Exploration P: 0.0101 Total reward: -1649.0843303584275 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.1395\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.150\n",
      "Episode: 419 Exploration P: 0.0101 Total reward: -533.3872421755821 SOC: 0.5067 Cumulative_SOC_deviation: 53.1806 Fuel Consumption: 1.5808\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.799\n",
      "Episode: 420 Exploration P: 0.0101 Total reward: -5508.574458937126 SOC: -0.0295 Cumulative_SOC_deviation: 550.6260 Fuel Consumption: 2.3149\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.428\n",
      "Episode: 421 Exploration P: 0.0101 Total reward: -5505.782476462251 SOC: -0.0328 Cumulative_SOC_deviation: 550.3699 Fuel Consumption: 2.0839\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 60.347\n",
      "Episode: 422 Exploration P: 0.0101 Total reward: -1635.332367380211 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.3224\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.368\n",
      "Episode: 423 Exploration P: 0.0101 Total reward: -522.7254888774913 SOC: 0.5079 Cumulative_SOC_deviation: 52.1058 Fuel Consumption: 1.6675\n",
      "\n",
      "training\\FTP_75_cycle.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOC is nan...\n",
      "elapsed_time: 130.539\n",
      "Episode: 424 Exploration P: 0.0101 Total reward: -7773.79363243948 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6378\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.209\n",
      "Episode: 425 Exploration P: 0.0101 Total reward: -5508.47067680565 SOC: -0.0354 Cumulative_SOC_deviation: 550.6551 Fuel Consumption: 1.9202\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.692\n",
      "Episode: 426 Exploration P: 0.0101 Total reward: -5505.244994435763 SOC: -0.0312 Cumulative_SOC_deviation: 550.3036 Fuel Consumption: 2.2090\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.062\n",
      "Episode: 427 Exploration P: 0.0101 Total reward: -5515.461266790177 SOC: -0.0325 Cumulative_SOC_deviation: 551.3368 Fuel Consumption: 2.0935\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.352\n",
      "Episode: 428 Exploration P: 0.0101 Total reward: -531.4068492812825 SOC: 0.5060 Cumulative_SOC_deviation: 52.9874 Fuel Consumption: 1.5327\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.361\n",
      "Episode: 429 Exploration P: 0.0101 Total reward: -1442.840936099586 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6396\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 60.282\n",
      "Episode: 430 Exploration P: 0.0101 Total reward: -1650.450256233263 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.1780\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.737\n",
      "Episode: 431 Exploration P: 0.0101 Total reward: -1653.6641214190238 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.0721\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 132.393\n",
      "Episode: 432 Exploration P: 0.0101 Total reward: -7824.100421776547 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.3778\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.416\n",
      "Episode: 433 Exploration P: 0.0101 Total reward: -5519.93981009922 SOC: -0.0309 Cumulative_SOC_deviation: 551.7702 Fuel Consumption: 2.2379\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.648\n",
      "Episode: 434 Exploration P: 0.0101 Total reward: -7740.5585128056755 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.8111\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.481\n",
      "Episode: 435 Exploration P: 0.0101 Total reward: -521.453229591622 SOC: 0.5076 Cumulative_SOC_deviation: 51.9815 Fuel Consumption: 1.6386\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.872\n",
      "Episode: 436 Exploration P: 0.0101 Total reward: -1441.125712329459 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.8419\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.768\n",
      "Episode: 437 Exploration P: 0.0101 Total reward: -5485.666397273998 SOC: -0.0282 Cumulative_SOC_deviation: 548.3303 Fuel Consumption: 2.3631\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.591\n",
      "Episode: 438 Exploration P: 0.0101 Total reward: -1438.4207019846076 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.8515\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.051\n",
      "Episode: 439 Exploration P: 0.0101 Total reward: -513.2944532375993 SOC: 0.5113 Cumulative_SOC_deviation: 51.1377 Fuel Consumption: 1.9178\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.322\n",
      "Episode: 440 Exploration P: 0.0101 Total reward: -542.4067233790257 SOC: 0.5050 Cumulative_SOC_deviation: 54.0961 Fuel Consumption: 1.4460\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.245\n",
      "Episode: 441 Exploration P: 0.0101 Total reward: -529.7016364679545 SOC: 0.5074 Cumulative_SOC_deviation: 52.8082 Fuel Consumption: 1.6194\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.777\n",
      "Episode: 442 Exploration P: 0.0101 Total reward: -5541.928401775398 SOC: -0.0343 Cumulative_SOC_deviation: 553.9902 Fuel Consumption: 2.0261\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.391\n",
      "Episode: 443 Exploration P: 0.0101 Total reward: -1629.7845923011923 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.4572\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.805\n",
      "Episode: 444 Exploration P: 0.0101 Total reward: -7807.521614458827 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6378\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.954\n",
      "Episode: 445 Exploration P: 0.0101 Total reward: -5482.82712219933 SOC: -0.0310 Cumulative_SOC_deviation: 548.0667 Fuel Consumption: 2.1598\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.854\n",
      "Episode: 446 Exploration P: 0.0101 Total reward: -538.8837742698959 SOC: 0.5057 Cumulative_SOC_deviation: 53.7390 Fuel Consumption: 1.4942\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.592\n",
      "Episode: 447 Exploration P: 0.0101 Total reward: -7733.045238609504 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 3.0133\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 60.690\n",
      "Episode: 448 Exploration P: 0.0101 Total reward: -1660.7604914779895 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.9084\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 60.286\n",
      "Episode: 449 Exploration P: 0.0101 Total reward: -1646.4122720575015 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.1780\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.454\n",
      "Episode: 450 Exploration P: 0.0101 Total reward: -5527.850317036733 SOC: -0.0325 Cumulative_SOC_deviation: 552.5738 Fuel Consumption: 2.1127\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.195\n",
      "Episode: 451 Exploration P: 0.0101 Total reward: -504.865628822939 SOC: 0.5101 Cumulative_SOC_deviation: 50.3034 Fuel Consumption: 1.8312\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.600\n",
      "Episode: 452 Exploration P: 0.0101 Total reward: -1440.4607706446122 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7552\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.966\n",
      "Episode: 453 Exploration P: 0.0101 Total reward: -7796.925108173121 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.4260\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 60.174\n",
      "Episode: 454 Exploration P: 0.0101 Total reward: -1638.5915949726118 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.3128\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.351\n",
      "Episode: 455 Exploration P: 0.0101 Total reward: -7757.343486798352 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6956\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.814\n",
      "Episode: 456 Exploration P: 0.0101 Total reward: -5497.230927786501 SOC: -0.0321 Cumulative_SOC_deviation: 549.5118 Fuel Consumption: 2.1127\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.226\n",
      "Episode: 457 Exploration P: 0.0101 Total reward: -549.8646334085252 SOC: 0.5027 Cumulative_SOC_deviation: 54.8592 Fuel Consumption: 1.2727\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.436\n",
      "Episode: 458 Exploration P: 0.0101 Total reward: -521.6111322710377 SOC: 0.5079 Cumulative_SOC_deviation: 51.9953 Fuel Consumption: 1.6579\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.046\n",
      "Episode: 459 Exploration P: 0.0101 Total reward: -5510.20268414503 SOC: -0.0293 Cumulative_SOC_deviation: 550.7849 Fuel Consumption: 2.3535\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.676\n",
      "Episode: 460 Exploration P: 0.0101 Total reward: -7761.5442569161 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6474\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 60.998\n",
      "Episode: 461 Exploration P: 0.0101 Total reward: -1648.4545520226843 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.0143\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.859\n",
      "Episode: 462 Exploration P: 0.0101 Total reward: -7797.75811704255 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.3757\n",
      "\n",
      "training\\07_manhattan.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.473\n",
      "Episode: 463 Exploration P: 0.0101 Total reward: -491.6659734806817 SOC: 0.5121 Cumulative_SOC_deviation: 48.9690 Fuel Consumption: 1.9756\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.970\n",
      "Episode: 464 Exploration P: 0.0101 Total reward: -510.6496343536915 SOC: 0.5096 Cumulative_SOC_deviation: 50.8867 Fuel Consumption: 1.7830\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 61.337\n",
      "Episode: 465 Exploration P: 0.0100 Total reward: -1651.53904518286 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.0625\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 60.262\n",
      "Episode: 466 Exploration P: 0.0100 Total reward: -1648.372027983482 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.1395\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.290\n",
      "Episode: 467 Exploration P: 0.0100 Total reward: -1442.0788494013477 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6782\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.242\n",
      "Episode: 468 Exploration P: 0.0100 Total reward: -1435.1365233250203 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.9381\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 130.375\n",
      "Episode: 469 Exploration P: 0.0100 Total reward: -7776.661230366098 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.5030\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.279\n",
      "Episode: 470 Exploration P: 0.0100 Total reward: -1440.2571472038321 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7456\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.521\n",
      "Episode: 471 Exploration P: 0.0100 Total reward: -1442.840936099586 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6396\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.980\n",
      "Episode: 472 Exploration P: 0.0100 Total reward: -5479.707083674303 SOC: -0.0288 Cumulative_SOC_deviation: 547.7354 Fuel Consumption: 2.3535\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.714\n",
      "Episode: 473 Exploration P: 0.0100 Total reward: -1639.9875276493076 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.2069\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.777\n",
      "Episode: 474 Exploration P: 0.0100 Total reward: -508.32169293916456 SOC: 0.5092 Cumulative_SOC_deviation: 50.6548 Fuel Consumption: 1.7734\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.316\n",
      "Episode: 475 Exploration P: 0.0100 Total reward: -510.3551616888048 SOC: 0.5101 Cumulative_SOC_deviation: 50.8524 Fuel Consumption: 1.8312\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.334\n",
      "Episode: 476 Exploration P: 0.0100 Total reward: -1442.1083100327078 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6782\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.258\n",
      "Episode: 477 Exploration P: 0.0100 Total reward: -525.9848119453393 SOC: 0.5080 Cumulative_SOC_deviation: 52.4308 Fuel Consumption: 1.6771\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 131.276\n",
      "Episode: 478 Exploration P: 0.0100 Total reward: -7763.035577209924 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.6667\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.035\n",
      "Episode: 479 Exploration P: 0.0100 Total reward: -5438.272575067667 SOC: -0.0262 Cumulative_SOC_deviation: 543.5794 Fuel Consumption: 2.4786\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.357\n",
      "Episode: 480 Exploration P: 0.0100 Total reward: -1441.27923077563 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6974\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 60.137\n",
      "Episode: 481 Exploration P: 0.0100 Total reward: -1647.8802292289954 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.1106\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.053\n",
      "Episode: 482 Exploration P: 0.0100 Total reward: -5488.32839316237 SOC: -0.0283 Cumulative_SOC_deviation: 548.5975 Fuel Consumption: 2.3535\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.538\n",
      "Episode: 483 Exploration P: 0.0100 Total reward: -1442.8660240125585 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6717\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.252\n",
      "Episode: 484 Exploration P: 0.0100 Total reward: -1439.2772716149186 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7937\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.002\n",
      "Episode: 485 Exploration P: 0.0100 Total reward: -526.6764257813018 SOC: 0.5072 Cumulative_SOC_deviation: 52.5067 Fuel Consumption: 1.6097\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 59.186\n",
      "Episode: 486 Exploration P: 0.0100 Total reward: -1648.655341641769 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.0721\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.435\n",
      "Episode: 487 Exploration P: 0.0100 Total reward: -5515.1547110655865 SOC: -0.0341 Cumulative_SOC_deviation: 551.3158 Fuel Consumption: 1.9972\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.305\n",
      "Episode: 488 Exploration P: 0.0100 Total reward: -1440.2887342323843 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7841\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.466\n",
      "Episode: 489 Exploration P: 0.0100 Total reward: -5512.00702986062 SOC: -0.0333 Cumulative_SOC_deviation: 550.9952 Fuel Consumption: 2.0550\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 19.145\n",
      "Episode: 490 Exploration P: 0.0100 Total reward: -1442.0694432501432 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7359\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 58.831\n",
      "Episode: 491 Exploration P: 0.0100 Total reward: -1651.122442393561 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.1588\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 122.028\n",
      "Episode: 492 Exploration P: 0.0100 Total reward: -5513.749981756265 SOC: -0.0309 Cumulative_SOC_deviation: 551.1522 Fuel Consumption: 2.2283\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 22.504\n",
      "Episode: 493 Exploration P: 0.0100 Total reward: -1441.8314385098377 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.7424\n",
      "\n",
      "training\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 147.132\n",
      "Episode: 494 Exploration P: 0.0100 Total reward: -7802.18220304284 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 2.5897\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 63.604\n",
      "Episode: 495 Exploration P: 0.0100 Total reward: -1654.2284874074553 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 1.1106\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.938\n",
      "Episode: 496 Exploration P: 0.0100 Total reward: -507.15100067081653 SOC: 0.5103 Cumulative_SOC_deviation: 50.5310 Fuel Consumption: 1.8408\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 124.533\n",
      "Episode: 497 Exploration P: 0.0100 Total reward: -5464.649416292948 SOC: -0.0258 Cumulative_SOC_deviation: 546.2132 Fuel Consumption: 2.5172\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.061\n",
      "Episode: 498 Exploration P: 0.0100 Total reward: -493.96641459013455 SOC: 0.5140 Cumulative_SOC_deviation: 49.1798 Fuel Consumption: 2.1682\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 127.203\n",
      "Episode: 499 Exploration P: 0.0100 Total reward: -5503.241819824574 SOC: -0.0309 Cumulative_SOC_deviation: 550.1081 Fuel Consumption: 2.1609\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 20.667\n",
      "Episode: 500 Exploration P: 0.0100 Total reward: -1442.5377274803482 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 0.6974\n",
      "\n",
      "model is saved..\n",
      "\n",
      "Trial 1\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 20.345\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -1017.380861679241 SOC: 0.8069 Cumulative_SOC_deviation: 95.7274 Fuel Consumption: 60.1073\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 20.068\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -1023.8080165850205 SOC: 0.8167 Cumulative_SOC_deviation: 96.3123 Fuel Consumption: 60.6851\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 16.201\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -2743.002381293935 SOC: 1.0000 Cumulative_SOC_deviation: 269.4500 Fuel Consumption: 48.5022\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 15.605\n",
      "Episode: 4 Exploration P: 1.0000 Total reward: -1045.4829551268763 SOC: 0.6690 Cumulative_SOC_deviation: 99.7176 Fuel Consumption: 48.3067\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 21.426\n",
      "Episode: 5 Exploration P: 1.0000 Total reward: -993.5790985272648 SOC: 0.8008 Cumulative_SOC_deviation: 93.4001 Fuel Consumption: 59.5777\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 21.308\n",
      "Episode: 6 Exploration P: 1.0000 Total reward: -1050.5270631716544 SOC: 0.8136 Cumulative_SOC_deviation: 99.0035 Fuel Consumption: 60.4925\n",
      "\n",
      "training\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 16.812\n",
      "Episode: 7 Exploration P: 1.0000 Total reward: -1033.7690120302964 SOC: 0.6683 Cumulative_SOC_deviation: 98.5299 Fuel Consumption: 48.4704\n",
      "\n",
      "training\\cudec_freeway.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 8.391\n",
      "Episode: 8 Exploration P: 1.0000 Total reward: -1728.3773711797164 SOC: 0.0681 Cumulative_SOC_deviation: 170.4429 Fuel Consumption: 23.9488\n",
      "\n",
      "training\\07_manhattan.mat\n",
      "WARNING:tensorflow:Layer batch_normalization_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 41.770\n",
      "Episode: 9 Exploration P: 0.9934 Total reward: -2686.866213977116 SOC: 1.0000 Cumulative_SOC_deviation: 263.9683 Fuel Consumption: 47.1831\n",
      "\n",
      "training\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.062\n",
      "Episode: 10 Exploration P: 0.9668 Total reward: -903.0509938141134 SOC: 0.7634 Cumulative_SOC_deviation: 84.6092 Fuel Consumption: 56.9587\n",
      "\n",
      "training\\06_udds_truck.mat\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5fa21cf5e743>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mDELAY_TRAINING\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[0mupdate_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                 eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
      "\u001b[1;32m<ipython-input-4-4679c004126e>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactor_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mcritic_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcritic_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mactor_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcritic_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mactor_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactor_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactor_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_merge_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36m_merge_function\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(tensors, axis)\u001b[0m\n\u001b[0;32m   2706\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_concat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2707\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2708\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1429\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[0;32m   1430\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1431\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1234\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   1235\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ConcatV2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m         name, _ctx._post_execution_callbacks, values, axis)\n\u001b[0m\u001b[0;32m   1237\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(env.version)\n",
    "\n",
    "num_trials = 3\n",
    "results_dict = {} \n",
    "driving_cycle_paths = glob.glob(\"training/*.mat\")\n",
    "# driving_cycle_paths.pop(1)\n",
    "driving_cycle_paths = driving_cycle_paths[:5]\n",
    "\n",
    "for trial in range(num_trials): \n",
    "    print(\"\")\n",
    "    print(\"Trial {}\".format(trial))\n",
    "    print(\"\")\n",
    "    \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer = initialization()\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    for ep in range(total_episodes): \n",
    "        driving_cycle_path = np.random.choice(driving_cycle_paths)\n",
    "        print(driving_cycle_path)\n",
    "        env = initialization_env(driving_cycle_path, 10)\n",
    "        \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
    "                                                                        -DELAY_TRAINING))\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_SOCs.append(env.SOC)\n",
    "        episode_FCs.append(env.fuel_consumption) \n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        print(\n",
    "              'Episode: {}'.format(ep + 1),\n",
    "              \"Exploration P: {:.4f}\".format(eps),\n",
    "              'Total reward: {}'.format(episodic_reward), \n",
    "              \"SOC: {:.4f}\".format(env.SOC), \n",
    "              \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "              \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "        )\n",
    "        print(\"\")\n",
    "    \n",
    "    root = \"DDPG4_trial{}\".format(trial+1)\n",
    "    save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "    \n",
    "    results_dict[trial + 1] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDPG4.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
