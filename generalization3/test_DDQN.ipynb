{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "\n",
    "from vehicle_model_DDQN1 import Environment \n",
    "from cell_model import CellModel \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_nimh_6_240_panasonic_MY01_Prius.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_id_75_110_Westinghouse.mat\"\n",
    "cell_model = CellModel()\n",
    "env = Environment(cell_model, drving_cycle, battery_path, motor_path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_SIZE = 4\n",
    "ACTION_SIZE = env.calculation_comp[\"action_size\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_network = keras.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[STATE_SIZE],  \n",
    "                       kernel_initializer=keras.initializers.he_normal()), \n",
    "#     keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(30, activation=\"relu\", kernel_initializer=keras.initializers.he_normal()),\n",
    "#     keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(ACTION_SIZE),\n",
    "])\n",
    "target_network = keras.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[STATE_SIZE],\n",
    "                       kernel_initializer=keras.initializers.he_normal()), \n",
    "#     keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(30, activation=\"relu\", kernel_initializer=keras.initializers.he_normal()),\n",
    "#     keras.layers.BatchNormalization(), \n",
    "    keras.layers.Dense(ACTION_SIZE),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cycle(model_path, driving_path): \n",
    "    env = Environment(cell_model, driving_path, battery_path, motor_path, 10)\n",
    "    primary_network.load_weights(model_path)\n",
    "    \n",
    "    \n",
    "    total_reward = 0 \n",
    "    state = env.reset() \n",
    "    while True: \n",
    "        action = np.argmax(primary_network(np.array(state).reshape(1, -1))) \n",
    "        next_state, reward, done = env.step(action)\n",
    "        \n",
    "        if done: \n",
    "            break \n",
    "            \n",
    "        state = next_state\n",
    "        total_reward += reward \n",
    "        \n",
    "    print(\"Test is done...\")\n",
    "    print(\"Total reward is {:.4f}\".format(total_reward))\n",
    "        \n",
    "    return env \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Constraint error, battery current limit ( motor mode )\n",
      "Constraint error, battery current limit ( motor mode )"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment\\generalization1\\vehicle_model_DDQN1.py:240: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n",
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment\\generalization1\\vehicle_model_DDQN1.py:241: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  2 * r_dis)) * (v_dis - (v_dis ** 2 - 4 * r_dis * p_bat) ** (0.5)) * (p_bat >= 0)\n",
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment\\generalization1\\vehicle_model_DDQN1.py:266: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n",
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment\\generalization1\\vehicle_model_DDQN1.py:267: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  2 * r_dis)) * (v_dis - (v_dis ** 2 - 4 * r_dis * p_bat) ** (0.5)) * (p_bat >= 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "maximum steps, simulation is done ... \n",
      "Test is done...\n",
      "Total reward is nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22011235b70>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"./DDQN1_trial1/primary_net_checkpoint\" \n",
    "driving_path = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/us06_hwy.mat'\n",
    "\n",
    "env = test_cycle(model_path, driving_path)\n",
    "\n",
    "plt.plot(env.history[\"SOC\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state, primary_network, eps): \n",
    "    if random.random() < eps: \n",
    "        return random.randint(0, ACTION_SIZE - 1)\n",
    "    else: \n",
    "        return np.argmax(primary_network(np.array(state).reshape(1, -1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(primary_network, target_network, memory): \n",
    "    batch = memory.sample(BATCH_SIZE)\n",
    "    states = np.array([val[0] for val in batch]) \n",
    "    actions = np.array([val[1] for val in batch])\n",
    "    rewards = np.array([val[2] for val in batch])\n",
    "    next_states = np.array([np.zeros(STATE_SIZE) if val[3] is None else val[3]  \n",
    "                            for val in batch])\n",
    "    \n",
    "    prim_qt = primary_network(states)\n",
    "    prim_qtp1 = primary_network(next_states)\n",
    "    target_q = prim_qt.numpy() \n",
    "    updates = rewards \n",
    "    valid_idxs = next_states.sum(axis=1) != 0 \n",
    "    batch_idxs = np.arange(BATCH_SIZE)\n",
    "    prim_action_tp1 = np.argmax(prim_qtp1.numpy(), axis=1)\n",
    "    q_from_target = target_network(next_states)\n",
    "    updates[valid_idxs] += GAMMA * q_from_target.numpy()[batch_idxs[valid_idxs], \n",
    "                                                        prim_action_tp1[valid_idxs]]\n",
    "    \n",
    "    target_q[batch_idxs, actions] = updates \n",
    "    loss = primary_network.train_on_batch(states, target_q)\n",
    "    return loss \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_with_rewardFactor(reward_factor):\n",
    "    env = Environment(cell_model, drving_cycle, battery_path, motor_path, reward_factor)\n",
    "    \n",
    "    memory = Memory(10000)\n",
    "    \n",
    "    primary_network = keras.Sequential([\n",
    "        keras.layers.Dense(30, activation=\"relu\", input_shape=[STATE_SIZE], \n",
    "                           kernel_initializer=keras.initializers.he_normal()),\n",
    "#         keras.layers.BatchNormalization(),  \n",
    "        keras.layers.Dense(30, activation=\"relu\", kernel_initializer=keras.initializers.he_normal()),\n",
    "#         keras.layers.BatchNormalization(), \n",
    "        keras.layers.Dense(ACTION_SIZE),\n",
    "    ])\n",
    "    target_network = keras.Sequential([\n",
    "        keras.layers.Dense(30, activation=\"relu\", input_shape=[STATE_SIZE], \n",
    "                           kernel_initializer=keras.initializers.he_normal()), \n",
    "#         keras.layers.BatchNormalization(), \n",
    "        keras.layers.Dense(30, activation=\"relu\", kernel_initializer=keras.initializers.he_normal()),\n",
    "#         keras.layers.BatchNormalization(), \n",
    "        keras.layers.Dense(ACTION_SIZE),\n",
    "    ])\n",
    "    primary_network.compile(\n",
    "        loss=\"mse\", \n",
    "        optimizer=keras.optimizers.Adam(lr=LEARNING_RATE) \n",
    "    )\n",
    "    return env, memory, primary_network, target_network \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(primary_net, target_net, root): \n",
    "    primary_net.save_weights(\"./{}/primary_net_checkpoint\".format(root))\n",
    "    target_net.save_weights(\"./{}/target_net_checkpoint\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment version: 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MAX_EPSILON' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c199291c6fb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward_factor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward_factors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMAX_EPSILON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mepisode_rewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MAX_EPSILON' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"environment version: {}\".format(env.version)) \n",
    "\n",
    " \n",
    "reward_factors = [10] * 2\n",
    "results_dict = {} \n",
    "\n",
    "for trial, reward_factor in enumerate(reward_factors): \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    \n",
    "    env, memory, primary_network, target_network = initialization_with_rewardFactor(reward_factor)\n",
    "    for episode in range(TOTAL_EPISODES): \n",
    "        state = env.reset() \n",
    "        avg_loss = 0 \n",
    "        total_reward = 0\n",
    "        cnt = 1 \n",
    "\n",
    "        while True:\n",
    "            action = choose_action(state, primary_network, eps)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            total_reward += reward \n",
    "            if done: \n",
    "                next_state = None \n",
    "            memory.add_sample((state, action, reward, next_state))\n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                loss = train(primary_network, target_network, memory)\n",
    "                update_network(primary_network, target_network)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * steps)\n",
    "            else: \n",
    "                loss = -1\n",
    "\n",
    "            avg_loss += loss \n",
    "            steps += 1 \n",
    "\n",
    "            if done: \n",
    "                if steps > DELAY_TRAINING: \n",
    "                    SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "                    avg_loss /= cnt \n",
    "                    print('Episode: {}'.format(episode + 1),\n",
    "                          'Total reward: {}'.format(total_reward), \n",
    "                          'Explore P: {:.4f}'.format(eps), \n",
    "                          \"SOC: {:.4f}\".format(env.SOC), \n",
    "                         \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "                         \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "                         )\n",
    "                else: \n",
    "                    print(f\"Pre-training...Episode: {episode}\")\n",
    "                \n",
    "                episode_rewards.append(total_reward)\n",
    "                episode_SOCs.append(env.SOC)\n",
    "                episode_FCs.append(env.fuel_consumption)\n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "            cnt += 1 \n",
    "    \n",
    "    root = \"DDQN1_trial{}\".format(trial+2)\n",
    "    save_weights(primary_network, target_network, root)\n",
    "    \n",
    "    results_dict[reward_factor] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs \n",
    "    }\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDQN1.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"results/replay_memory_size_effect.pkl\", \"rb\") as f: \n",
    "#     data = pickle.load(f)\n",
    "    \n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
