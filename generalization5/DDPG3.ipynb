{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "\n",
    "from vehicle_model_DDPG1 import Environment \n",
    "from cell_model import CellModel \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_nimh_6_240_panasonic_MY01_Prius.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_pm_95_145_X2.mat\"\n",
    "cell_model = CellModel()\n",
    "env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):      \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    inputs_batchnorm = layers.BatchNormalization()(inputs)\n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs_batchnorm)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_input_batchnorm = layers.BatchNormalization()(state_input)\n",
    "    \n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input_batchnorm)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 300\n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 10000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "\n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_model, critic_model, target_actor, target_critic, root): \n",
    "    actor_model.save_weights(\"./{}/actor_model_checkpoint\".format(root))\n",
    "    critic_model.save_weights(\"./{}/critic_model_checkpoint\".format(root))\n",
    "    target_actor.save_weights(\"./{}/target_actor_checkpoint\".format(root))\n",
    "    target_critic.save_weights(\"./{}/target_critic_checkpoint\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_env(driving_path, reward_factor):\n",
    "    env = Environment(cell_model, driving_path, battery_path, motor_path, reward_factor)\n",
    "    return env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(actor_model, reward_factor, test_path_start):\n",
    "    test_cycles = glob.glob(\"../data/driving_cycles/city/*.mat\")[test_path_start:]\n",
    "    test_cycle = np.random.choice(test_cycles)\n",
    "    env = initialization_env(test_cycle, reward_factor)\n",
    "    \n",
    "    total_reward = 0\n",
    "    state = env.reset() \n",
    "    while True: \n",
    "        tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "        action = policy_epsilon_greedy(tf_state, -1)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        \n",
    "        state = next_state \n",
    "        total_reward += reward \n",
    "        \n",
    "        if done: \n",
    "            break \n",
    "        \n",
    "    SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "    \n",
    "    print(\"******************* Test is start *****************\")\n",
    "    print(test_cycle)\n",
    "    print('Total reward: {}'.format(total_reward), \n",
    "          \"SOC: {:.4f}\".format(env.SOC), \n",
    "          \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "          \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption))\n",
    "    print(\"******************* Test is done *****************\")\n",
    "    print(\"\")\n",
    "    return env.history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "Trial 0\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 13.551\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -3888.440468935018 SOC: 1.0000 Cumulative_SOC_deviation: 376.4943 Fuel Consumption: 123.4976\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.742\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -3876.445887686777 SOC: 1.0000 Cumulative_SOC_deviation: 375.6155 Fuel Consumption: 120.2914\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 13.157\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -3913.223848436321 SOC: 1.0000 Cumulative_SOC_deviation: 379.1706 Fuel Consumption: 121.5181\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 13.374\n",
      "Episode: 4 Exploration P: 1.0000 Total reward: -3855.2939238575764 SOC: 1.0000 Cumulative_SOC_deviation: 373.7327 Fuel Consumption: 117.9671\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 15.671\n",
      "Episode: 5 Exploration P: 1.0000 Total reward: -3840.529718291666 SOC: 1.0000 Cumulative_SOC_deviation: 372.0991 Fuel Consumption: 119.5387\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 19.879\n",
      "Episode: 6 Exploration P: 1.0000 Total reward: -4592.3553023259565 SOC: 1.0000 Cumulative_SOC_deviation: 444.0663 Fuel Consumption: 151.6918\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 15.283\n",
      "Episode: 7 Exploration P: 1.0000 Total reward: -3742.845973785058 SOC: 1.0000 Cumulative_SOC_deviation: 362.1577 Fuel Consumption: 121.2690\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 15.195\n",
      "Episode: 8 Exploration P: 1.0000 Total reward: -3713.4089870257217 SOC: 1.0000 Cumulative_SOC_deviation: 359.1393 Fuel Consumption: 122.0160\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "WARNING:tensorflow:Layer batch_normalization_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 34.272\n",
      "Episode: 9 Exploration P: 0.9937 Total reward: -4695.351531795661 SOC: 1.0000 Cumulative_SOC_deviation: 453.9922 Fuel Consumption: 155.4296\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.773\n",
      "Episode: 10 Exploration P: 0.9575 Total reward: -6704.272962855098 SOC: 1.0000 Cumulative_SOC_deviation: 649.5137 Fuel Consumption: 209.1364\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.494\n",
      "Episode: 11 Exploration P: 0.9376 Total reward: -3608.0876875336444 SOC: 1.0000 Cumulative_SOC_deviation: 349.3567 Fuel Consumption: 114.5203\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.351\n",
      "Episode: 12 Exploration P: 0.9125 Total reward: -4550.71558152474 SOC: 1.0000 Cumulative_SOC_deviation: 440.3710 Fuel Consumption: 147.0060\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.598\n",
      "Episode: 13 Exploration P: 0.8881 Total reward: -4381.615455765154 SOC: 1.0000 Cumulative_SOC_deviation: 424.4171 Fuel Consumption: 137.4447\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.774\n",
      "Episode: 14 Exploration P: 0.8702 Total reward: -3608.3878705192215 SOC: 1.0000 Cumulative_SOC_deviation: 350.7171 Fuel Consumption: 101.2174\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.284\n",
      "Episode: 15 Exploration P: 0.8518 Total reward: -3802.5424360991024 SOC: 1.0000 Cumulative_SOC_deviation: 370.1571 Fuel Consumption: 100.9719\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.700\n",
      "Episode: 16 Exploration P: 0.8290 Total reward: -4136.7135788097185 SOC: 1.0000 Cumulative_SOC_deviation: 400.7618 Fuel Consumption: 129.0958\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.219\n",
      "Episode: 17 Exploration P: 0.8123 Total reward: -3576.3909814683825 SOC: 1.0000 Cumulative_SOC_deviation: 347.9420 Fuel Consumption: 96.9711\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.587\n",
      "Episode: 18 Exploration P: 0.7905 Total reward: -3997.888449295881 SOC: 1.0000 Cumulative_SOC_deviation: 387.6647 Fuel Consumption: 121.2410\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.193\n",
      "Episode: 19 Exploration P: 0.7746 Total reward: -3465.3433849452986 SOC: 1.0000 Cumulative_SOC_deviation: 337.5463 Fuel Consumption: 89.8806\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.547\n",
      "Episode: 20 Exploration P: 0.7581 Total reward: -3707.042761888669 SOC: 1.0000 Cumulative_SOC_deviation: 361.1183 Fuel Consumption: 95.8595\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.098\n",
      "Episode: 21 Exploration P: 0.7429 Total reward: -3412.927332538614 SOC: 1.0000 Cumulative_SOC_deviation: 332.7738 Fuel Consumption: 85.1890\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.043\n",
      "Episode: 22 Exploration P: 0.7275 Total reward: -3077.954226827811 SOC: 1.0000 Cumulative_SOC_deviation: 299.1497 Fuel Consumption: 86.4570\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.099\n",
      "Episode: 23 Exploration P: 0.7124 Total reward: -3123.2517114079265 SOC: 1.0000 Cumulative_SOC_deviation: 303.4545 Fuel Consumption: 88.7066\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.577\n",
      "Episode: 24 Exploration P: 0.6974 Total reward: -3625.4674878978035 SOC: 1.0000 Cumulative_SOC_deviation: 353.8409 Fuel Consumption: 87.0580\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.680\n",
      "Episode: 25 Exploration P: 0.6834 Total reward: -3429.156778185509 SOC: 1.0000 Cumulative_SOC_deviation: 335.0541 Fuel Consumption: 78.6156\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.756\n",
      "Episode: 26 Exploration P: 0.6689 Total reward: -3594.9667032043617 SOC: 1.0000 Cumulative_SOC_deviation: 351.2330 Fuel Consumption: 82.6365\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.944\n",
      "Episode: 27 Exploration P: 0.6447 Total reward: -5491.880108189376 SOC: 1.0000 Cumulative_SOC_deviation: 534.6018 Fuel Consumption: 145.8617\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.491\n",
      "Episode: 28 Exploration P: 0.6318 Total reward: -3402.595189097909 SOC: 1.0000 Cumulative_SOC_deviation: 332.5453 Fuel Consumption: 77.1417\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.817\n",
      "Episode: 29 Exploration P: 0.6184 Total reward: -3494.7346545486052 SOC: 1.0000 Cumulative_SOC_deviation: 341.5304 Fuel Consumption: 79.4302\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.568\n",
      "Episode: 30 Exploration P: 0.6053 Total reward: -3375.700366313682 SOC: 1.0000 Cumulative_SOC_deviation: 329.9840 Fuel Consumption: 75.8607\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.712\n",
      "Episode: 31 Exploration P: 0.5925 Total reward: -3352.1244770660865 SOC: 1.0000 Cumulative_SOC_deviation: 328.0496 Fuel Consumption: 71.6288\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.331\n",
      "Episode: 32 Exploration P: 0.5799 Total reward: -3456.1265322147274 SOC: 1.0000 Cumulative_SOC_deviation: 338.2317 Fuel Consumption: 73.8093\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.180\n",
      "Episode: 33 Exploration P: 0.5676 Total reward: -3460.2433826911474 SOC: 1.0000 Cumulative_SOC_deviation: 338.7296 Fuel Consumption: 72.9475\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.030\n",
      "Episode: 34 Exploration P: 0.5556 Total reward: -3350.7483588467294 SOC: 1.0000 Cumulative_SOC_deviation: 328.1361 Fuel Consumption: 69.3878\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.170\n",
      "Episode: 35 Exploration P: 0.5445 Total reward: -3134.1879827041494 SOC: 1.0000 Cumulative_SOC_deviation: 307.0265 Fuel Consumption: 63.9231\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.457\n",
      "Episode: 36 Exploration P: 0.5330 Total reward: -3308.439149288743 SOC: 1.0000 Cumulative_SOC_deviation: 323.8537 Fuel Consumption: 69.9021\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.774\n",
      "Episode: 37 Exploration P: 0.5218 Total reward: -3293.858045370592 SOC: 1.0000 Cumulative_SOC_deviation: 322.4696 Fuel Consumption: 69.1622\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.268\n",
      "Episode: 38 Exploration P: 0.5079 Total reward: -2477.3646668603546 SOC: 1.0000 Cumulative_SOC_deviation: 239.1151 Fuel Consumption: 86.2136\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.544\n",
      "Episode: 39 Exploration P: 0.4974 Total reward: -1724.931613346251 SOC: 0.8439 Cumulative_SOC_deviation: 165.9513 Fuel Consumption: 65.4181\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.496\n",
      "Episode: 40 Exploration P: 0.4875 Total reward: -2961.6454646010784 SOC: 1.0000 Cumulative_SOC_deviation: 290.4422 Fuel Consumption: 57.2233\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.021\n",
      "Episode: 41 Exploration P: 0.4778 Total reward: -2998.545928707319 SOC: 1.0000 Cumulative_SOC_deviation: 294.1383 Fuel Consumption: 57.1630\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.206\n",
      "Episode: 42 Exploration P: 0.4677 Total reward: -3085.8749526754323 SOC: 1.0000 Cumulative_SOC_deviation: 302.5342 Fuel Consumption: 60.5333\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.935\n",
      "Episode: 43 Exploration P: 0.4579 Total reward: -3231.1837581164987 SOC: 1.0000 Cumulative_SOC_deviation: 316.8293 Fuel Consumption: 62.8904\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.730\n",
      "Episode: 44 Exploration P: 0.4482 Total reward: -3035.4085043628706 SOC: 1.0000 Cumulative_SOC_deviation: 297.6774 Fuel Consumption: 58.6342\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.299\n",
      "Episode: 45 Exploration P: 0.4388 Total reward: -3033.1753394742796 SOC: 1.0000 Cumulative_SOC_deviation: 297.6809 Fuel Consumption: 56.3659\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.346\n",
      "Episode: 46 Exploration P: 0.4297 Total reward: -2928.3984895002072 SOC: 1.0000 Cumulative_SOC_deviation: 287.5414 Fuel Consumption: 52.9844\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.150\n",
      "Episode: 47 Exploration P: 0.4211 Total reward: -2711.8371303213485 SOC: 1.0000 Cumulative_SOC_deviation: 265.9182 Fuel Consumption: 52.6553\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.544\n",
      "Episode: 48 Exploration P: 0.4122 Total reward: -3102.973525834929 SOC: 1.0000 Cumulative_SOC_deviation: 304.6031 Fuel Consumption: 56.9420\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.065\n",
      "Episode: 49 Exploration P: 0.4036 Total reward: -2765.2095760431966 SOC: 1.0000 Cumulative_SOC_deviation: 271.3403 Fuel Consumption: 51.8065\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.173\n",
      "Episode: 50 Exploration P: 0.3891 Total reward: -2637.2954040283403 SOC: 0.8145 Cumulative_SOC_deviation: 254.3254 Fuel Consumption: 94.0417\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.518\n",
      "Episode: 51 Exploration P: 0.3789 Total reward: -923.4100790039976 SOC: 0.7507 Cumulative_SOC_deviation: 86.3188 Fuel Consumption: 60.2217\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.695\n",
      "Episode: 52 Exploration P: 0.3653 Total reward: -1813.967561736504 SOC: 0.6932 Cumulative_SOC_deviation: 172.9869 Fuel Consumption: 84.0983\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.778\n",
      "Episode: 53 Exploration P: 0.3578 Total reward: -1027.8539855873648 SOC: 0.5922 Cumulative_SOC_deviation: 98.1765 Fuel Consumption: 46.0887\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.084\n",
      "Episode: 54 Exploration P: 0.3450 Total reward: -1380.8978127714663 SOC: 0.6560 Cumulative_SOC_deviation: 129.9670 Fuel Consumption: 81.2282\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.790\n",
      "Episode: 55 Exploration P: 0.3327 Total reward: -1261.207200877926 SOC: 0.6139 Cumulative_SOC_deviation: 118.2384 Fuel Consumption: 78.8235\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.286\n",
      "Episode: 56 Exploration P: 0.3257 Total reward: -2340.200023493141 SOC: 1.0000 Cumulative_SOC_deviation: 229.6373 Fuel Consumption: 43.8269\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.002\n",
      "Episode: 57 Exploration P: 0.3141 Total reward: -1241.2424077521407 SOC: 0.5877 Cumulative_SOC_deviation: 116.4476 Fuel Consumption: 76.7664\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.707\n",
      "Episode: 58 Exploration P: 0.3079 Total reward: -2295.5066034112906 SOC: 0.9707 Cumulative_SOC_deviation: 225.4791 Fuel Consumption: 40.7152\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.227\n",
      "Episode: 59 Exploration P: 0.3019 Total reward: -1961.9375535177728 SOC: 0.9253 Cumulative_SOC_deviation: 192.5308 Fuel Consumption: 36.6298\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.179\n",
      "Episode: 60 Exploration P: 0.2959 Total reward: -2256.933097250249 SOC: 0.9559 Cumulative_SOC_deviation: 221.7568 Fuel Consumption: 39.3649\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.207\n",
      "Episode: 61 Exploration P: 0.2901 Total reward: -1971.2510435634274 SOC: 0.9301 Cumulative_SOC_deviation: 193.4004 Fuel Consumption: 37.2475\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.676\n",
      "Episode: 62 Exploration P: 0.2798 Total reward: -2096.4938653352265 SOC: 0.4041 Cumulative_SOC_deviation: 203.3340 Fuel Consumption: 63.1542\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.616\n",
      "Episode: 63 Exploration P: 0.2739 Total reward: -1903.766552938721 SOC: 0.9637 Cumulative_SOC_deviation: 186.5327 Fuel Consumption: 38.4400\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.727\n",
      "Episode: 64 Exploration P: 0.2683 Total reward: -2068.5474590001627 SOC: 0.9676 Cumulative_SOC_deviation: 202.9757 Fuel Consumption: 38.7905\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.793\n",
      "Episode: 65 Exploration P: 0.2613 Total reward: -1643.035622457997 SOC: 0.5438 Cumulative_SOC_deviation: 159.9084 Fuel Consumption: 43.9520\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.385\n",
      "Episode: 66 Exploration P: 0.2520 Total reward: -2591.0890558548545 SOC: 0.3392 Cumulative_SOC_deviation: 253.2098 Fuel Consumption: 58.9913\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.321\n",
      "Episode: 67 Exploration P: 0.2471 Total reward: -1232.7116773891487 SOC: 0.8009 Cumulative_SOC_deviation: 120.6399 Fuel Consumption: 26.3129\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.182\n",
      "Episode: 68 Exploration P: 0.2420 Total reward: -1777.3021926611582 SOC: 0.8835 Cumulative_SOC_deviation: 174.2515 Fuel Consumption: 34.7869\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.472\n",
      "Episode: 69 Exploration P: 0.2357 Total reward: -1534.266089308882 SOC: 0.5551 Cumulative_SOC_deviation: 148.9875 Fuel Consumption: 44.3915\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.808\n",
      "Episode: 70 Exploration P: 0.2274 Total reward: -3363.5465292658055 SOC: 0.2248 Cumulative_SOC_deviation: 331.3519 Fuel Consumption: 50.0276\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.852\n",
      "Episode: 71 Exploration P: 0.2228 Total reward: -1349.968859906485 SOC: 0.3793 Cumulative_SOC_deviation: 131.9822 Fuel Consumption: 30.1465\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.407\n",
      "Episode: 72 Exploration P: 0.2183 Total reward: -1509.6201362604183 SOC: 0.8376 Cumulative_SOC_deviation: 147.8763 Fuel Consumption: 30.8566\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.838\n",
      "Episode: 73 Exploration P: 0.2138 Total reward: -1502.1000803103666 SOC: 0.8522 Cumulative_SOC_deviation: 147.2802 Fuel Consumption: 29.2982\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.221\n",
      "Episode: 74 Exploration P: 0.2096 Total reward: -1337.0039589843361 SOC: 0.8229 Cumulative_SOC_deviation: 130.8571 Fuel Consumption: 28.4332\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.608\n",
      "Episode: 75 Exploration P: 0.2053 Total reward: -1572.762029711248 SOC: 0.8856 Cumulative_SOC_deviation: 154.0749 Fuel Consumption: 32.0132\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.777\n",
      "Episode: 76 Exploration P: 0.1981 Total reward: -4234.71417576691 SOC: 0.1608 Cumulative_SOC_deviation: 418.9134 Fuel Consumption: 45.5802\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.994\n",
      "Episode: 77 Exploration P: 0.1941 Total reward: -1397.4469318962854 SOC: 0.8555 Cumulative_SOC_deviation: 136.7994 Fuel Consumption: 29.4533\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.092\n",
      "Episode: 78 Exploration P: 0.1891 Total reward: -2445.4395956160356 SOC: 0.4106 Cumulative_SOC_deviation: 241.1905 Fuel Consumption: 33.5345\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.290\n",
      "Episode: 79 Exploration P: 0.1855 Total reward: -1207.1617506860327 SOC: 0.7804 Cumulative_SOC_deviation: 118.2064 Fuel Consumption: 25.0976\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.925\n",
      "Episode: 80 Exploration P: 0.1817 Total reward: -1435.0834200312358 SOC: 0.8569 Cumulative_SOC_deviation: 140.5630 Fuel Consumption: 29.4533\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.735\n",
      "Episode: 81 Exploration P: 0.1781 Total reward: -1407.2099749903314 SOC: 0.3180 Cumulative_SOC_deviation: 138.1496 Fuel Consumption: 25.7135\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.194\n",
      "Episode: 82 Exploration P: 0.1745 Total reward: -981.0225732212042 SOC: 0.7377 Cumulative_SOC_deviation: 95.8363 Fuel Consumption: 22.6600\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.147\n",
      "Episode: 83 Exploration P: 0.1700 Total reward: -2896.0860250783794 SOC: 0.3619 Cumulative_SOC_deviation: 286.6002 Fuel Consumption: 30.0841\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.357\n",
      "Episode: 84 Exploration P: 0.1667 Total reward: -1451.8045487898164 SOC: 0.3039 Cumulative_SOC_deviation: 142.7539 Fuel Consumption: 24.2655\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.462\n",
      "Episode: 85 Exploration P: 0.1633 Total reward: -987.9532302220714 SOC: 0.7381 Cumulative_SOC_deviation: 96.5086 Fuel Consumption: 22.8669\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.519\n",
      "Episode: 86 Exploration P: 0.1591 Total reward: -3086.9280265759458 SOC: 0.3185 Cumulative_SOC_deviation: 306.0119 Fuel Consumption: 26.8089\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RECL\\Desktop\\Song\\graduate_paper\\program\\experiment\\generalization5\\vehicle_model_DDPG1.py:251: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n",
      "C:\\Users\\RECL\\Desktop\\Song\\graduate_paper\\program\\experiment\\generalization5\\vehicle_model_DDPG1.py:277: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOC is nan...\n",
      "elapsed_time: 99.261\n",
      "Episode: 87 Exploration P: 0.1543 Total reward: -13914.536230282776 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 34.1924\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.976\n",
      "Episode: 88 Exploration P: 0.1504 Total reward: -3088.8010402309365 SOC: 0.3221 Cumulative_SOC_deviation: 306.1811 Fuel Consumption: 26.9899\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.965\n",
      "Episode: 89 Exploration P: 0.1474 Total reward: -761.9203354749645 SOC: 0.7469 Cumulative_SOC_deviation: 74.1232 Fuel Consumption: 20.6878\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.890\n",
      "Episode: 90 Exploration P: 0.1444 Total reward: -950.8744087208106 SOC: 0.7672 Cumulative_SOC_deviation: 92.8661 Fuel Consumption: 22.2134\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.426\n",
      "Episode: 91 Exploration P: 0.1416 Total reward: -1717.5125119614472 SOC: 0.2148 Cumulative_SOC_deviation: 169.9162 Fuel Consumption: 18.3500\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.701\n",
      "Episode: 92 Exploration P: 0.1388 Total reward: -750.0361948655711 SOC: 0.7372 Cumulative_SOC_deviation: 73.0176 Fuel Consumption: 19.8604\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.840\n",
      "Episode: 93 Exploration P: 0.1360 Total reward: -611.5908820060187 SOC: 0.7122 Cumulative_SOC_deviation: 59.3773 Fuel Consumption: 17.8177\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.632\n",
      "Episode: 94 Exploration P: 0.1326 Total reward: -3382.360728705887 SOC: 0.2899 Cumulative_SOC_deviation: 335.7686 Fuel Consumption: 24.6742\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.784\n",
      "Episode: 95 Exploration P: 0.1292 Total reward: -3121.372948684968 SOC: 0.3046 Cumulative_SOC_deviation: 309.5495 Fuel Consumption: 25.8780\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.290\n",
      "Episode: 96 Exploration P: 0.1267 Total reward: -1760.0616820134558 SOC: 0.1958 Cumulative_SOC_deviation: 174.2959 Fuel Consumption: 17.1031\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.336\n",
      "Episode: 97 Exploration P: 0.1244 Total reward: -533.8687038024912 SOC: 0.6812 Cumulative_SOC_deviation: 51.6813 Fuel Consumption: 17.0561\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.481\n",
      "Episode: 98 Exploration P: 0.1213 Total reward: -3276.9133795660996 SOC: 0.2856 Cumulative_SOC_deviation: 325.2509 Fuel Consumption: 24.4042\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.480\n",
      "Episode: 99 Exploration P: 0.1190 Total reward: -523.8170700286287 SOC: 0.6752 Cumulative_SOC_deviation: 50.7382 Fuel Consumption: 16.4356\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.197\n",
      "Episode: 100 Exploration P: 0.1168 Total reward: -576.7361979770551 SOC: 0.6858 Cumulative_SOC_deviation: 55.9344 Fuel Consumption: 17.3923\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.461\n",
      "Episode: 101 Exploration P: 0.1146 Total reward: -760.890874827776 SOC: 0.7007 Cumulative_SOC_deviation: 74.2309 Fuel Consumption: 18.5817\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.998\n",
      "Episode: 102 Exploration P: 0.1123 Total reward: -610.3338771357148 SOC: 0.7101 Cumulative_SOC_deviation: 59.2826 Fuel Consumption: 17.5075\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 95.303\n",
      "Episode: 103 Exploration P: 0.1092 Total reward: -14542.594782362059 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 21.1063\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.094\n",
      "Episode: 104 Exploration P: 0.1070 Total reward: -463.4985050060236 SOC: 0.6807 Cumulative_SOC_deviation: 44.8292 Fuel Consumption: 15.2062\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.304\n",
      "Episode: 105 Exploration P: 0.1050 Total reward: -272.2776592358081 SOC: 0.6562 Cumulative_SOC_deviation: 25.8804 Fuel Consumption: 13.4738\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.587\n",
      "Episode: 106 Exploration P: 0.1030 Total reward: -1859.5091617276023 SOC: 0.1688 Cumulative_SOC_deviation: 184.4707 Fuel Consumption: 14.8019\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.019\n",
      "Episode: 107 Exploration P: 0.1010 Total reward: -825.6320042233965 SOC: 0.6680 Cumulative_SOC_deviation: 80.8833 Fuel Consumption: 16.7994\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.873\n",
      "Episode: 108 Exploration P: 0.0976 Total reward: -676.2638613523328 SOC: 0.6330 Cumulative_SOC_deviation: 60.2710 Fuel Consumption: 73.5542\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.845\n",
      "Episode: 109 Exploration P: 0.0957 Total reward: -619.5594490613653 SOC: 0.6916 Cumulative_SOC_deviation: 60.3507 Fuel Consumption: 16.0523\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.936\n",
      "Episode: 110 Exploration P: 0.0939 Total reward: -588.7186774772689 SOC: 0.6851 Cumulative_SOC_deviation: 57.3441 Fuel Consumption: 15.2780\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -329.96703808089427 SOC: 0.6208 Cumulative_SOC_deviation: 31.5401 Fuel Consumption: 14.5662\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.511\n",
      "Episode: 111 Exploration P: 0.0921 Total reward: -589.8112941987844 SOC: 0.6630 Cumulative_SOC_deviation: 57.2978 Fuel Consumption: 16.8337\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.744\n",
      "Episode: 112 Exploration P: 0.0903 Total reward: -598.2182752255625 SOC: 0.6977 Cumulative_SOC_deviation: 58.1603 Fuel Consumption: 16.6153\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.747\n",
      "Episode: 113 Exploration P: 0.0886 Total reward: -249.0397589868917 SOC: 0.6127 Cumulative_SOC_deviation: 23.6311 Fuel Consumption: 12.7286\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.001\n",
      "Episode: 114 Exploration P: 0.0857 Total reward: -250.09668573716115 SOC: 0.6095 Cumulative_SOC_deviation: 17.6743 Fuel Consumption: 73.3538\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.907\n",
      "Episode: 115 Exploration P: 0.0837 Total reward: -150.78709635518345 SOC: 0.6154 Cumulative_SOC_deviation: 10.4807 Fuel Consumption: 45.9797\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.298\n",
      "Episode: 116 Exploration P: 0.0821 Total reward: -373.852462998652 SOC: 0.6692 Cumulative_SOC_deviation: 32.5181 Fuel Consumption: 48.6719\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.351\n",
      "Episode: 117 Exploration P: 0.0806 Total reward: -336.35771214622974 SOC: 0.6432 Cumulative_SOC_deviation: 29.0157 Fuel Consumption: 46.2008\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.929\n",
      "Episode: 118 Exploration P: 0.0780 Total reward: -296.37945728665943 SOC: 0.6059 Cumulative_SOC_deviation: 22.3463 Fuel Consumption: 72.9162\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.471\n",
      "Episode: 119 Exploration P: 0.0762 Total reward: -204.8640524027518 SOC: 0.5971 Cumulative_SOC_deviation: 15.9542 Fuel Consumption: 45.3223\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.741\n",
      "Episode: 120 Exploration P: 0.0748 Total reward: -239.77792100240083 SOC: 0.6368 Cumulative_SOC_deviation: 22.6459 Fuel Consumption: 13.3189\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -106.769774386488 SOC: 0.5852 Cumulative_SOC_deviation: 9.4245 Fuel Consumption: 12.5246\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.729\n",
      "Episode: 121 Exploration P: 0.0734 Total reward: -278.088803093297 SOC: 0.6498 Cumulative_SOC_deviation: 26.5391 Fuel Consumption: 12.6981\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.428\n",
      "Episode: 122 Exploration P: 0.0717 Total reward: -201.8568561789976 SOC: 0.5949 Cumulative_SOC_deviation: 15.6954 Fuel Consumption: 44.9027\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.425\n",
      "Episode: 123 Exploration P: 0.0704 Total reward: -339.43570002941004 SOC: 0.6197 Cumulative_SOC_deviation: 32.7285 Fuel Consumption: 12.1510\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.670\n",
      "Episode: 124 Exploration P: 0.0691 Total reward: -248.83120759709954 SOC: 0.6062 Cumulative_SOC_deviation: 23.6566 Fuel Consumption: 12.2656\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.262\n",
      "Episode: 125 Exploration P: 0.0679 Total reward: -239.80780724664618 SOC: 0.6029 Cumulative_SOC_deviation: 22.9061 Fuel Consumption: 10.7471\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.533\n",
      "Episode: 126 Exploration P: 0.0668 Total reward: -214.89689773013149 SOC: 0.6060 Cumulative_SOC_deviation: 20.4024 Fuel Consumption: 10.8733\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.444\n",
      "Episode: 127 Exploration P: 0.0656 Total reward: -242.9810719845409 SOC: 0.6051 Cumulative_SOC_deviation: 23.2079 Fuel Consumption: 10.9022\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.073\n",
      "Episode: 128 Exploration P: 0.0644 Total reward: -170.93759881132004 SOC: 0.6272 Cumulative_SOC_deviation: 16.0024 Fuel Consumption: 10.9139\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.103\n",
      "Episode: 129 Exploration P: 0.0632 Total reward: -141.80892678688343 SOC: 0.6195 Cumulative_SOC_deviation: 13.1518 Fuel Consumption: 10.2912\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.746\n",
      "Episode: 130 Exploration P: 0.0621 Total reward: -156.72722110249347 SOC: 0.6214 Cumulative_SOC_deviation: 14.6149 Fuel Consumption: 10.5778\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -883.8916529189202 SOC: 0.4884 Cumulative_SOC_deviation: 87.8682 Fuel Consumption: 5.2093\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.778\n",
      "Episode: 131 Exploration P: 0.0610 Total reward: -388.17595941571426 SOC: 0.5725 Cumulative_SOC_deviation: 34.6527 Fuel Consumption: 41.6486\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.895\n",
      "Episode: 132 Exploration P: 0.0599 Total reward: -53.570254156022486 SOC: 0.6025 Cumulative_SOC_deviation: 4.4621 Fuel Consumption: 8.9488\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.060\n",
      "Episode: 133 Exploration P: 0.0588 Total reward: -91.96689032635703 SOC: 0.6276 Cumulative_SOC_deviation: 8.1027 Fuel Consumption: 10.9398\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.426\n",
      "Episode: 134 Exploration P: 0.0578 Total reward: -140.62218009402127 SOC: 0.5585 Cumulative_SOC_deviation: 13.2158 Fuel Consumption: 8.4646\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 110.855\n",
      "Episode: 135 Exploration P: 0.0560 Total reward: -2546.225494663078 SOC: 0.4489 Cumulative_SOC_deviation: 248.3883 Fuel Consumption: 62.3421\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.290\n",
      "Episode: 136 Exploration P: 0.0548 Total reward: -1492.3635269524557 SOC: 0.5473 Cumulative_SOC_deviation: 144.9904 Fuel Consumption: 42.4591\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.210\n",
      "Episode: 137 Exploration P: 0.0538 Total reward: -192.39467630981193 SOC: 0.6306 Cumulative_SOC_deviation: 14.6230 Fuel Consumption: 46.1646\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.082\n",
      "Episode: 138 Exploration P: 0.0529 Total reward: -69.64888832958574 SOC: 0.6107 Cumulative_SOC_deviation: 5.9929 Fuel Consumption: 9.7203\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.373\n",
      "Episode: 139 Exploration P: 0.0513 Total reward: -463.4607775245927 SOC: 0.5877 Cumulative_SOC_deviation: 38.9890 Fuel Consumption: 73.5707\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.372\n",
      "Episode: 140 Exploration P: 0.0502 Total reward: -239.3800724869243 SOC: 0.6038 Cumulative_SOC_deviation: 19.3573 Fuel Consumption: 45.8070\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -102.90842027141241 SOC: 0.6009 Cumulative_SOC_deviation: 8.9102 Fuel Consumption: 13.8065\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.214\n",
      "Episode: 141 Exploration P: 0.0494 Total reward: -171.06914535094617 SOC: 0.6128 Cumulative_SOC_deviation: 15.9971 Fuel Consumption: 11.0983\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.224\n",
      "Episode: 142 Exploration P: 0.0483 Total reward: -100.47623323968357 SOC: 0.6000 Cumulative_SOC_deviation: 5.6520 Fuel Consumption: 43.9557\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.224\n",
      "Episode: 143 Exploration P: 0.0475 Total reward: -122.11536167218509 SOC: 0.6097 Cumulative_SOC_deviation: 7.9230 Fuel Consumption: 42.8854\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.570\n",
      "Episode: 144 Exploration P: 0.0461 Total reward: -817.499197384849 SOC: 0.5518 Cumulative_SOC_deviation: 74.9682 Fuel Consumption: 67.8172\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.667\n",
      "Episode: 145 Exploration P: 0.0453 Total reward: -104.27540283808949 SOC: 0.5826 Cumulative_SOC_deviation: 9.4234 Fuel Consumption: 10.0419\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.602\n",
      "Episode: 146 Exploration P: 0.0446 Total reward: -145.3183553678277 SOC: 0.5809 Cumulative_SOC_deviation: 13.5632 Fuel Consumption: 9.6868\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.518\n",
      "Episode: 147 Exploration P: 0.0438 Total reward: -132.37438087186484 SOC: 0.6121 Cumulative_SOC_deviation: 12.2929 Fuel Consumption: 9.4452\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.683\n",
      "Episode: 148 Exploration P: 0.0431 Total reward: -158.19775274968046 SOC: 0.5578 Cumulative_SOC_deviation: 15.0206 Fuel Consumption: 7.9922\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.049\n",
      "Episode: 149 Exploration P: 0.0424 Total reward: -329.89199631642157 SOC: 0.5777 Cumulative_SOC_deviation: 28.9194 Fuel Consumption: 40.6981\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.603\n",
      "Episode: 150 Exploration P: 0.0417 Total reward: -369.74823524592915 SOC: 0.5834 Cumulative_SOC_deviation: 32.8652 Fuel Consumption: 41.0964\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -303.7784506015348 SOC: 0.5642 Cumulative_SOC_deviation: 29.3587 Fuel Consumption: 10.1912\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.967\n",
      "Episode: 151 Exploration P: 0.0411 Total reward: -195.77600530840058 SOC: 0.5796 Cumulative_SOC_deviation: 18.6879 Fuel Consumption: 8.8974\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.702\n",
      "Episode: 152 Exploration P: 0.0404 Total reward: -585.3606207777832 SOC: 0.5760 Cumulative_SOC_deviation: 54.2171 Fuel Consumption: 43.1900\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.228\n",
      "Episode: 153 Exploration P: 0.0398 Total reward: -135.49653553453194 SOC: 0.5794 Cumulative_SOC_deviation: 12.8450 Fuel Consumption: 7.0468\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.623\n",
      "Episode: 154 Exploration P: 0.0390 Total reward: -2429.483584909613 SOC: 0.3963 Cumulative_SOC_deviation: 239.9833 Fuel Consumption: 29.6507\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.062\n",
      "Episode: 155 Exploration P: 0.0382 Total reward: -401.51214260235673 SOC: 0.5626 Cumulative_SOC_deviation: 36.0846 Fuel Consumption: 40.6659\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.530\n",
      "Episode: 156 Exploration P: 0.0376 Total reward: -141.68045137011632 SOC: 0.5845 Cumulative_SOC_deviation: 13.4076 Fuel Consumption: 7.6043\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.682\n",
      "Episode: 157 Exploration P: 0.0370 Total reward: -207.00469088457731 SOC: 0.5479 Cumulative_SOC_deviation: 19.9671 Fuel Consumption: 7.3333\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.030\n",
      "Episode: 158 Exploration P: 0.0360 Total reward: -982.2826781080498 SOC: 0.5493 Cumulative_SOC_deviation: 91.0307 Fuel Consumption: 71.9753\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.850\n",
      "Episode: 159 Exploration P: 0.0354 Total reward: -152.3555115457052 SOC: 0.5488 Cumulative_SOC_deviation: 14.4802 Fuel Consumption: 7.5534\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.927\n",
      "Episode: 160 Exploration P: 0.0349 Total reward: -218.24546324640377 SOC: 0.5490 Cumulative_SOC_deviation: 21.1852 Fuel Consumption: 6.3930\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -554.2072796449539 SOC: 0.5454 Cumulative_SOC_deviation: 54.5434 Fuel Consumption: 8.7737\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.135\n",
      "Episode: 161 Exploration P: 0.0340 Total reward: -1373.8617020185884 SOC: 0.5447 Cumulative_SOC_deviation: 130.2073 Fuel Consumption: 71.7888\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.959\n",
      "Episode: 162 Exploration P: 0.0334 Total reward: -989.7996213654324 SOC: 0.5313 Cumulative_SOC_deviation: 94.9208 Fuel Consumption: 40.5916\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.271\n",
      "Episode: 163 Exploration P: 0.0329 Total reward: -702.4983772597972 SOC: 0.5366 Cumulative_SOC_deviation: 66.2094 Fuel Consumption: 40.4043\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.728\n",
      "Episode: 164 Exploration P: 0.0322 Total reward: -481.644681970741 SOC: 0.5825 Cumulative_SOC_deviation: 43.3733 Fuel Consumption: 47.9114\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.895\n",
      "Episode: 165 Exploration P: 0.0318 Total reward: -55.74231784103384 SOC: 0.6070 Cumulative_SOC_deviation: 4.4288 Fuel Consumption: 11.4544\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.759\n",
      "Episode: 166 Exploration P: 0.0313 Total reward: -226.24557442577165 SOC: 0.6133 Cumulative_SOC_deviation: 21.3870 Fuel Consumption: 12.3755\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.438\n",
      "Episode: 167 Exploration P: 0.0309 Total reward: -135.7305378482385 SOC: 0.6106 Cumulative_SOC_deviation: 12.5082 Fuel Consumption: 10.6483\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.139\n",
      "Episode: 168 Exploration P: 0.0304 Total reward: -1214.5408090193125 SOC: 1.0000 Cumulative_SOC_deviation: 111.3068 Fuel Consumption: 101.4724\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.568\n",
      "Episode: 169 Exploration P: 0.0300 Total reward: -4148.477881996106 SOC: 1.0000 Cumulative_SOC_deviation: 391.7967 Fuel Consumption: 230.5113\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.437\n",
      "Episode: 170 Exploration P: 0.0296 Total reward: -4144.49080145864 SOC: 1.0000 Cumulative_SOC_deviation: 391.4784 Fuel Consumption: 229.7069\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -5641.035927475313 SOC: 1.0000 Cumulative_SOC_deviation: 533.6285 Fuel Consumption: 304.7514\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.141\n",
      "Episode: 171 Exploration P: 0.0292 Total reward: -4277.4874429752335 SOC: 1.0000 Cumulative_SOC_deviation: 404.5865 Fuel Consumption: 231.6224\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.962\n",
      "Episode: 172 Exploration P: 0.0288 Total reward: -4039.031363675862 SOC: 1.0000 Cumulative_SOC_deviation: 381.8726 Fuel Consumption: 220.3055\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.317\n",
      "Episode: 173 Exploration P: 0.0283 Total reward: -5455.34902728958 SOC: 1.0000 Cumulative_SOC_deviation: 516.1048 Fuel Consumption: 294.3011\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.586\n",
      "Episode: 174 Exploration P: 0.0276 Total reward: -7570.542688482405 SOC: 1.0000 Cumulative_SOC_deviation: 716.8758 Fuel Consumption: 401.7844\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.212\n",
      "Episode: 175 Exploration P: 0.0272 Total reward: -4280.058646043994 SOC: 1.0000 Cumulative_SOC_deviation: 404.8439 Fuel Consumption: 231.6196\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.138\n",
      "Episode: 176 Exploration P: 0.0268 Total reward: -4277.43945228778 SOC: 1.0000 Cumulative_SOC_deviation: 404.5711 Fuel Consumption: 231.7287\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.495\n",
      "Episode: 177 Exploration P: 0.0265 Total reward: -4256.530331167897 SOC: 1.0000 Cumulative_SOC_deviation: 402.5338 Fuel Consumption: 231.1928\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.451\n",
      "Episode: 178 Exploration P: 0.0261 Total reward: -4148.0689932183095 SOC: 1.0000 Cumulative_SOC_deviation: 391.9399 Fuel Consumption: 228.6698\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.075\n",
      "Episode: 179 Exploration P: 0.0258 Total reward: -4041.713512398098 SOC: 1.0000 Cumulative_SOC_deviation: 382.0394 Fuel Consumption: 221.3196\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.414\n",
      "Episode: 180 Exploration P: 0.0254 Total reward: -5447.582763871823 SOC: 1.0000 Cumulative_SOC_deviation: 515.2253 Fuel Consumption: 295.3296\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -5641.035927475313 SOC: 1.0000 Cumulative_SOC_deviation: 533.6285 Fuel Consumption: 304.7514\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.367\n",
      "Episode: 181 Exploration P: 0.0250 Total reward: -4278.423321912412 SOC: 1.0000 Cumulative_SOC_deviation: 404.5347 Fuel Consumption: 233.0762\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.694\n",
      "Episode: 182 Exploration P: 0.0247 Total reward: -4152.585677712168 SOC: 1.0000 Cumulative_SOC_deviation: 392.1175 Fuel Consumption: 231.4106\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.196\n",
      "Episode: 183 Exploration P: 0.0244 Total reward: -4271.267884638437 SOC: 1.0000 Cumulative_SOC_deviation: 403.9545 Fuel Consumption: 231.7230\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.359\n",
      "Episode: 184 Exploration P: 0.0241 Total reward: -4282.804038411024 SOC: 1.0000 Cumulative_SOC_deviation: 404.9645 Fuel Consumption: 233.1595\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.428\n",
      "Episode: 185 Exploration P: 0.0238 Total reward: -4154.312283724206 SOC: 1.0000 Cumulative_SOC_deviation: 392.4232 Fuel Consumption: 230.0804\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.668\n",
      "Episode: 186 Exploration P: 0.0235 Total reward: -4251.0636750742015 SOC: 1.0000 Cumulative_SOC_deviation: 402.0897 Fuel Consumption: 230.1671\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.058\n",
      "Episode: 187 Exploration P: 0.0232 Total reward: -4043.679468148781 SOC: 1.0000 Cumulative_SOC_deviation: 382.2328 Fuel Consumption: 221.3513\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.698\n",
      "Episode: 188 Exploration P: 0.0230 Total reward: -4037.831782853113 SOC: 1.0000 Cumulative_SOC_deviation: 381.6753 Fuel Consumption: 221.0783\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.236\n",
      "Episode: 189 Exploration P: 0.0227 Total reward: -4254.7355388911465 SOC: 1.0000 Cumulative_SOC_deviation: 402.3862 Fuel Consumption: 230.8739\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.310\n",
      "Episode: 190 Exploration P: 0.0224 Total reward: -4152.139488757249 SOC: 1.0000 Cumulative_SOC_deviation: 392.1585 Fuel Consumption: 230.5545\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -5641.035927475313 SOC: 1.0000 Cumulative_SOC_deviation: 533.6285 Fuel Consumption: 304.7514\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.129\n",
      "Episode: 191 Exploration P: 0.0222 Total reward: -4036.1872611659305 SOC: 1.0000 Cumulative_SOC_deviation: 381.4977 Fuel Consumption: 221.2105\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.366\n",
      "Episode: 192 Exploration P: 0.0219 Total reward: -4278.200328340503 SOC: 1.0000 Cumulative_SOC_deviation: 404.5006 Fuel Consumption: 233.1940\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.607\n",
      "Episode: 193 Exploration P: 0.0215 Total reward: -7572.365925894721 SOC: 1.0000 Cumulative_SOC_deviation: 716.7450 Fuel Consumption: 404.9160\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.903\n",
      "Episode: 194 Exploration P: 0.0210 Total reward: -7565.662056656693 SOC: 1.0000 Cumulative_SOC_deviation: 716.3128 Fuel Consumption: 402.5343\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.774\n",
      "Episode: 195 Exploration P: 0.0208 Total reward: -4158.46754607729 SOC: 1.0000 Cumulative_SOC_deviation: 392.6586 Fuel Consumption: 231.8818\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.983\n",
      "Episode: 196 Exploration P: 0.0205 Total reward: -5452.873361573809 SOC: 1.0000 Cumulative_SOC_deviation: 515.6110 Fuel Consumption: 296.7632\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.607\n",
      "Episode: 197 Exploration P: 0.0203 Total reward: -4280.006012354059 SOC: 1.0000 Cumulative_SOC_deviation: 404.7211 Fuel Consumption: 232.7946\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.564\n",
      "Episode: 198 Exploration P: 0.0199 Total reward: -7574.733896404398 SOC: 1.0000 Cumulative_SOC_deviation: 717.0048 Fuel Consumption: 404.6861\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.819\n",
      "Episode: 199 Exploration P: 0.0197 Total reward: -4279.157057469903 SOC: 1.0000 Cumulative_SOC_deviation: 404.7118 Fuel Consumption: 232.0390\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.085\n",
      "Episode: 200 Exploration P: 0.0195 Total reward: -4155.701697118548 SOC: 1.0000 Cumulative_SOC_deviation: 392.4331 Fuel Consumption: 231.3704\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -5641.035927475313 SOC: 1.0000 Cumulative_SOC_deviation: 533.6285 Fuel Consumption: 304.7514\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.468\n",
      "Episode: 201 Exploration P: 0.0191 Total reward: -7571.53475729899 SOC: 1.0000 Cumulative_SOC_deviation: 716.7369 Fuel Consumption: 404.1661\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.711\n",
      "Episode: 202 Exploration P: 0.0189 Total reward: -4278.5923775263245 SOC: 1.0000 Cumulative_SOC_deviation: 404.6487 Fuel Consumption: 232.1051\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.025\n",
      "Episode: 203 Exploration P: 0.0188 Total reward: -4154.504114110392 SOC: 1.0000 Cumulative_SOC_deviation: 392.3183 Fuel Consumption: 231.3216\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.670\n",
      "Episode: 204 Exploration P: 0.0185 Total reward: -5457.753554773263 SOC: 1.0000 Cumulative_SOC_deviation: 516.0982 Fuel Consumption: 296.7718\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.959\n",
      "Episode: 205 Exploration P: 0.0183 Total reward: -4254.66803887363 SOC: 1.0000 Cumulative_SOC_deviation: 402.3165 Fuel Consumption: 231.5031\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.990\n",
      "Episode: 206 Exploration P: 0.0181 Total reward: -5452.701331183785 SOC: 1.0000 Cumulative_SOC_deviation: 515.6237 Fuel Consumption: 296.4644\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.571\n",
      "Episode: 207 Exploration P: 0.0179 Total reward: -4283.499144243795 SOC: 1.0000 Cumulative_SOC_deviation: 405.0389 Fuel Consumption: 233.1106\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.712\n",
      "Episode: 208 Exploration P: 0.0177 Total reward: -5456.848482447171 SOC: 1.0000 Cumulative_SOC_deviation: 515.9950 Fuel Consumption: 296.8982\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.511\n",
      "Episode: 209 Exploration P: 0.0176 Total reward: -3731.067821035427 SOC: 0.9298 Cumulative_SOC_deviation: 360.9319 Fuel Consumption: 121.7487\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.412\n",
      "Episode: 210 Exploration P: 0.0174 Total reward: -202.9061611361606 SOC: 0.5667 Cumulative_SOC_deviation: 19.6804 Fuel Consumption: 6.1021\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -763.414727472078 SOC: 0.5052 Cumulative_SOC_deviation: 75.7044 Fuel Consumption: 6.3706\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.053\n",
      "Episode: 211 Exploration P: 0.0172 Total reward: -114.29287647687048 SOC: 0.5883 Cumulative_SOC_deviation: 10.6805 Fuel Consumption: 7.4881\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.149\n",
      "Episode: 212 Exploration P: 0.0171 Total reward: -124.36303299222398 SOC: 0.6003 Cumulative_SOC_deviation: 11.4638 Fuel Consumption: 9.7247\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.387\n",
      "Episode: 213 Exploration P: 0.0169 Total reward: -3232.2404217345684 SOC: 1.0000 Cumulative_SOC_deviation: 305.1587 Fuel Consumption: 180.6533\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.116\n",
      "Episode: 214 Exploration P: 0.0168 Total reward: -4157.237852202393 SOC: 1.0000 Cumulative_SOC_deviation: 392.6023 Fuel Consumption: 231.2153\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.200\n",
      "Episode: 215 Exploration P: 0.0166 Total reward: -5458.697831964117 SOC: 1.0000 Cumulative_SOC_deviation: 516.0561 Fuel Consumption: 298.1365\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.482\n",
      "Episode: 216 Exploration P: 0.0165 Total reward: -4279.862151170604 SOC: 1.0000 Cumulative_SOC_deviation: 404.6717 Fuel Consumption: 233.1451\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.567\n",
      "Episode: 217 Exploration P: 0.0163 Total reward: -4283.565703497005 SOC: 1.0000 Cumulative_SOC_deviation: 405.1038 Fuel Consumption: 232.5274\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.533\n",
      "Episode: 218 Exploration P: 0.0162 Total reward: -3818.2446501822888 SOC: 0.9485 Cumulative_SOC_deviation: 368.6314 Fuel Consumption: 131.9304\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.075\n",
      "Episode: 219 Exploration P: 0.0161 Total reward: -182.60395468816077 SOC: 0.5795 Cumulative_SOC_deviation: 17.5779 Fuel Consumption: 6.8246\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.445\n",
      "Episode: 220 Exploration P: 0.0159 Total reward: -196.9346223717299 SOC: 0.5209 Cumulative_SOC_deviation: 19.1562 Fuel Consumption: 5.3724\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1011.1383092240851 SOC: 0.4723 Cumulative_SOC_deviation: 100.7233 Fuel Consumption: 3.9057\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.400\n",
      "Episode: 221 Exploration P: 0.0158 Total reward: -303.79090087363073 SOC: 0.5242 Cumulative_SOC_deviation: 29.9379 Fuel Consumption: 4.4121\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.138\n",
      "Episode: 222 Exploration P: 0.0157 Total reward: -861.7761190633337 SOC: 0.5904 Cumulative_SOC_deviation: 81.5674 Fuel Consumption: 46.1018\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.790\n",
      "Episode: 223 Exploration P: 0.0155 Total reward: -3562.300519106006 SOC: 1.0000 Cumulative_SOC_deviation: 336.4732 Fuel Consumption: 197.5687\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.789\n",
      "Episode: 224 Exploration P: 0.0154 Total reward: -4249.384401817256 SOC: 0.9917 Cumulative_SOC_deviation: 404.2352 Fuel Consumption: 207.0328\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.309\n",
      "Episode: 225 Exploration P: 0.0153 Total reward: -467.03834653264994 SOC: 0.5744 Cumulative_SOC_deviation: 42.4402 Fuel Consumption: 42.6361\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.135\n",
      "Episode: 226 Exploration P: 0.0152 Total reward: -282.6247796948511 SOC: 0.5587 Cumulative_SOC_deviation: 27.7386 Fuel Consumption: 5.2391\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.588\n",
      "Episode: 227 Exploration P: 0.0151 Total reward: -284.8624892280883 SOC: 0.5613 Cumulative_SOC_deviation: 27.9426 Fuel Consumption: 5.4367\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.887\n",
      "Episode: 228 Exploration P: 0.0150 Total reward: -242.83939961468178 SOC: 0.5317 Cumulative_SOC_deviation: 23.6669 Fuel Consumption: 6.1708\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.035\n",
      "Episode: 229 Exploration P: 0.0149 Total reward: -238.4793871873047 SOC: 0.5588 Cumulative_SOC_deviation: 23.0935 Fuel Consumption: 7.5449\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.218\n",
      "Episode: 230 Exploration P: 0.0148 Total reward: -256.25108219673234 SOC: 0.5615 Cumulative_SOC_deviation: 24.9560 Fuel Consumption: 6.6907\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -460.16239803920473 SOC: 0.5536 Cumulative_SOC_deviation: 45.0877 Fuel Consumption: 9.2858\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.972\n",
      "Episode: 231 Exploration P: 0.0146 Total reward: -651.1372933516689 SOC: 0.5527 Cumulative_SOC_deviation: 61.2199 Fuel Consumption: 38.9385\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.552\n",
      "Episode: 232 Exploration P: 0.0145 Total reward: -935.775685477603 SOC: 0.5532 Cumulative_SOC_deviation: 86.9489 Fuel Consumption: 66.2865\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.167\n",
      "Episode: 233 Exploration P: 0.0143 Total reward: -666.6511811480862 SOC: 0.5602 Cumulative_SOC_deviation: 62.6114 Fuel Consumption: 40.5376\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.645\n",
      "Episode: 234 Exploration P: 0.0143 Total reward: -259.01566873275556 SOC: 0.5570 Cumulative_SOC_deviation: 25.2439 Fuel Consumption: 6.5765\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.309\n",
      "Episode: 235 Exploration P: 0.0142 Total reward: -240.80785801573361 SOC: 0.5656 Cumulative_SOC_deviation: 23.3495 Fuel Consumption: 7.3128\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.228\n",
      "Episode: 236 Exploration P: 0.0141 Total reward: -199.91604279532615 SOC: 0.5800 Cumulative_SOC_deviation: 19.1439 Fuel Consumption: 8.4767\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.155\n",
      "Episode: 237 Exploration P: 0.0140 Total reward: -152.71755489377406 SOC: 0.5829 Cumulative_SOC_deviation: 14.5513 Fuel Consumption: 7.2048\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.878\n",
      "Episode: 238 Exploration P: 0.0139 Total reward: -171.28779095147257 SOC: 0.5887 Cumulative_SOC_deviation: 16.3802 Fuel Consumption: 7.4859\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.143\n",
      "Episode: 239 Exploration P: 0.0138 Total reward: -155.773347368257 SOC: 0.5817 Cumulative_SOC_deviation: 14.8846 Fuel Consumption: 6.9269\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.749\n",
      "Episode: 240 Exploration P: 0.0137 Total reward: -57.646492361390074 SOC: 0.6014 Cumulative_SOC_deviation: 4.6210 Fuel Consumption: 11.4361\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -192.33744418551296 SOC: 0.5830 Cumulative_SOC_deviation: 18.0134 Fuel Consumption: 12.2034\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.439\n",
      "Episode: 241 Exploration P: 0.0137 Total reward: -89.61511083245725 SOC: 0.5948 Cumulative_SOC_deviation: 7.8871 Fuel Consumption: 10.7442\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.713\n",
      "Episode: 242 Exploration P: 0.0136 Total reward: -75.32457992286824 SOC: 0.5986 Cumulative_SOC_deviation: 6.6995 Fuel Consumption: 8.3295\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.916\n",
      "Episode: 243 Exploration P: 0.0135 Total reward: -154.8718569523448 SOC: 0.6111 Cumulative_SOC_deviation: 10.9043 Fuel Consumption: 45.8293\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.200\n",
      "Episode: 244 Exploration P: 0.0134 Total reward: -75.55481635327816 SOC: 0.6078 Cumulative_SOC_deviation: 6.3771 Fuel Consumption: 11.7841\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.973\n",
      "Episode: 245 Exploration P: 0.0134 Total reward: -52.82162262550293 SOC: 0.5981 Cumulative_SOC_deviation: 4.4501 Fuel Consumption: 8.3211\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.206\n",
      "Episode: 246 Exploration P: 0.0133 Total reward: -162.19049915866566 SOC: 0.6319 Cumulative_SOC_deviation: 11.4302 Fuel Consumption: 47.8884\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.460\n",
      "Episode: 247 Exploration P: 0.0131 Total reward: -374.93629509854003 SOC: 0.6112 Cumulative_SOC_deviation: 30.0004 Fuel Consumption: 74.9324\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.978\n",
      "Episode: 248 Exploration P: 0.0131 Total reward: -54.70999741083775 SOC: 0.6070 Cumulative_SOC_deviation: 4.5854 Fuel Consumption: 8.8561\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.426\n",
      "Episode: 249 Exploration P: 0.0130 Total reward: -70.29780749387129 SOC: 0.6092 Cumulative_SOC_deviation: 5.8294 Fuel Consumption: 12.0039\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.965\n",
      "Episode: 250 Exploration P: 0.0129 Total reward: -83.52193646673575 SOC: 0.6108 Cumulative_SOC_deviation: 7.1151 Fuel Consumption: 12.3712\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -93.31831044243884 SOC: 0.6082 Cumulative_SOC_deviation: 7.8769 Fuel Consumption: 14.5496\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.359\n",
      "Episode: 251 Exploration P: 0.0129 Total reward: -66.49004174570553 SOC: 0.6066 Cumulative_SOC_deviation: 5.7581 Fuel Consumption: 8.9094\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.928\n",
      "Episode: 252 Exploration P: 0.0128 Total reward: -74.93925300376529 SOC: 0.6102 Cumulative_SOC_deviation: 6.5718 Fuel Consumption: 9.2211\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.839\n",
      "Episode: 253 Exploration P: 0.0128 Total reward: -65.71341662601206 SOC: 0.6075 Cumulative_SOC_deviation: 5.6754 Fuel Consumption: 8.9592\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.402\n",
      "Episode: 254 Exploration P: 0.0127 Total reward: -220.43103349051586 SOC: 0.6085 Cumulative_SOC_deviation: 14.5627 Fuel Consumption: 74.8035\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.781\n",
      "Episode: 255 Exploration P: 0.0126 Total reward: -64.15233550026367 SOC: 0.6139 Cumulative_SOC_deviation: 5.4887 Fuel Consumption: 9.2653\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.805\n",
      "Episode: 256 Exploration P: 0.0125 Total reward: -79.65416214790825 SOC: 0.6071 Cumulative_SOC_deviation: 7.0837 Fuel Consumption: 8.8174\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.598\n",
      "Episode: 257 Exploration P: 0.0125 Total reward: -115.00000592446123 SOC: 0.6023 Cumulative_SOC_deviation: 7.3085 Fuel Consumption: 41.9149\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.462\n",
      "Episode: 258 Exploration P: 0.0124 Total reward: -417.20458742258387 SOC: 0.5643 Cumulative_SOC_deviation: 37.5390 Fuel Consumption: 41.8150\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.994\n",
      "Episode: 259 Exploration P: 0.0124 Total reward: -401.16456008461387 SOC: 0.5775 Cumulative_SOC_deviation: 35.8433 Fuel Consumption: 42.7319\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.329\n",
      "Episode: 260 Exploration P: 0.0123 Total reward: -178.89721356907106 SOC: 0.6328 Cumulative_SOC_deviation: 16.6183 Fuel Consumption: 12.7146\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -193.80163654509198 SOC: 0.6110 Cumulative_SOC_deviation: 17.9420 Fuel Consumption: 14.3816\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.465\n",
      "Episode: 261 Exploration P: 0.0123 Total reward: -833.3913699298745 SOC: 0.5082 Cumulative_SOC_deviation: 79.6224 Fuel Consumption: 37.1678\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.504\n",
      "Episode: 262 Exploration P: 0.0122 Total reward: -275.12310462286143 SOC: 0.5460 Cumulative_SOC_deviation: 26.9289 Fuel Consumption: 5.8337\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.233\n",
      "Episode: 263 Exploration P: 0.0122 Total reward: -154.19208858337953 SOC: 0.6131 Cumulative_SOC_deviation: 10.8946 Fuel Consumption: 45.2463\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.648\n",
      "Episode: 264 Exploration P: 0.0122 Total reward: -217.80207831231698 SOC: 0.6138 Cumulative_SOC_deviation: 20.8161 Fuel Consumption: 9.6406\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.948\n",
      "Episode: 265 Exploration P: 0.0121 Total reward: -282.54058311674703 SOC: 0.5721 Cumulative_SOC_deviation: 23.8766 Fuel Consumption: 43.7741\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.280\n",
      "Episode: 266 Exploration P: 0.0120 Total reward: -510.3667203215937 SOC: 0.6209 Cumulative_SOC_deviation: 43.3250 Fuel Consumption: 77.1163\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.707\n",
      "Episode: 267 Exploration P: 0.0119 Total reward: -1507.5841120631544 SOC: 0.4452 Cumulative_SOC_deviation: 144.6435 Fuel Consumption: 61.1489\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.559\n",
      "Episode: 268 Exploration P: 0.0119 Total reward: -311.20400928557694 SOC: 0.6147 Cumulative_SOC_deviation: 26.5369 Fuel Consumption: 45.8348\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.293\n",
      "Episode: 269 Exploration P: 0.0119 Total reward: -218.86169350883287 SOC: 0.6300 Cumulative_SOC_deviation: 20.8061 Fuel Consumption: 10.8005\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.954\n",
      "Episode: 270 Exploration P: 0.0118 Total reward: -454.22727424758864 SOC: 0.6091 Cumulative_SOC_deviation: 38.1003 Fuel Consumption: 73.2244\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -88.07812453951917 SOC: 0.5984 Cumulative_SOC_deviation: 7.5277 Fuel Consumption: 12.8007\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.441\n",
      "Episode: 271 Exploration P: 0.0118 Total reward: -64.56667546425791 SOC: 0.6160 Cumulative_SOC_deviation: 5.2217 Fuel Consumption: 12.3493\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.512\n",
      "Episode: 272 Exploration P: 0.0117 Total reward: -93.16552199489381 SOC: 0.6057 Cumulative_SOC_deviation: 8.2556 Fuel Consumption: 10.6091\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.554\n",
      "Episode: 273 Exploration P: 0.0117 Total reward: -115.93576359294953 SOC: 0.6038 Cumulative_SOC_deviation: 7.0578 Fuel Consumption: 45.3579\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.265\n",
      "Episode: 274 Exploration P: 0.0116 Total reward: -247.7920895819768 SOC: 0.6131 Cumulative_SOC_deviation: 23.5626 Fuel Consumption: 12.1657\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.004\n",
      "Episode: 275 Exploration P: 0.0116 Total reward: -87.63277818189057 SOC: 0.6034 Cumulative_SOC_deviation: 7.9055 Fuel Consumption: 8.5779\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.178\n",
      "Episode: 276 Exploration P: 0.0115 Total reward: -250.6366708461957 SOC: 0.6258 Cumulative_SOC_deviation: 17.7307 Fuel Consumption: 73.3296\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.592\n",
      "Episode: 277 Exploration P: 0.0115 Total reward: -196.98625814880216 SOC: 0.6206 Cumulative_SOC_deviation: 18.7397 Fuel Consumption: 9.5897\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.189\n",
      "Episode: 278 Exploration P: 0.0115 Total reward: -137.43595809401555 SOC: 0.6138 Cumulative_SOC_deviation: 9.4298 Fuel Consumption: 43.1379\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.319\n",
      "Episode: 279 Exploration P: 0.0114 Total reward: -191.99747262334853 SOC: 0.6227 Cumulative_SOC_deviation: 18.0088 Fuel Consumption: 11.9094\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.647\n",
      "Episode: 280 Exploration P: 0.0114 Total reward: -171.66879492174593 SOC: 0.6054 Cumulative_SOC_deviation: 16.2977 Fuel Consumption: 8.6921\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -302.35872444506407 SOC: 0.5675 Cumulative_SOC_deviation: 29.2109 Fuel Consumption: 10.2498\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.831\n",
      "Episode: 281 Exploration P: 0.0114 Total reward: -384.47747730223574 SOC: 0.5361 Cumulative_SOC_deviation: 38.0829 Fuel Consumption: 3.6482\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.877\n",
      "Episode: 282 Exploration P: 0.0113 Total reward: -932.7526434916382 SOC: 0.6219 Cumulative_SOC_deviation: 85.4736 Fuel Consumption: 78.0168\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 116.192\n",
      "Episode: 283 Exploration P: 0.0113 Total reward: -251.15561811457974 SOC: 0.6172 Cumulative_SOC_deviation: 17.7697 Fuel Consumption: 73.4584\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.217\n",
      "Episode: 284 Exploration P: 0.0113 Total reward: -150.03300317410262 SOC: 0.6211 Cumulative_SOC_deviation: 10.5521 Fuel Consumption: 44.5121\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.911\n",
      "Episode: 285 Exploration P: 0.0112 Total reward: -112.66955831125202 SOC: 0.6166 Cumulative_SOC_deviation: 10.1558 Fuel Consumption: 11.1116\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.752\n",
      "Episode: 286 Exploration P: 0.0112 Total reward: -171.7699351362306 SOC: 0.6141 Cumulative_SOC_deviation: 10.1472 Fuel Consumption: 70.2975\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.625\n",
      "Episode: 287 Exploration P: 0.0111 Total reward: -201.87271660829745 SOC: 0.5901 Cumulative_SOC_deviation: 13.3517 Fuel Consumption: 68.3556\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.792\n",
      "Episode: 288 Exploration P: 0.0111 Total reward: -56.32484660822501 SOC: 0.5999 Cumulative_SOC_deviation: 4.8231 Fuel Consumption: 8.0942\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.835\n",
      "Episode: 289 Exploration P: 0.0111 Total reward: -85.22316767982194 SOC: 0.5968 Cumulative_SOC_deviation: 7.5871 Fuel Consumption: 9.3519\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.604\n",
      "Episode: 290 Exploration P: 0.0111 Total reward: -67.56656077712351 SOC: 0.6066 Cumulative_SOC_deviation: 5.8991 Fuel Consumption: 8.5751\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -84.01113228657827 SOC: 0.6082 Cumulative_SOC_deviation: 7.0715 Fuel Consumption: 13.2957\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.847\n",
      "Episode: 291 Exploration P: 0.0110 Total reward: -73.51385434937727 SOC: 0.6056 Cumulative_SOC_deviation: 6.3382 Fuel Consumption: 10.1321\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.192\n",
      "Episode: 292 Exploration P: 0.0110 Total reward: -38.34545359588611 SOC: 0.6032 Cumulative_SOC_deviation: 2.7649 Fuel Consumption: 10.6964\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.855\n",
      "Episode: 293 Exploration P: 0.0110 Total reward: -166.08610478348615 SOC: 0.5973 Cumulative_SOC_deviation: 9.6314 Fuel Consumption: 69.7723\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.129\n",
      "Episode: 294 Exploration P: 0.0110 Total reward: -201.36205244670992 SOC: 0.5904 Cumulative_SOC_deviation: 13.2021 Fuel Consumption: 69.3410\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.241\n",
      "Episode: 295 Exploration P: 0.0109 Total reward: -76.78085665011915 SOC: 0.6011 Cumulative_SOC_deviation: 6.7085 Fuel Consumption: 9.6957\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.912\n",
      "Episode: 296 Exploration P: 0.0109 Total reward: -127.9342411979988 SOC: 0.6084 Cumulative_SOC_deviation: 8.5194 Fuel Consumption: 42.7406\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.765\n",
      "Episode: 297 Exploration P: 0.0109 Total reward: -342.7419361603239 SOC: 0.5899 Cumulative_SOC_deviation: 27.3848 Fuel Consumption: 68.8936\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.019\n",
      "Episode: 298 Exploration P: 0.0109 Total reward: -135.37237702715342 SOC: 0.5982 Cumulative_SOC_deviation: 9.3589 Fuel Consumption: 41.7838\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.852\n",
      "Episode: 299 Exploration P: 0.0108 Total reward: -327.7410961933362 SOC: 0.5555 Cumulative_SOC_deviation: 32.2775 Fuel Consumption: 4.9660\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.820\n",
      "Episode: 300 Exploration P: 0.0108 Total reward: -340.65882326064536 SOC: 0.5554 Cumulative_SOC_deviation: 33.5792 Fuel Consumption: 4.8666\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -406.1327194647691 SOC: 0.5567 Cumulative_SOC_deviation: 39.6496 Fuel Consumption: 9.6365\n",
      "******************* Test is done *****************\n",
      "\n",
      "model is saved..\n"
     ]
    }
   ],
   "source": [
    "print(env.version)\n",
    "\n",
    "num_trials = 1\n",
    "results_dict = {} \n",
    "driving_cycle_paths = glob.glob(\"../data/driving_cycles/city/*.mat\")[:7]\n",
    "\n",
    "for trial in range(num_trials): \n",
    "    print(\"\")\n",
    "    print(\"Trial {}\".format(trial))\n",
    "    print(\"\")\n",
    "    \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer = initialization()\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    episode_test_history = [] \n",
    "    episode_num_test = [] \n",
    "    for ep in range(total_episodes): \n",
    "        k = ep % len(driving_cycle_paths)\n",
    "        driving_cycle_path = driving_cycle_paths[k]\n",
    "#         driving_cycle_path = np.random.choice(driving_cycle_paths)\n",
    "        print(driving_cycle_path)\n",
    "        env = initialization_env(driving_cycle_path, 10)\n",
    "        \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
    "                                                                        -DELAY_TRAINING))\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_SOCs.append(env.SOC)\n",
    "        episode_FCs.append(env.fuel_consumption) \n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        print(\n",
    "              'Episode: {}'.format(ep + 1),\n",
    "              \"Exploration P: {:.4f}\".format(eps),\n",
    "              'Total reward: {}'.format(episodic_reward), \n",
    "              \"SOC: {:.4f}\".format(env.SOC), \n",
    "              \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "              \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "        )\n",
    "        print(\"\")\n",
    "        \n",
    "        if (ep + 1) % 10 == 0: \n",
    "            history = test_agent(actor_model, 10, -1)\n",
    "            episode_test_history.append(history) \n",
    "            episode_num_test.append(ep + 1)\n",
    "    \n",
    "    root = \"DDPG3_trial{}\".format(trial+1)\n",
    "    save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "    \n",
    "    results_dict[trial + 1] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs, \n",
    "        \"test_history\": episode_test_history, \n",
    "        \"test_episode_num\": episode_num_test, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDPG3.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
