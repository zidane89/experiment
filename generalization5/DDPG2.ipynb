{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "\n",
    "from vehicle_model_DDPG1 import Environment \n",
    "from cell_model import CellModel \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_nimh_6_240_panasonic_MY01_Prius.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_pm_95_145_X2.mat\"\n",
    "cell_model = CellModel()\n",
    "env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):      \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    inputs_batchnorm = layers.BatchNormalization()(inputs)\n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs_batchnorm)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_input_batchnorm = layers.BatchNormalization()(state_input)\n",
    "    \n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input_batchnorm)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 300\n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 10000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "\n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_model, critic_model, target_actor, target_critic, root): \n",
    "    actor_model.save_weights(\"./{}/actor_model_checkpoint\".format(root))\n",
    "    critic_model.save_weights(\"./{}/critic_model_checkpoint\".format(root))\n",
    "    target_actor.save_weights(\"./{}/target_actor_checkpoint\".format(root))\n",
    "    target_critic.save_weights(\"./{}/target_critic_checkpoint\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_env(driving_path, reward_factor):\n",
    "    env = Environment(cell_model, driving_path, battery_path, motor_path, reward_factor)\n",
    "    return env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(actor_model, reward_factor, test_path_start):\n",
    "    test_cycles = glob.glob(\"../data/driving_cycles/city/*.mat\")[test_path_start:]\n",
    "    test_cycle = np.random.choice(test_cycles)\n",
    "    env = initialization_env(test_cycle, reward_factor)\n",
    "    \n",
    "    total_reward = 0\n",
    "    state = env.reset() \n",
    "    while True: \n",
    "        tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "        action = policy_epsilon_greedy(tf_state, -1)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        \n",
    "        state = next_state \n",
    "        total_reward += reward \n",
    "        \n",
    "        if done: \n",
    "            break \n",
    "        \n",
    "    SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "    \n",
    "    print(\"******************* Test is start *****************\")\n",
    "    print(test_cycle)\n",
    "    print('Total reward: {}'.format(total_reward), \n",
    "          \"SOC: {:.4f}\".format(env.SOC), \n",
    "          \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "          \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption))\n",
    "    print(\"******************* Test is done *****************\")\n",
    "    print(\"\")\n",
    "    return env.history \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "Trial 0\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 13.938\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -3687.233783860015 SOC: 1.0000 Cumulative_SOC_deviation: 356.6410 Fuel Consumption: 120.8237\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.616\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -3696.2477246492517 SOC: 1.0000 Cumulative_SOC_deviation: 357.6711 Fuel Consumption: 119.5366\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.907\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -3898.296379230762 SOC: 1.0000 Cumulative_SOC_deviation: 377.6379 Fuel Consumption: 121.9175\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.737\n",
      "Episode: 4 Exploration P: 1.0000 Total reward: -3647.58304240338 SOC: 1.0000 Cumulative_SOC_deviation: 352.8702 Fuel Consumption: 118.8815\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 19.654\n",
      "Episode: 5 Exploration P: 1.0000 Total reward: -4655.345854411785 SOC: 1.0000 Cumulative_SOC_deviation: 450.0856 Fuel Consumption: 154.4901\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 15.960\n",
      "Episode: 6 Exploration P: 1.0000 Total reward: -3905.118489548355 SOC: 1.0000 Cumulative_SOC_deviation: 378.1713 Fuel Consumption: 123.4057\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 19.915\n",
      "Episode: 7 Exploration P: 1.0000 Total reward: -4680.798245482755 SOC: 1.0000 Cumulative_SOC_deviation: 452.2990 Fuel Consumption: 157.8084\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 15.344\n",
      "Episode: 8 Exploration P: 1.0000 Total reward: -3669.775437105606 SOC: 1.0000 Cumulative_SOC_deviation: 355.0279 Fuel Consumption: 119.4963\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "WARNING:tensorflow:Layer batch_normalization_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 27.024\n",
      "Episode: 9 Exploration P: 0.9949 Total reward: -3864.9637234186935 SOC: 1.0000 Cumulative_SOC_deviation: 374.5109 Fuel Consumption: 119.8547\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.816\n",
      "Episode: 10 Exploration P: 0.9742 Total reward: -3660.9390212690623 SOC: 1.0000 Cumulative_SOC_deviation: 354.3253 Fuel Consumption: 117.6864\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.449\n",
      "Episode: 11 Exploration P: 0.9481 Total reward: -4591.257671575613 SOC: 1.0000 Cumulative_SOC_deviation: 444.2482 Fuel Consumption: 148.7757\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.713\n",
      "Episode: 12 Exploration P: 0.9284 Total reward: -3561.3599644784426 SOC: 1.0000 Cumulative_SOC_deviation: 344.7641 Fuel Consumption: 113.7188\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.982\n",
      "Episode: 13 Exploration P: 0.9091 Total reward: -3576.817813829791 SOC: 1.0000 Cumulative_SOC_deviation: 346.3567 Fuel Consumption: 113.2505\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.955\n",
      "Episode: 14 Exploration P: 0.8897 Total reward: -3770.8682858840893 SOC: 1.0000 Cumulative_SOC_deviation: 366.2847 Fuel Consumption: 108.0209\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.857\n",
      "Episode: 15 Exploration P: 0.8708 Total reward: -3798.7192709039437 SOC: 1.0000 Cumulative_SOC_deviation: 369.5413 Fuel Consumption: 103.3063\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.074\n",
      "Episode: 16 Exploration P: 0.8527 Total reward: -3371.2196678015057 SOC: 1.0000 Cumulative_SOC_deviation: 326.9717 Fuel Consumption: 101.5028\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.102\n",
      "Episode: 17 Exploration P: 0.8299 Total reward: -4219.178812662392 SOC: 1.0000 Cumulative_SOC_deviation: 408.8112 Fuel Consumption: 131.0666\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.054\n",
      "Episode: 18 Exploration P: 0.8122 Total reward: -3738.6139291942754 SOC: 1.0000 Cumulative_SOC_deviation: 363.8715 Fuel Consumption: 99.8989\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.013\n",
      "Episode: 19 Exploration P: 0.7953 Total reward: -3344.0290700243504 SOC: 1.0000 Cumulative_SOC_deviation: 324.4546 Fuel Consumption: 99.4831\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.672\n",
      "Episode: 20 Exploration P: 0.7741 Total reward: -4078.209313740334 SOC: 1.0000 Cumulative_SOC_deviation: 395.1435 Fuel Consumption: 126.7744\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.738\n",
      "Episode: 21 Exploration P: 0.7576 Total reward: -3639.209894764206 SOC: 1.0000 Cumulative_SOC_deviation: 354.5022 Fuel Consumption: 94.1874\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.959\n",
      "Episode: 22 Exploration P: 0.7415 Total reward: -3631.233528033516 SOC: 1.0000 Cumulative_SOC_deviation: 353.8431 Fuel Consumption: 92.8027\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.029\n",
      "Episode: 23 Exploration P: 0.7257 Total reward: -3719.311249542513 SOC: 1.0000 Cumulative_SOC_deviation: 362.7649 Fuel Consumption: 91.6621\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.967\n",
      "Episode: 24 Exploration P: 0.7103 Total reward: -3623.5352451845883 SOC: 1.0000 Cumulative_SOC_deviation: 353.7254 Fuel Consumption: 86.2810\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.224\n",
      "Episode: 25 Exploration P: 0.6913 Total reward: -3692.5683658179423 SOC: 1.0000 Cumulative_SOC_deviation: 358.0199 Fuel Consumption: 112.3693\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.173\n",
      "Episode: 26 Exploration P: 0.6766 Total reward: -3549.497092702945 SOC: 1.0000 Cumulative_SOC_deviation: 346.4158 Fuel Consumption: 85.3386\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.316\n",
      "Episode: 27 Exploration P: 0.6626 Total reward: -3014.624514386814 SOC: 1.0000 Cumulative_SOC_deviation: 293.2046 Fuel Consumption: 82.5785\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.479\n",
      "Episode: 28 Exploration P: 0.6489 Total reward: -2936.2008685533574 SOC: 1.0000 Cumulative_SOC_deviation: 285.1835 Fuel Consumption: 84.3655\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.077\n",
      "Episode: 29 Exploration P: 0.6351 Total reward: -3445.0996652689214 SOC: 1.0000 Cumulative_SOC_deviation: 336.7242 Fuel Consumption: 77.8574\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.539\n",
      "Episode: 30 Exploration P: 0.6220 Total reward: -2903.6378610876545 SOC: 1.0000 Cumulative_SOC_deviation: 282.1341 Fuel Consumption: 82.2969\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.135\n",
      "Episode: 31 Exploration P: 0.6054 Total reward: -3368.96873859821 SOC: 1.0000 Cumulative_SOC_deviation: 326.7456 Fuel Consumption: 101.5122\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.665\n",
      "Episode: 32 Exploration P: 0.5926 Total reward: -3395.263194467815 SOC: 1.0000 Cumulative_SOC_deviation: 332.0848 Fuel Consumption: 74.4155\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.340\n",
      "Episode: 33 Exploration P: 0.5768 Total reward: -2969.4541612829717 SOC: 1.0000 Cumulative_SOC_deviation: 287.6090 Fuel Consumption: 93.3645\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.429\n",
      "Episode: 34 Exploration P: 0.5649 Total reward: -1981.9281299950987 SOC: 0.8978 Cumulative_SOC_deviation: 191.2488 Fuel Consumption: 69.4403\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.423\n",
      "Episode: 35 Exploration P: 0.5532 Total reward: -2242.7528502859805 SOC: 0.9246 Cumulative_SOC_deviation: 217.1385 Fuel Consumption: 71.3681\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.944\n",
      "Episode: 36 Exploration P: 0.5418 Total reward: -1665.6208733762292 SOC: 0.8275 Cumulative_SOC_deviation: 160.1794 Fuel Consumption: 63.8265\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.787\n",
      "Episode: 37 Exploration P: 0.5307 Total reward: -2039.5494971028147 SOC: 0.8977 Cumulative_SOC_deviation: 196.9968 Fuel Consumption: 69.5811\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.380\n",
      "Episode: 38 Exploration P: 0.5194 Total reward: -3286.740631834446 SOC: 1.0000 Cumulative_SOC_deviation: 322.1108 Fuel Consumption: 65.6328\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.505\n",
      "Episode: 39 Exploration P: 0.5087 Total reward: -1908.7012289121049 SOC: 0.8462 Cumulative_SOC_deviation: 184.3148 Fuel Consumption: 65.5532\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.111\n",
      "Episode: 40 Exploration P: 0.4952 Total reward: -2189.150554194154 SOC: 1.0000 Cumulative_SOC_deviation: 210.5230 Fuel Consumption: 83.9209\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.115\n",
      "Episode: 41 Exploration P: 0.4851 Total reward: -1425.0940276584918 SOC: 0.7741 Cumulative_SOC_deviation: 136.5689 Fuel Consumption: 59.4050\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.899\n",
      "Episode: 42 Exploration P: 0.4722 Total reward: -2043.1596699169336 SOC: 1.0000 Cumulative_SOC_deviation: 196.1764 Fuel Consumption: 81.3956\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.539\n",
      "Episode: 43 Exploration P: 0.4625 Total reward: -1761.2439884667363 SOC: 0.8242 Cumulative_SOC_deviation: 169.7507 Fuel Consumption: 63.7374\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.689\n",
      "Episode: 44 Exploration P: 0.4527 Total reward: -3160.2922995748595 SOC: 1.0000 Cumulative_SOC_deviation: 310.2322 Fuel Consumption: 57.9706\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.936\n",
      "Episode: 45 Exploration P: 0.4407 Total reward: -1763.3471844972132 SOC: 0.9564 Cumulative_SOC_deviation: 168.7459 Fuel Consumption: 75.8881\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.758\n",
      "Episode: 46 Exploration P: 0.4314 Total reward: -2933.8641376142964 SOC: 1.0000 Cumulative_SOC_deviation: 287.7267 Fuel Consumption: 56.5973\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.330\n",
      "Episode: 47 Exploration P: 0.4200 Total reward: -1469.5104641699054 SOC: 0.9046 Cumulative_SOC_deviation: 139.7762 Fuel Consumption: 71.7481\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.836\n",
      "Episode: 48 Exploration P: 0.4112 Total reward: -2883.0506164588883 SOC: 1.0000 Cumulative_SOC_deviation: 283.0806 Fuel Consumption: 52.2447\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.821\n",
      "Episode: 49 Exploration P: 0.4003 Total reward: -1219.5283872711814 SOC: 0.8464 Cumulative_SOC_deviation: 115.2538 Fuel Consumption: 66.9904\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.359\n",
      "Episode: 50 Exploration P: 0.3897 Total reward: -1141.2621760215266 SOC: 0.8415 Cumulative_SOC_deviation: 107.4381 Fuel Consumption: 66.8813\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.207\n",
      "Episode: 51 Exploration P: 0.3818 Total reward: -1029.02981886419 SOC: 0.6602 Cumulative_SOC_deviation: 97.7796 Fuel Consumption: 51.2342\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.545\n",
      "Episode: 52 Exploration P: 0.3738 Total reward: -2777.14977390484 SOC: 1.0000 Cumulative_SOC_deviation: 272.6744 Fuel Consumption: 50.4060\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.831\n",
      "Episode: 53 Exploration P: 0.3659 Total reward: -2718.4135754775384 SOC: 1.0000 Cumulative_SOC_deviation: 267.0226 Fuel Consumption: 48.1881\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.816\n",
      "Episode: 54 Exploration P: 0.3582 Total reward: -2497.956049741504 SOC: 1.0000 Cumulative_SOC_deviation: 245.3037 Fuel Consumption: 44.9186\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.264\n",
      "Episode: 55 Exploration P: 0.3509 Total reward: -988.406531313655 SOC: 0.6134 Cumulative_SOC_deviation: 94.1149 Fuel Consumption: 47.2580\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.972\n",
      "Episode: 56 Exploration P: 0.3438 Total reward: -880.3746256330242 SOC: 0.6418 Cumulative_SOC_deviation: 83.0991 Fuel Consumption: 49.3840\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.956\n",
      "Episode: 57 Exploration P: 0.3347 Total reward: -779.9258758687926 SOC: 0.7258 Cumulative_SOC_deviation: 72.1804 Fuel Consumption: 58.1215\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.617\n",
      "Episode: 58 Exploration P: 0.3279 Total reward: -1063.841331887164 SOC: 0.5732 Cumulative_SOC_deviation: 101.9201 Fuel Consumption: 44.6407\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.426\n",
      "Episode: 59 Exploration P: 0.3211 Total reward: -2564.3759226823613 SOC: 1.0000 Cumulative_SOC_deviation: 251.7282 Fuel Consumption: 47.0935\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.060\n",
      "Episode: 60 Exploration P: 0.3145 Total reward: -1087.490940145284 SOC: 0.5369 Cumulative_SOC_deviation: 104.5410 Fuel Consumption: 42.0809\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.983\n",
      "Episode: 61 Exploration P: 0.3063 Total reward: -1009.771980540473 SOC: 0.6676 Cumulative_SOC_deviation: 95.5423 Fuel Consumption: 54.3493\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.186\n",
      "Episode: 62 Exploration P: 0.3001 Total reward: -1199.8938441292007 SOC: 0.4749 Cumulative_SOC_deviation: 116.2674 Fuel Consumption: 37.2198\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.815\n",
      "Episode: 63 Exploration P: 0.2940 Total reward: -989.7557726848406 SOC: 0.5398 Cumulative_SOC_deviation: 94.7571 Fuel Consumption: 42.1843\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.003\n",
      "Episode: 64 Exploration P: 0.2880 Total reward: -1191.5693328767734 SOC: 0.4554 Cumulative_SOC_deviation: 115.5953 Fuel Consumption: 35.6167\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.071\n",
      "Episode: 65 Exploration P: 0.2820 Total reward: -2026.8439478900184 SOC: 0.9521 Cumulative_SOC_deviation: 198.9375 Fuel Consumption: 37.4690\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.843\n",
      "Episode: 66 Exploration P: 0.2746 Total reward: -1418.963599124281 SOC: 0.5720 Cumulative_SOC_deviation: 137.2733 Fuel Consumption: 46.2303\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.742\n",
      "Episode: 67 Exploration P: 0.2689 Total reward: -1870.5548826674112 SOC: 0.9268 Cumulative_SOC_deviation: 183.5335 Fuel Consumption: 35.2194\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.030\n",
      "Episode: 68 Exploration P: 0.2619 Total reward: -1444.1410153365346 SOC: 0.5428 Cumulative_SOC_deviation: 140.0370 Fuel Consumption: 43.7710\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.533\n",
      "Episode: 69 Exploration P: 0.2565 Total reward: -1982.3647909800538 SOC: 0.9600 Cumulative_SOC_deviation: 194.4206 Fuel Consumption: 38.1585\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.761\n",
      "Episode: 70 Exploration P: 0.2498 Total reward: -1741.0913901616202 SOC: 0.5290 Cumulative_SOC_deviation: 169.8277 Fuel Consumption: 42.8143\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.843\n",
      "Episode: 71 Exploration P: 0.2446 Total reward: -1691.757112568268 SOC: 0.8919 Cumulative_SOC_deviation: 165.9434 Fuel Consumption: 32.3234\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.566\n",
      "Episode: 72 Exploration P: 0.2396 Total reward: -1674.0564861059183 SOC: 0.9149 Cumulative_SOC_deviation: 164.0001 Fuel Consumption: 34.0558\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.496\n",
      "Episode: 73 Exploration P: 0.2348 Total reward: -1315.9234077251467 SOC: 0.3965 Cumulative_SOC_deviation: 128.4418 Fuel Consumption: 31.5054\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.098\n",
      "Episode: 74 Exploration P: 0.2299 Total reward: -1568.3682616325923 SOC: 0.9101 Cumulative_SOC_deviation: 153.4623 Fuel Consumption: 33.7456\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.664\n",
      "Episode: 75 Exploration P: 0.2253 Total reward: -1392.4859587332353 SOC: 0.3711 Cumulative_SOC_deviation: 136.2828 Fuel Consumption: 29.6581\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.970\n",
      "Episode: 76 Exploration P: 0.2207 Total reward: -1479.4229545462408 SOC: 0.8537 Cumulative_SOC_deviation: 145.0021 Fuel Consumption: 29.4016\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.033\n",
      "Episode: 77 Exploration P: 0.2161 Total reward: -1290.9458986381806 SOC: 0.8519 Cumulative_SOC_deviation: 126.1777 Fuel Consumption: 29.1689\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.420\n",
      "Episode: 78 Exploration P: 0.2118 Total reward: -1301.1281650245603 SOC: 0.3628 Cumulative_SOC_deviation: 127.2467 Fuel Consumption: 28.6612\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.799\n",
      "Episode: 79 Exploration P: 0.2075 Total reward: -1316.330860753491 SOC: 0.3608 Cumulative_SOC_deviation: 128.7802 Fuel Consumption: 28.5290\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.134\n",
      "Episode: 80 Exploration P: 0.2034 Total reward: -1217.9274251155002 SOC: 0.3801 Cumulative_SOC_deviation: 118.8103 Fuel Consumption: 29.8247\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.495\n",
      "Episode: 81 Exploration P: 0.1982 Total reward: -2814.5279910066647 SOC: 0.3768 Cumulative_SOC_deviation: 278.3232 Fuel Consumption: 31.2965\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.836\n",
      "Episode: 82 Exploration P: 0.1942 Total reward: -1421.722938883255 SOC: 0.3278 Cumulative_SOC_deviation: 139.5466 Fuel Consumption: 26.2565\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.963\n",
      "Episode: 83 Exploration P: 0.1892 Total reward: -2658.642708131141 SOC: 0.4012 Cumulative_SOC_deviation: 262.5413 Fuel Consumption: 33.2300\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.759\n",
      "Episode: 84 Exploration P: 0.1854 Total reward: -1127.293463494329 SOC: 0.7987 Cumulative_SOC_deviation: 110.2365 Fuel Consumption: 24.9284\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.022\n",
      "Episode: 85 Exploration P: 0.1806 Total reward: -2599.5431032285246 SOC: 0.4067 Cumulative_SOC_deviation: 256.6115 Fuel Consumption: 33.4282\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.747\n",
      "Episode: 86 Exploration P: 0.1769 Total reward: -1213.9476353684508 SOC: 0.8035 Cumulative_SOC_deviation: 118.8735 Fuel Consumption: 25.2128\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.965\n",
      "Episode: 87 Exploration P: 0.1734 Total reward: -1455.4753706026913 SOC: 0.3135 Cumulative_SOC_deviation: 142.9995 Fuel Consumption: 25.4808\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.960\n",
      "Episode: 88 Exploration P: 0.1700 Total reward: -1502.5134908207963 SOC: 0.2950 Cumulative_SOC_deviation: 147.8274 Fuel Consumption: 24.2396\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.098\n",
      "Episode: 89 Exploration P: 0.1665 Total reward: -1073.7155393342284 SOC: 0.7967 Cumulative_SOC_deviation: 104.9201 Fuel Consumption: 24.5147\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.380\n",
      "Episode: 90 Exploration P: 0.1633 Total reward: -1556.1915722932508 SOC: 0.2711 Cumulative_SOC_deviation: 153.3658 Fuel Consumption: 22.5331\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.900\n",
      "Episode: 91 Exploration P: 0.1591 Total reward: -2776.5985890757565 SOC: 0.3898 Cumulative_SOC_deviation: 274.4006 Fuel Consumption: 32.5922\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.983\n",
      "Episode: 92 Exploration P: 0.1551 Total reward: -3199.7180425391734 SOC: 0.3254 Cumulative_SOC_deviation: 317.2033 Fuel Consumption: 27.6851\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.772\n",
      "Episode: 93 Exploration P: 0.1511 Total reward: -2907.9026517871944 SOC: 0.3485 Cumulative_SOC_deviation: 287.8738 Fuel Consumption: 29.1647\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.927\n",
      "Episode: 94 Exploration P: 0.1481 Total reward: -783.4521463586045 SOC: 0.7574 Cumulative_SOC_deviation: 76.2221 Fuel Consumption: 21.2308\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.763\n",
      "Episode: 95 Exploration P: 0.1451 Total reward: -846.7111822054417 SOC: 0.7471 Cumulative_SOC_deviation: 82.6282 Fuel Consumption: 20.4293\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.611\n",
      "Episode: 96 Exploration P: 0.1422 Total reward: -647.559891916577 SOC: 0.7261 Cumulative_SOC_deviation: 62.8837 Fuel Consumption: 18.7227\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.607\n",
      "Episode: 97 Exploration P: 0.1386 Total reward: -3224.1980627481576 SOC: 0.3102 Cumulative_SOC_deviation: 319.8013 Fuel Consumption: 26.1854\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.825\n",
      "Episode: 98 Exploration P: 0.1351 Total reward: -3038.678001893814 SOC: 0.3340 Cumulative_SOC_deviation: 301.0685 Fuel Consumption: 27.9925\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.644\n",
      "Episode: 99 Exploration P: 0.1324 Total reward: -829.4423168398718 SOC: 0.7392 Cumulative_SOC_deviation: 80.9375 Fuel Consumption: 20.0673\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.684\n",
      "Episode: 100 Exploration P: 0.1298 Total reward: -752.3141860949424 SOC: 0.7358 Cumulative_SOC_deviation: 73.2583 Fuel Consumption: 19.7311\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.445\n",
      "Episode: 101 Exploration P: 0.1272 Total reward: -605.2667842234897 SOC: 0.7193 Cumulative_SOC_deviation: 58.6828 Fuel Consumption: 18.4383\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.080\n",
      "Episode: 102 Exploration P: 0.1240 Total reward: -3826.3938619366695 SOC: 0.2417 Cumulative_SOC_deviation: 380.5015 Fuel Consumption: 21.3789\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.579\n",
      "Episode: 103 Exploration P: 0.1216 Total reward: -292.54272132794955 SOC: 0.6493 Cumulative_SOC_deviation: 24.5132 Fuel Consumption: 47.4107\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.286\n",
      "Episode: 104 Exploration P: 0.1193 Total reward: -266.57336792315283 SOC: 0.6395 Cumulative_SOC_deviation: 22.1086 Fuel Consumption: 45.4877\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.246\n",
      "Episode: 105 Exploration P: 0.1163 Total reward: -147.7223081661755 SOC: 0.6182 Cumulative_SOC_deviation: 10.1657 Fuel Consumption: 46.0650\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.391\n",
      "Episode: 106 Exploration P: 0.1140 Total reward: -628.5973279180514 SOC: 0.7081 Cumulative_SOC_deviation: 61.1260 Fuel Consumption: 17.3377\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.120\n",
      "Episode: 107 Exploration P: 0.1118 Total reward: -628.7214226331782 SOC: 0.7005 Cumulative_SOC_deviation: 61.2007 Fuel Consumption: 16.7145\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.318\n",
      "Episode: 108 Exploration P: 0.1090 Total reward: -127.67800395651263 SOC: 0.6128 Cumulative_SOC_deviation: 8.2480 Fuel Consumption: 45.1977\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.014\n",
      "Episode: 109 Exploration P: 0.1064 Total reward: -117.01839720947568 SOC: 0.6045 Cumulative_SOC_deviation: 7.2517 Fuel Consumption: 44.5014\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.021\n",
      "Episode: 110 Exploration P: 0.1038 Total reward: -116.25212894845377 SOC: 0.6079 Cumulative_SOC_deviation: 7.0932 Fuel Consumption: 45.3203\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -67.16309046769231 SOC: 0.6020 Cumulative_SOC_deviation: 5.4502 Fuel Consumption: 12.6615\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.534\n",
      "Episode: 111 Exploration P: 0.1012 Total reward: -106.29569223582837 SOC: 0.6019 Cumulative_SOC_deviation: 6.2012 Fuel Consumption: 44.2839\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.534\n",
      "Episode: 112 Exploration P: 0.0993 Total reward: -250.35648993596695 SOC: 0.6354 Cumulative_SOC_deviation: 20.4406 Fuel Consumption: 45.9506\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.960\n",
      "Episode: 113 Exploration P: 0.0974 Total reward: -196.1253169109327 SOC: 0.6257 Cumulative_SOC_deviation: 15.1219 Fuel Consumption: 44.9063\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.124\n",
      "Episode: 114 Exploration P: 0.0956 Total reward: -193.50111259315335 SOC: 0.6190 Cumulative_SOC_deviation: 14.9324 Fuel Consumption: 44.1767\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.725\n",
      "Episode: 115 Exploration P: 0.0938 Total reward: -229.91003779045698 SOC: 0.6322 Cumulative_SOC_deviation: 18.4488 Fuel Consumption: 45.4225\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.781\n",
      "Episode: 116 Exploration P: 0.0920 Total reward: -216.63011994488005 SOC: 0.6321 Cumulative_SOC_deviation: 17.1303 Fuel Consumption: 45.3270\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.741\n",
      "Episode: 117 Exploration P: 0.0898 Total reward: -116.55585759425179 SOC: 0.5991 Cumulative_SOC_deviation: 7.2352 Fuel Consumption: 44.2034\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.274\n",
      "Episode: 118 Exploration P: 0.0881 Total reward: -166.1208625557465 SOC: 0.6246 Cumulative_SOC_deviation: 12.1543 Fuel Consumption: 44.5779\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.101\n",
      "Episode: 119 Exploration P: 0.0860 Total reward: -111.53084548654336 SOC: 0.6108 Cumulative_SOC_deviation: 6.6580 Fuel Consumption: 44.9510\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.510\n",
      "Episode: 120 Exploration P: 0.0844 Total reward: -285.71760351117894 SOC: 0.6433 Cumulative_SOC_deviation: 27.3308 Fuel Consumption: 12.4097\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -77.44091254199726 SOC: 0.5971 Cumulative_SOC_deviation: 6.4720 Fuel Consumption: 12.7206\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.099\n",
      "Episode: 121 Exploration P: 0.0828 Total reward: -360.11074832119454 SOC: 0.6652 Cumulative_SOC_deviation: 34.6021 Fuel Consumption: 14.0896\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.452\n",
      "Episode: 122 Exploration P: 0.0812 Total reward: -148.02460907563758 SOC: 0.6223 Cumulative_SOC_deviation: 10.3823 Fuel Consumption: 44.2020\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.716\n",
      "Episode: 123 Exploration P: 0.0793 Total reward: -127.45703547482287 SOC: 0.5982 Cumulative_SOC_deviation: 8.3766 Fuel Consumption: 43.6907\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.461\n",
      "Episode: 124 Exploration P: 0.0774 Total reward: -129.7005472212509 SOC: 0.5996 Cumulative_SOC_deviation: 8.5637 Fuel Consumption: 44.0634\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.444\n",
      "Episode: 125 Exploration P: 0.0760 Total reward: -148.04485370562338 SOC: 0.6104 Cumulative_SOC_deviation: 10.4559 Fuel Consumption: 43.4859\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.865\n",
      "Episode: 126 Exploration P: 0.0746 Total reward: -189.26497753098027 SOC: 0.6293 Cumulative_SOC_deviation: 14.4033 Fuel Consumption: 45.2324\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.861\n",
      "Episode: 127 Exploration P: 0.0732 Total reward: -418.13465757061505 SOC: 0.6532 Cumulative_SOC_deviation: 40.5100 Fuel Consumption: 13.0342\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.581\n",
      "Episode: 128 Exploration P: 0.0719 Total reward: -259.6232230518288 SOC: 0.6427 Cumulative_SOC_deviation: 24.7287 Fuel Consumption: 12.3361\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.845\n",
      "Episode: 129 Exploration P: 0.0702 Total reward: -139.95099168203842 SOC: 0.6031 Cumulative_SOC_deviation: 9.5852 Fuel Consumption: 44.0993\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.437\n",
      "Episode: 130 Exploration P: 0.0689 Total reward: -168.81362640170818 SOC: 0.6254 Cumulative_SOC_deviation: 12.4070 Fuel Consumption: 44.7438\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -91.88072497609062 SOC: 0.5915 Cumulative_SOC_deviation: 7.9801 Fuel Consumption: 12.0794\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.377\n",
      "Episode: 131 Exploration P: 0.0673 Total reward: -139.04217664541932 SOC: 0.5999 Cumulative_SOC_deviation: 9.5141 Fuel Consumption: 43.9016\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.141\n",
      "Episode: 132 Exploration P: 0.0661 Total reward: -164.96757952871278 SOC: 0.6338 Cumulative_SOC_deviation: 15.3666 Fuel Consumption: 11.3018\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.155\n",
      "Episode: 133 Exploration P: 0.0649 Total reward: -134.37598667913423 SOC: 0.6191 Cumulative_SOC_deviation: 12.4168 Fuel Consumption: 10.2079\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.357\n",
      "Episode: 134 Exploration P: 0.0634 Total reward: -150.0923676721984 SOC: 0.6005 Cumulative_SOC_deviation: 10.6114 Fuel Consumption: 43.9783\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.628\n",
      "Episode: 135 Exploration P: 0.0620 Total reward: -162.42857397661643 SOC: 0.5974 Cumulative_SOC_deviation: 11.8190 Fuel Consumption: 44.2386\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.981\n",
      "Episode: 136 Exploration P: 0.0609 Total reward: -129.52558676391996 SOC: 0.6084 Cumulative_SOC_deviation: 8.6423 Fuel Consumption: 43.1027\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.170\n",
      "Episode: 137 Exploration P: 0.0598 Total reward: -132.65475310737713 SOC: 0.6101 Cumulative_SOC_deviation: 8.9617 Fuel Consumption: 43.0374\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.101\n",
      "Episode: 138 Exploration P: 0.0588 Total reward: -143.9004076766626 SOC: 0.6260 Cumulative_SOC_deviation: 9.9778 Fuel Consumption: 44.1228\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.898\n",
      "Episode: 139 Exploration P: 0.0574 Total reward: -149.86868493573448 SOC: 0.5980 Cumulative_SOC_deviation: 10.5905 Fuel Consumption: 43.9638\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.351\n",
      "Episode: 140 Exploration P: 0.0564 Total reward: -161.03560015293792 SOC: 0.6259 Cumulative_SOC_deviation: 11.7349 Fuel Consumption: 43.6864\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -79.53014290373024 SOC: 0.5934 Cumulative_SOC_deviation: 6.7202 Fuel Consumption: 12.3277\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.644\n",
      "Episode: 141 Exploration P: 0.0554 Total reward: -94.97948122134763 SOC: 0.6210 Cumulative_SOC_deviation: 8.4484 Fuel Consumption: 10.4958\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.254\n",
      "Episode: 142 Exploration P: 0.0545 Total reward: -133.0829244620973 SOC: 0.6034 Cumulative_SOC_deviation: 9.0870 Fuel Consumption: 42.2134\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.475\n",
      "Episode: 143 Exploration P: 0.0536 Total reward: -158.14899531156271 SOC: 0.6106 Cumulative_SOC_deviation: 11.4975 Fuel Consumption: 43.1737\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.255\n",
      "Episode: 144 Exploration P: 0.0526 Total reward: -54.78112580790255 SOC: 0.6052 Cumulative_SOC_deviation: 4.5739 Fuel Consumption: 9.0419\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.203\n",
      "Episode: 145 Exploration P: 0.0515 Total reward: -162.13516040106023 SOC: 0.5968 Cumulative_SOC_deviation: 11.9023 Fuel Consumption: 43.1122\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.737\n",
      "Episode: 146 Exploration P: 0.0503 Total reward: -195.8030028104708 SOC: 0.5965 Cumulative_SOC_deviation: 15.2030 Fuel Consumption: 43.7734\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.353\n",
      "Episode: 147 Exploration P: 0.0492 Total reward: -162.83689229748543 SOC: 0.5951 Cumulative_SOC_deviation: 11.9932 Fuel Consumption: 42.9046\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.845\n",
      "Episode: 148 Exploration P: 0.0482 Total reward: -201.42848493666102 SOC: 0.5887 Cumulative_SOC_deviation: 15.8389 Fuel Consumption: 43.0390\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.144\n",
      "Episode: 149 Exploration P: 0.0474 Total reward: -118.00158531558893 SOC: 0.6215 Cumulative_SOC_deviation: 7.4671 Fuel Consumption: 43.3310\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.273\n",
      "Episode: 150 Exploration P: 0.0464 Total reward: -198.75642791201986 SOC: 0.5928 Cumulative_SOC_deviation: 15.5554 Fuel Consumption: 43.2029\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -96.44853012454789 SOC: 0.5886 Cumulative_SOC_deviation: 8.4224 Fuel Consumption: 12.2241\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.195\n",
      "Episode: 151 Exploration P: 0.0456 Total reward: -46.79706706153372 SOC: 0.6053 Cumulative_SOC_deviation: 3.7538 Fuel Consumption: 9.2591\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.124\n",
      "Episode: 152 Exploration P: 0.0448 Total reward: -124.7838757519593 SOC: 0.6047 Cumulative_SOC_deviation: 8.2447 Fuel Consumption: 42.3368\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.288\n",
      "Episode: 153 Exploration P: 0.0439 Total reward: -173.56825077320136 SOC: 0.6010 Cumulative_SOC_deviation: 12.9739 Fuel Consumption: 43.8295\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.115\n",
      "Episode: 154 Exploration P: 0.0432 Total reward: -137.853402495067 SOC: 0.6089 Cumulative_SOC_deviation: 9.5592 Fuel Consumption: 42.2615\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.237\n",
      "Episode: 155 Exploration P: 0.0425 Total reward: -132.1011731222225 SOC: 0.6094 Cumulative_SOC_deviation: 8.9738 Fuel Consumption: 42.3627\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.164\n",
      "Episode: 156 Exploration P: 0.0418 Total reward: -57.05167161752971 SOC: 0.6070 Cumulative_SOC_deviation: 4.7838 Fuel Consumption: 9.2133\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.617\n",
      "Episode: 157 Exploration P: 0.0411 Total reward: -106.70569273504593 SOC: 0.6063 Cumulative_SOC_deviation: 6.4982 Fuel Consumption: 41.7241\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.924\n",
      "Episode: 158 Exploration P: 0.0403 Total reward: -171.34450478355123 SOC: 0.6009 Cumulative_SOC_deviation: 12.7820 Fuel Consumption: 43.5242\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.160\n",
      "Episode: 159 Exploration P: 0.0396 Total reward: -130.52252073460272 SOC: 0.6056 Cumulative_SOC_deviation: 8.8494 Fuel Consumption: 42.0285\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.508\n",
      "Episode: 160 Exploration P: 0.0388 Total reward: -203.56491684748886 SOC: 0.5929 Cumulative_SOC_deviation: 16.0829 Fuel Consumption: 42.7355\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -111.61220933476116 SOC: 0.5869 Cumulative_SOC_deviation: 9.9486 Fuel Consumption: 12.1265\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.549\n",
      "Episode: 161 Exploration P: 0.0382 Total reward: -79.21558379873893 SOC: 0.5869 Cumulative_SOC_deviation: 7.1582 Fuel Consumption: 7.6337\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.993\n",
      "Episode: 162 Exploration P: 0.0374 Total reward: -210.13358630690718 SOC: 0.5951 Cumulative_SOC_deviation: 16.6714 Fuel Consumption: 43.4198\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.367\n",
      "Episode: 163 Exploration P: 0.0367 Total reward: -205.81262446090318 SOC: 0.5889 Cumulative_SOC_deviation: 16.2721 Fuel Consumption: 43.0919\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.765\n",
      "Episode: 164 Exploration P: 0.0360 Total reward: -199.99417492898178 SOC: 0.5926 Cumulative_SOC_deviation: 15.6681 Fuel Consumption: 43.3130\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.996\n",
      "Episode: 165 Exploration P: 0.0354 Total reward: -129.08729878457186 SOC: 0.6084 Cumulative_SOC_deviation: 8.6759 Fuel Consumption: 42.3288\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.246\n",
      "Episode: 166 Exploration P: 0.0349 Total reward: -129.96341245335614 SOC: 0.6098 Cumulative_SOC_deviation: 8.6736 Fuel Consumption: 43.2277\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.443\n",
      "Episode: 167 Exploration P: 0.0344 Total reward: -44.74284007530018 SOC: 0.5975 Cumulative_SOC_deviation: 3.6375 Fuel Consumption: 8.3681\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.451\n",
      "Episode: 168 Exploration P: 0.0337 Total reward: -228.52835508933114 SOC: 0.5877 Cumulative_SOC_deviation: 18.5190 Fuel Consumption: 43.3381\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.905\n",
      "Episode: 169 Exploration P: 0.0332 Total reward: -140.27160504578117 SOC: 0.6128 Cumulative_SOC_deviation: 9.7478 Fuel Consumption: 42.7939\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.586\n",
      "Episode: 170 Exploration P: 0.0327 Total reward: -50.382075516961955 SOC: 0.5989 Cumulative_SOC_deviation: 4.2063 Fuel Consumption: 8.3189\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -81.58744977392817 SOC: 0.5937 Cumulative_SOC_deviation: 6.8982 Fuel Consumption: 12.6053\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.268\n",
      "Episode: 171 Exploration P: 0.0322 Total reward: -123.61838604033956 SOC: 0.6117 Cumulative_SOC_deviation: 8.0681 Fuel Consumption: 42.9378\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.842\n",
      "Episode: 172 Exploration P: 0.0316 Total reward: -193.39694846617664 SOC: 0.5924 Cumulative_SOC_deviation: 14.9765 Fuel Consumption: 43.6320\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.457\n",
      "Episode: 173 Exploration P: 0.0312 Total reward: -118.01493249689159 SOC: 0.6040 Cumulative_SOC_deviation: 7.6431 Fuel Consumption: 41.5838\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.627\n",
      "Episode: 174 Exploration P: 0.0307 Total reward: -69.98885508860836 SOC: 0.6002 Cumulative_SOC_deviation: 6.1779 Fuel Consumption: 8.2101\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.194\n",
      "Episode: 175 Exploration P: 0.0303 Total reward: -69.8321206361671 SOC: 0.5914 Cumulative_SOC_deviation: 6.2234 Fuel Consumption: 7.5983\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.627\n",
      "Episode: 176 Exploration P: 0.0297 Total reward: -159.61605472982194 SOC: 0.6012 Cumulative_SOC_deviation: 11.6573 Fuel Consumption: 43.0427\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.907\n",
      "Episode: 177 Exploration P: 0.0293 Total reward: -113.15762661152353 SOC: 0.6091 Cumulative_SOC_deviation: 7.1288 Fuel Consumption: 41.8691\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.306\n",
      "Episode: 178 Exploration P: 0.0289 Total reward: -113.85995179730482 SOC: 0.6038 Cumulative_SOC_deviation: 7.2486 Fuel Consumption: 41.3744\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.311\n",
      "Episode: 179 Exploration P: 0.0285 Total reward: -56.333017075687756 SOC: 0.5981 Cumulative_SOC_deviation: 4.8287 Fuel Consumption: 8.0462\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.877\n",
      "Episode: 180 Exploration P: 0.0281 Total reward: -74.72494740751873 SOC: 0.5939 Cumulative_SOC_deviation: 6.6788 Fuel Consumption: 7.9367\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -126.38920022870822 SOC: 0.5830 Cumulative_SOC_deviation: 11.4361 Fuel Consumption: 12.0286\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.928\n",
      "Episode: 181 Exploration P: 0.0277 Total reward: -117.42045043570465 SOC: 0.6084 Cumulative_SOC_deviation: 7.5447 Fuel Consumption: 41.9737\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.147\n",
      "Episode: 182 Exploration P: 0.0272 Total reward: -189.00460228024176 SOC: 0.5910 Cumulative_SOC_deviation: 14.6347 Fuel Consumption: 42.6574\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.068\n",
      "Episode: 183 Exploration P: 0.0269 Total reward: -52.35958203937695 SOC: 0.5948 Cumulative_SOC_deviation: 4.4602 Fuel Consumption: 7.7574\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.880\n",
      "Episode: 184 Exploration P: 0.0265 Total reward: -112.4667131506083 SOC: 0.6028 Cumulative_SOC_deviation: 7.1007 Fuel Consumption: 41.4596\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.147\n",
      "Episode: 185 Exploration P: 0.0262 Total reward: -37.150336246849854 SOC: 0.5908 Cumulative_SOC_deviation: 2.9369 Fuel Consumption: 7.7817\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.948\n",
      "Episode: 186 Exploration P: 0.0257 Total reward: -195.3437059206715 SOC: 0.5934 Cumulative_SOC_deviation: 15.2144 Fuel Consumption: 43.1997\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.824\n",
      "Episode: 187 Exploration P: 0.0254 Total reward: -127.2361222346096 SOC: 0.6066 Cumulative_SOC_deviation: 8.5646 Fuel Consumption: 41.5903\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.577\n",
      "Episode: 188 Exploration P: 0.0250 Total reward: -168.86122800420964 SOC: 0.5900 Cumulative_SOC_deviation: 12.6727 Fuel Consumption: 42.1345\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.448\n",
      "Episode: 189 Exploration P: 0.0246 Total reward: -198.80995346464954 SOC: 0.5930 Cumulative_SOC_deviation: 15.6411 Fuel Consumption: 42.3988\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.430\n",
      "Episode: 190 Exploration P: 0.0243 Total reward: -114.96727670767761 SOC: 0.6027 Cumulative_SOC_deviation: 7.3748 Fuel Consumption: 41.2192\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -76.98485174831669 SOC: 0.5936 Cumulative_SOC_deviation: 6.4693 Fuel Consumption: 12.2921\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.944\n",
      "Episode: 191 Exploration P: 0.0239 Total reward: -193.9911869583302 SOC: 0.5926 Cumulative_SOC_deviation: 15.1755 Fuel Consumption: 42.2358\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.371\n",
      "Episode: 192 Exploration P: 0.0235 Total reward: -176.21318220858478 SOC: 0.5961 Cumulative_SOC_deviation: 13.3573 Fuel Consumption: 42.6398\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.355\n",
      "Episode: 193 Exploration P: 0.0232 Total reward: -62.43685154806396 SOC: 0.5986 Cumulative_SOC_deviation: 5.4319 Fuel Consumption: 8.1179\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.083\n",
      "Episode: 194 Exploration P: 0.0229 Total reward: -122.69413225129905 SOC: 0.6010 Cumulative_SOC_deviation: 8.1387 Fuel Consumption: 41.3074\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.106\n",
      "Episode: 195 Exploration P: 0.0226 Total reward: -62.24367134613062 SOC: 0.5941 Cumulative_SOC_deviation: 5.4475 Fuel Consumption: 7.7686\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.602\n",
      "Episode: 196 Exploration P: 0.0224 Total reward: -64.4596084389791 SOC: 0.5962 Cumulative_SOC_deviation: 5.6570 Fuel Consumption: 7.8893\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.360\n",
      "Episode: 197 Exploration P: 0.0221 Total reward: -118.71703368565433 SOC: 0.6073 Cumulative_SOC_deviation: 7.7279 Fuel Consumption: 41.4376\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.408\n",
      "Episode: 198 Exploration P: 0.0219 Total reward: -75.49878796136112 SOC: 0.5925 Cumulative_SOC_deviation: 6.7846 Fuel Consumption: 7.6523\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.597\n",
      "Episode: 199 Exploration P: 0.0216 Total reward: -124.34678240941295 SOC: 0.6034 Cumulative_SOC_deviation: 8.3209 Fuel Consumption: 41.1381\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.368\n",
      "Episode: 200 Exploration P: 0.0214 Total reward: -120.0121516817151 SOC: 0.5989 Cumulative_SOC_deviation: 7.9432 Fuel Consumption: 40.5804\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -164.25603609690205 SOC: 0.5785 Cumulative_SOC_deviation: 15.2967 Fuel Consumption: 11.2886\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.168\n",
      "Episode: 201 Exploration P: 0.0211 Total reward: -99.80270768232907 SOC: 0.5929 Cumulative_SOC_deviation: 9.2231 Fuel Consumption: 7.5716\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.980\n",
      "Episode: 202 Exploration P: 0.0209 Total reward: -117.62949755107748 SOC: 0.6039 Cumulative_SOC_deviation: 7.6627 Fuel Consumption: 41.0021\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.743\n",
      "Episode: 203 Exploration P: 0.0207 Total reward: -115.9583863877447 SOC: 0.6144 Cumulative_SOC_deviation: 7.3877 Fuel Consumption: 42.0819\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.853\n",
      "Episode: 204 Exploration P: 0.0204 Total reward: -115.9601297259442 SOC: 0.5996 Cumulative_SOC_deviation: 7.5346 Fuel Consumption: 40.6137\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.929\n",
      "Episode: 205 Exploration P: 0.0201 Total reward: -152.61160100219595 SOC: 0.5866 Cumulative_SOC_deviation: 11.1311 Fuel Consumption: 41.3006\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.229\n",
      "Episode: 206 Exploration P: 0.0199 Total reward: -131.42160493111444 SOC: 0.5990 Cumulative_SOC_deviation: 9.0683 Fuel Consumption: 40.7389\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.717\n",
      "Episode: 207 Exploration P: 0.0197 Total reward: -232.98601770080464 SOC: 0.5931 Cumulative_SOC_deviation: 19.1286 Fuel Consumption: 41.7005\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.643\n",
      "Episode: 208 Exploration P: 0.0194 Total reward: -210.87180128034655 SOC: 0.5943 Cumulative_SOC_deviation: 16.8716 Fuel Consumption: 42.1562\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.678\n",
      "Episode: 209 Exploration P: 0.0192 Total reward: -120.55830260402362 SOC: 0.6064 Cumulative_SOC_deviation: 7.9285 Fuel Consumption: 41.2732\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.383\n",
      "Episode: 210 Exploration P: 0.0190 Total reward: -110.25701014350258 SOC: 0.5853 Cumulative_SOC_deviation: 10.3210 Fuel Consumption: 7.0473\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -121.40614581674353 SOC: 0.5854 Cumulative_SOC_deviation: 10.9789 Fuel Consumption: 11.6167\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.087\n",
      "Episode: 211 Exploration P: 0.0188 Total reward: -130.13887721622004 SOC: 0.6077 Cumulative_SOC_deviation: 8.8750 Fuel Consumption: 41.3890\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.987\n",
      "Episode: 212 Exploration P: 0.0186 Total reward: -92.4916270851882 SOC: 0.5894 Cumulative_SOC_deviation: 8.5031 Fuel Consumption: 7.4603\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.296\n",
      "Episode: 213 Exploration P: 0.0184 Total reward: -144.72176232254427 SOC: 0.6106 Cumulative_SOC_deviation: 10.3267 Fuel Consumption: 41.4547\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.431\n",
      "Episode: 214 Exploration P: 0.0182 Total reward: -187.92060530034442 SOC: 0.5897 Cumulative_SOC_deviation: 14.6542 Fuel Consumption: 41.3788\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.482\n",
      "Episode: 215 Exploration P: 0.0180 Total reward: -123.85034781300496 SOC: 0.6058 Cumulative_SOC_deviation: 8.2386 Fuel Consumption: 41.4641\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.924\n",
      "Episode: 216 Exploration P: 0.0179 Total reward: -91.48663478529053 SOC: 0.5939 Cumulative_SOC_deviation: 8.3768 Fuel Consumption: 7.7184\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.802\n",
      "Episode: 217 Exploration P: 0.0177 Total reward: -135.0670837179471 SOC: 0.6020 Cumulative_SOC_deviation: 9.3862 Fuel Consumption: 41.2048\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.923\n",
      "Episode: 218 Exploration P: 0.0175 Total reward: -129.49101736492958 SOC: 0.5876 Cumulative_SOC_deviation: 12.2306 Fuel Consumption: 7.1850\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.627\n",
      "Episode: 219 Exploration P: 0.0174 Total reward: -135.37954698336839 SOC: 0.5973 Cumulative_SOC_deviation: 9.4915 Fuel Consumption: 40.4641\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.494\n",
      "Episode: 220 Exploration P: 0.0172 Total reward: -106.37921398853962 SOC: 0.5896 Cumulative_SOC_deviation: 9.8997 Fuel Consumption: 7.3823\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -89.4957259194325 SOC: 0.5932 Cumulative_SOC_deviation: 7.7519 Fuel Consumption: 11.9768\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.482\n",
      "Episode: 221 Exploration P: 0.0171 Total reward: -125.96366065490247 SOC: 0.6018 Cumulative_SOC_deviation: 8.4982 Fuel Consumption: 40.9817\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.732\n",
      "Episode: 222 Exploration P: 0.0169 Total reward: -112.00114547947386 SOC: 0.6057 Cumulative_SOC_deviation: 7.0436 Fuel Consumption: 41.5655\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.168\n",
      "Episode: 223 Exploration P: 0.0168 Total reward: -125.84483851121779 SOC: 0.6090 Cumulative_SOC_deviation: 8.4020 Fuel Consumption: 41.8247\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.789\n",
      "Episode: 224 Exploration P: 0.0166 Total reward: -148.4902133552582 SOC: 0.5895 Cumulative_SOC_deviation: 10.7025 Fuel Consumption: 41.4650\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.913\n",
      "Episode: 225 Exploration P: 0.0165 Total reward: -142.33110537633218 SOC: 0.5971 Cumulative_SOC_deviation: 10.1944 Fuel Consumption: 40.3876\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.573\n",
      "Episode: 226 Exploration P: 0.0163 Total reward: -126.83754761227686 SOC: 0.6038 Cumulative_SOC_deviation: 8.5421 Fuel Consumption: 41.4166\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.369\n",
      "Episode: 227 Exploration P: 0.0162 Total reward: -145.25161499031142 SOC: 0.5969 Cumulative_SOC_deviation: 10.4497 Fuel Consumption: 40.7546\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.398\n",
      "Episode: 228 Exploration P: 0.0161 Total reward: -155.15376020347338 SOC: 0.5978 Cumulative_SOC_deviation: 11.4734 Fuel Consumption: 40.4196\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.394\n",
      "Episode: 229 Exploration P: 0.0159 Total reward: -138.47714901480796 SOC: 0.5987 Cumulative_SOC_deviation: 9.7742 Fuel Consumption: 40.7354\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.866\n",
      "Episode: 230 Exploration P: 0.0158 Total reward: -286.7063060055276 SOC: 0.5858 Cumulative_SOC_deviation: 24.5808 Fuel Consumption: 40.8980\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -164.39414099566235 SOC: 0.5827 Cumulative_SOC_deviation: 15.2993 Fuel Consumption: 11.4008\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.354\n",
      "Episode: 231 Exploration P: 0.0156 Total reward: -160.1614289160095 SOC: 0.5961 Cumulative_SOC_deviation: 11.9546 Fuel Consumption: 40.6157\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.218\n",
      "Episode: 232 Exploration P: 0.0155 Total reward: -143.98875864778458 SOC: 0.5832 Cumulative_SOC_deviation: 13.7028 Fuel Consumption: 6.9610\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.564\n",
      "Episode: 233 Exploration P: 0.0154 Total reward: -173.3934704011917 SOC: 0.5933 Cumulative_SOC_deviation: 13.2996 Fuel Consumption: 40.3972\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.137\n",
      "Episode: 234 Exploration P: 0.0153 Total reward: -164.37717228860473 SOC: 0.5817 Cumulative_SOC_deviation: 15.7664 Fuel Consumption: 6.7131\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.180\n",
      "Episode: 235 Exploration P: 0.0152 Total reward: -170.28793261920578 SOC: 0.5849 Cumulative_SOC_deviation: 16.3328 Fuel Consumption: 6.9603\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.467\n",
      "Episode: 236 Exploration P: 0.0150 Total reward: -179.3663994341326 SOC: 0.5855 Cumulative_SOC_deviation: 13.8050 Fuel Consumption: 41.3161\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.763\n",
      "Episode: 237 Exploration P: 0.0149 Total reward: -261.431059032401 SOC: 0.5881 Cumulative_SOC_deviation: 22.0598 Fuel Consumption: 40.8329\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.447\n",
      "Episode: 238 Exploration P: 0.0148 Total reward: -125.5186252382084 SOC: 0.5979 Cumulative_SOC_deviation: 8.4674 Fuel Consumption: 40.8443\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.699\n",
      "Episode: 239 Exploration P: 0.0147 Total reward: -128.48437728387395 SOC: 0.6083 Cumulative_SOC_deviation: 8.6850 Fuel Consumption: 41.6348\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.269\n",
      "Episode: 240 Exploration P: 0.0146 Total reward: -188.19397656312572 SOC: 0.5856 Cumulative_SOC_deviation: 14.7358 Fuel Consumption: 40.8355\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -151.9516894707559 SOC: 0.5856 Cumulative_SOC_deviation: 14.0476 Fuel Consumption: 11.4759\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.565\n",
      "Episode: 241 Exploration P: 0.0145 Total reward: -165.81965940576427 SOC: 0.5917 Cumulative_SOC_deviation: 12.5512 Fuel Consumption: 40.3080\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.339\n",
      "Episode: 242 Exploration P: 0.0144 Total reward: -144.75217387972316 SOC: 0.5849 Cumulative_SOC_deviation: 13.7697 Fuel Consumption: 7.0547\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.630\n",
      "Episode: 243 Exploration P: 0.0143 Total reward: -144.2984680491721 SOC: 0.5930 Cumulative_SOC_deviation: 10.3923 Fuel Consumption: 40.3751\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.313\n",
      "Episode: 244 Exploration P: 0.0142 Total reward: -178.21049236100768 SOC: 0.5785 Cumulative_SOC_deviation: 17.1720 Fuel Consumption: 6.4907\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.439\n",
      "Episode: 245 Exploration P: 0.0141 Total reward: -184.65749398436677 SOC: 0.5897 Cumulative_SOC_deviation: 14.4304 Fuel Consumption: 40.3533\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.228\n",
      "Episode: 246 Exploration P: 0.0140 Total reward: -282.8609624089265 SOC: 0.5850 Cumulative_SOC_deviation: 24.1781 Fuel Consumption: 41.0799\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.552\n",
      "Episode: 247 Exploration P: 0.0139 Total reward: -229.7445965452196 SOC: 0.5828 Cumulative_SOC_deviation: 18.8516 Fuel Consumption: 41.2286\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.474\n",
      "Episode: 248 Exploration P: 0.0138 Total reward: -320.865412496526 SOC: 0.5800 Cumulative_SOC_deviation: 28.0007 Fuel Consumption: 40.8587\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.072\n",
      "Episode: 249 Exploration P: 0.0137 Total reward: -308.0482212782724 SOC: 0.5834 Cumulative_SOC_deviation: 26.6830 Fuel Consumption: 41.2180\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.245\n",
      "Episode: 250 Exploration P: 0.0136 Total reward: -163.022912197081 SOC: 0.5802 Cumulative_SOC_deviation: 15.6192 Fuel Consumption: 6.8312\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -203.71785885832853 SOC: 0.5777 Cumulative_SOC_deviation: 19.2521 Fuel Consumption: 11.1972\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.558\n",
      "Episode: 251 Exploration P: 0.0135 Total reward: -160.68266070653658 SOC: 0.5986 Cumulative_SOC_deviation: 11.9565 Fuel Consumption: 41.1175\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.887\n",
      "Episode: 252 Exploration P: 0.0134 Total reward: -349.4418927407992 SOC: 0.5796 Cumulative_SOC_deviation: 30.8885 Fuel Consumption: 40.5567\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.345\n",
      "Episode: 253 Exploration P: 0.0134 Total reward: -189.3635121282369 SOC: 0.5781 Cumulative_SOC_deviation: 18.2798 Fuel Consumption: 6.5660\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.977\n",
      "Episode: 254 Exploration P: 0.0133 Total reward: -277.10977860360083 SOC: 0.5866 Cumulative_SOC_deviation: 23.5975 Fuel Consumption: 41.1343\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.298\n",
      "Episode: 255 Exploration P: 0.0132 Total reward: -64.28020458597227 SOC: 0.6032 Cumulative_SOC_deviation: 5.6204 Fuel Consumption: 8.0758\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.262\n",
      "Episode: 256 Exploration P: 0.0131 Total reward: -97.75574374648642 SOC: 0.6040 Cumulative_SOC_deviation: 5.4799 Fuel Consumption: 42.9572\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.492\n",
      "Episode: 257 Exploration P: 0.0130 Total reward: -48.0135145499888 SOC: 0.6045 Cumulative_SOC_deviation: 3.9614 Fuel Consumption: 8.3999\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.908\n",
      "Episode: 258 Exploration P: 0.0130 Total reward: -116.01047362341795 SOC: 0.6168 Cumulative_SOC_deviation: 7.2872 Fuel Consumption: 43.1385\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.268\n",
      "Episode: 259 Exploration P: 0.0129 Total reward: -119.30473365472021 SOC: 0.6099 Cumulative_SOC_deviation: 7.6970 Fuel Consumption: 42.3346\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.247\n",
      "Episode: 260 Exploration P: 0.0129 Total reward: -31.471191863765192 SOC: 0.5990 Cumulative_SOC_deviation: 2.3568 Fuel Consumption: 7.9031\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -65.66154485701959 SOC: 0.6027 Cumulative_SOC_deviation: 5.2720 Fuel Consumption: 12.9419\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.432\n",
      "Episode: 261 Exploration P: 0.0128 Total reward: -35.30271129662876 SOC: 0.6033 Cumulative_SOC_deviation: 2.7116 Fuel Consumption: 8.1863\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.044\n",
      "Episode: 262 Exploration P: 0.0127 Total reward: -95.0029924107743 SOC: 0.6013 Cumulative_SOC_deviation: 5.2203 Fuel Consumption: 42.7999\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.934\n",
      "Episode: 263 Exploration P: 0.0127 Total reward: -125.00074896212823 SOC: 0.6104 Cumulative_SOC_deviation: 8.1725 Fuel Consumption: 43.2759\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.898\n",
      "Episode: 264 Exploration P: 0.0126 Total reward: -129.23085966514452 SOC: 0.6129 Cumulative_SOC_deviation: 8.6064 Fuel Consumption: 43.1667\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.054\n",
      "Episode: 265 Exploration P: 0.0125 Total reward: -117.07402124340108 SOC: 0.5930 Cumulative_SOC_deviation: 7.5006 Fuel Consumption: 42.0677\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.059\n",
      "Episode: 266 Exploration P: 0.0125 Total reward: -146.31770466517875 SOC: 0.6030 Cumulative_SOC_deviation: 10.3320 Fuel Consumption: 42.9973\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.307\n",
      "Episode: 267 Exploration P: 0.0124 Total reward: -94.69419194750827 SOC: 0.6012 Cumulative_SOC_deviation: 5.2466 Fuel Consumption: 42.2279\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.797\n",
      "Episode: 268 Exploration P: 0.0123 Total reward: -101.36741486645577 SOC: 0.5978 Cumulative_SOC_deviation: 5.9084 Fuel Consumption: 42.2833\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.075\n",
      "Episode: 269 Exploration P: 0.0123 Total reward: -26.868322133088427 SOC: 0.5994 Cumulative_SOC_deviation: 1.9084 Fuel Consumption: 7.7842\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.121\n",
      "Episode: 270 Exploration P: 0.0122 Total reward: -31.158211924823892 SOC: 0.6028 Cumulative_SOC_deviation: 2.3054 Fuel Consumption: 8.1037\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -77.39490372190348 SOC: 0.6057 Cumulative_SOC_deviation: 6.4523 Fuel Consumption: 12.8715\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.177\n",
      "Episode: 271 Exploration P: 0.0122 Total reward: -114.97122723737562 SOC: 0.6115 Cumulative_SOC_deviation: 7.2535 Fuel Consumption: 42.4366\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.321\n",
      "Episode: 272 Exploration P: 0.0121 Total reward: -33.190422725485334 SOC: 0.6031 Cumulative_SOC_deviation: 2.4936 Fuel Consumption: 8.2544\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.217\n",
      "Episode: 273 Exploration P: 0.0121 Total reward: -96.8855410781926 SOC: 0.6023 Cumulative_SOC_deviation: 5.4503 Fuel Consumption: 42.3826\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.349\n",
      "Episode: 274 Exploration P: 0.0120 Total reward: -134.70906478364398 SOC: 0.6076 Cumulative_SOC_deviation: 9.1906 Fuel Consumption: 42.8029\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.210\n",
      "Episode: 275 Exploration P: 0.0120 Total reward: -132.31980330771893 SOC: 0.6100 Cumulative_SOC_deviation: 8.9413 Fuel Consumption: 42.9064\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.099\n",
      "Episode: 276 Exploration P: 0.0120 Total reward: -27.711256830195477 SOC: 0.6005 Cumulative_SOC_deviation: 1.9418 Fuel Consumption: 8.2930\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.297\n",
      "Episode: 277 Exploration P: 0.0119 Total reward: -26.382888256178745 SOC: 0.6016 Cumulative_SOC_deviation: 1.8285 Fuel Consumption: 8.0983\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.034\n",
      "Episode: 278 Exploration P: 0.0119 Total reward: -99.2155791134971 SOC: 0.6000 Cumulative_SOC_deviation: 5.6790 Fuel Consumption: 42.4255\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.810\n",
      "Episode: 279 Exploration P: 0.0118 Total reward: -110.87723872670153 SOC: 0.6038 Cumulative_SOC_deviation: 6.7567 Fuel Consumption: 43.3100\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.404\n",
      "Episode: 280 Exploration P: 0.0118 Total reward: -106.26239878782077 SOC: 0.6001 Cumulative_SOC_deviation: 6.4450 Fuel Consumption: 41.8119\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -70.58186875472117 SOC: 0.5985 Cumulative_SOC_deviation: 5.7609 Fuel Consumption: 12.9729\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.683\n",
      "Episode: 281 Exploration P: 0.0117 Total reward: -118.158547001245 SOC: 0.6052 Cumulative_SOC_deviation: 7.5812 Fuel Consumption: 42.3470\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.581\n",
      "Episode: 282 Exploration P: 0.0117 Total reward: -67.77694631426114 SOC: 0.5990 Cumulative_SOC_deviation: 5.9706 Fuel Consumption: 8.0711\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.960\n",
      "Episode: 283 Exploration P: 0.0117 Total reward: -114.81883655333364 SOC: 0.6082 Cumulative_SOC_deviation: 7.2568 Fuel Consumption: 42.2506\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.281\n",
      "Episode: 284 Exploration P: 0.0116 Total reward: -106.689918140761 SOC: 0.6007 Cumulative_SOC_deviation: 6.4248 Fuel Consumption: 42.4414\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.436\n",
      "Episode: 285 Exploration P: 0.0116 Total reward: -29.931608327625195 SOC: 0.6002 Cumulative_SOC_deviation: 2.1789 Fuel Consumption: 8.1424\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.077\n",
      "Episode: 286 Exploration P: 0.0115 Total reward: -103.88577551028357 SOC: 0.6023 Cumulative_SOC_deviation: 6.1424 Fuel Consumption: 42.4617\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.566\n",
      "Episode: 287 Exploration P: 0.0115 Total reward: -95.82164933551407 SOC: 0.6054 Cumulative_SOC_deviation: 5.3392 Fuel Consumption: 42.4300\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.305\n",
      "Episode: 288 Exploration P: 0.0115 Total reward: -99.7076030874192 SOC: 0.6046 Cumulative_SOC_deviation: 5.6820 Fuel Consumption: 42.8873\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.713\n",
      "Episode: 289 Exploration P: 0.0114 Total reward: -31.996744274485494 SOC: 0.6041 Cumulative_SOC_deviation: 2.3620 Fuel Consumption: 8.3768\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.125\n",
      "Episode: 290 Exploration P: 0.0114 Total reward: -120.96232280973847 SOC: 0.6115 Cumulative_SOC_deviation: 7.7931 Fuel Consumption: 43.0314\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -58.90908159655058 SOC: 0.6009 Cumulative_SOC_deviation: 4.5656 Fuel Consumption: 13.2526\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.958\n",
      "Episode: 291 Exploration P: 0.0114 Total reward: -114.95420171315776 SOC: 0.6132 Cumulative_SOC_deviation: 7.2137 Fuel Consumption: 42.8168\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.870\n",
      "Episode: 292 Exploration P: 0.0113 Total reward: -90.21027413685519 SOC: 0.6033 Cumulative_SOC_deviation: 4.7687 Fuel Consumption: 42.5233\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.708\n",
      "Episode: 293 Exploration P: 0.0113 Total reward: -104.77841375809335 SOC: 0.6009 Cumulative_SOC_deviation: 6.2095 Fuel Consumption: 42.6838\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.758\n",
      "Episode: 294 Exploration P: 0.0113 Total reward: -128.63265928213596 SOC: 0.6139 Cumulative_SOC_deviation: 8.5752 Fuel Consumption: 42.8802\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.017\n",
      "Episode: 295 Exploration P: 0.0112 Total reward: -121.86375995460817 SOC: 0.6122 Cumulative_SOC_deviation: 7.9186 Fuel Consumption: 42.6781\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.772\n",
      "Episode: 296 Exploration P: 0.0112 Total reward: -95.27760690714061 SOC: 0.5984 Cumulative_SOC_deviation: 5.3112 Fuel Consumption: 42.1651\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.806\n",
      "Episode: 297 Exploration P: 0.0112 Total reward: -53.20990358052952 SOC: 0.5969 Cumulative_SOC_deviation: 4.5269 Fuel Consumption: 7.9407\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.912\n",
      "Episode: 298 Exploration P: 0.0111 Total reward: -97.6543088086205 SOC: 0.6004 Cumulative_SOC_deviation: 5.5308 Fuel Consumption: 42.3460\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.998\n",
      "Episode: 299 Exploration P: 0.0111 Total reward: -30.2668047992798 SOC: 0.6014 Cumulative_SOC_deviation: 2.2026 Fuel Consumption: 8.2407\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.764\n",
      "Episode: 300 Exploration P: 0.0111 Total reward: -127.43781997570524 SOC: 0.6149 Cumulative_SOC_deviation: 8.4822 Fuel Consumption: 42.6154\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -69.74081195168377 SOC: 0.6037 Cumulative_SOC_deviation: 5.6991 Fuel Consumption: 12.7502\n",
      "******************* Test is done *****************\n",
      "\n",
      "model is saved..\n"
     ]
    }
   ],
   "source": [
    "print(env.version)\n",
    "\n",
    "num_trials = 1\n",
    "results_dict = {} \n",
    "driving_cycle_paths = glob.glob(\"../data/driving_cycles/city/*.mat\")[:3]\n",
    "\n",
    "for trial in range(num_trials): \n",
    "    print(\"\")\n",
    "    print(\"Trial {}\".format(trial))\n",
    "    print(\"\")\n",
    "    \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer = initialization()\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    episode_test_history = [] \n",
    "    episode_num_test = [] \n",
    "    for ep in range(total_episodes): \n",
    "        driving_cycle_path = np.random.choice(driving_cycle_paths)\n",
    "        print(driving_cycle_path)\n",
    "        env = initialization_env(driving_cycle_path, 10)\n",
    "        \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
    "                                                                        -DELAY_TRAINING))\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_SOCs.append(env.SOC)\n",
    "        episode_FCs.append(env.fuel_consumption) \n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        print(\n",
    "              'Episode: {}'.format(ep + 1),\n",
    "              \"Exploration P: {:.4f}\".format(eps),\n",
    "              'Total reward: {}'.format(episodic_reward), \n",
    "              \"SOC: {:.4f}\".format(env.SOC), \n",
    "              \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "              \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "        )\n",
    "        print(\"\")\n",
    "        \n",
    "        if (ep + 1) % 10 == 0: \n",
    "            history = test_agent(actor_model, 10, -1)\n",
    "            episode_test_history.append(history) \n",
    "            episode_num_test.append(ep + 1)\n",
    "    \n",
    "    root = \"DDPG2_trial{}\".format(trial+1)\n",
    "    save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "    \n",
    "    results_dict[trial + 1] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs, \n",
    "        \"test_history\": episode_test_history, \n",
    "        \"test_episode_num\": episode_num_test, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDPG2.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
