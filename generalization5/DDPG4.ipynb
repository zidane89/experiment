{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "\n",
    "from vehicle_model_DDPG1 import Environment \n",
    "from cell_model import CellModel \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_nimh_6_240_panasonic_MY01_Prius.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_pm_95_145_X2.mat\"\n",
    "cell_model = CellModel()\n",
    "env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):      \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    inputs_batchnorm = layers.BatchNormalization()(inputs)\n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs_batchnorm)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_input_batchnorm = layers.BatchNormalization()(state_input)\n",
    "    \n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input_batchnorm)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 300\n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 10000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "\n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_model, critic_model, target_actor, target_critic, root): \n",
    "    actor_model.save_weights(\"./{}/actor_model_checkpoint\".format(root))\n",
    "    critic_model.save_weights(\"./{}/critic_model_checkpoint\".format(root))\n",
    "    target_actor.save_weights(\"./{}/target_actor_checkpoint\".format(root))\n",
    "    target_critic.save_weights(\"./{}/target_critic_checkpoint\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_env(driving_path, reward_factor):\n",
    "    env = Environment(cell_model, driving_path, battery_path, motor_path, reward_factor)\n",
    "    return env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(actor_model, reward_factor, test_path_start):\n",
    "    test_cycles = glob.glob(\"../data/driving_cycles/city/*.mat\")[test_path_start:]\n",
    "    test_cycle = np.random.choice(test_cycles)\n",
    "    env = initialization_env(test_cycle, reward_factor)\n",
    "    \n",
    "    total_reward = 0\n",
    "    state = env.reset() \n",
    "    while True: \n",
    "        tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "        action = policy_epsilon_greedy(tf_state, -1)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        \n",
    "        state = next_state \n",
    "        total_reward += reward \n",
    "        \n",
    "        if done: \n",
    "            break \n",
    "        \n",
    "    SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "    \n",
    "    print(\"******************* Test is start *****************\")\n",
    "    print(test_cycle)\n",
    "    print('Total reward: {}'.format(total_reward), \n",
    "          \"SOC: {:.4f}\".format(env.SOC), \n",
    "          \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "          \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption))\n",
    "    print(\"******************* Test is done *****************\")\n",
    "    print(\"\")\n",
    "    return env.history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "Trial 0\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 13.655\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -3917.75503969744 SOC: 1.0000 Cumulative_SOC_deviation: 379.5797 Fuel Consumption: 121.9577\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.586\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -3660.053389566367 SOC: 1.0000 Cumulative_SOC_deviation: 354.0485 Fuel Consumption: 119.5682\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 38.075\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -11513.9936530536 SOC: 1.0000 Cumulative_SOC_deviation: 1119.1317 Fuel Consumption: 322.6767\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 29.304\n",
      "Episode: 4 Exploration P: 1.0000 Total reward: -7591.485666309332 SOC: 1.0000 Cumulative_SOC_deviation: 737.1545 Fuel Consumption: 219.9409\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 38.385\n",
      "Episode: 5 Exploration P: 1.0000 Total reward: -10075.879291277253 SOC: 1.0000 Cumulative_SOC_deviation: 979.0242 Fuel Consumption: 285.6374\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "WARNING:tensorflow:Layer batch_normalization_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 140.166\n",
      "Episode: 6 Exploration P: 0.9549 Total reward: -10096.080025756675 SOC: 1.0000 Cumulative_SOC_deviation: 981.2307 Fuel Consumption: 283.7729\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.056\n",
      "Episode: 7 Exploration P: 0.9350 Total reward: -3577.892255516521 SOC: 1.0000 Cumulative_SOC_deviation: 346.5719 Fuel Consumption: 112.1731\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 135.394\n",
      "Episode: 8 Exploration P: 0.8940 Total reward: -8545.52772433325 SOC: 1.0000 Cumulative_SOC_deviation: 831.7176 Fuel Consumption: 228.3514\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 119.313\n",
      "Episode: 9 Exploration P: 0.8593 Total reward: -7399.192074972161 SOC: 1.0000 Cumulative_SOC_deviation: 721.1509 Fuel Consumption: 187.6830\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 53.402\n",
      "Episode: 10 Exploration P: 0.8442 Total reward: -2746.9667629227833 SOC: 1.0000 Cumulative_SOC_deviation: 266.2510 Fuel Consumption: 84.4569\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.840\n",
      "Episode: 11 Exploration P: 0.8216 Total reward: -4260.422101715698 SOC: 1.0000 Cumulative_SOC_deviation: 413.1864 Fuel Consumption: 128.5585\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.747\n",
      "Episode: 12 Exploration P: 0.7917 Total reward: -5893.281389699043 SOC: 1.0000 Cumulative_SOC_deviation: 572.6177 Fuel Consumption: 167.1046\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.292\n",
      "Episode: 13 Exploration P: 0.7646 Total reward: -6434.340936269505 SOC: 1.0000 Cumulative_SOC_deviation: 628.3443 Fuel Consumption: 150.8981\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.212\n",
      "Episode: 14 Exploration P: 0.7484 Total reward: -3644.202607166466 SOC: 1.0000 Cumulative_SOC_deviation: 355.3714 Fuel Consumption: 90.4883\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "Available condition is not avail... SOC: 0.9956086948786288\n",
      "elapsed_time: 54.625\n",
      "Episode: 15 Exploration P: 0.7350 Total reward: -2828.400883454856 SOC: 0.9956 Cumulative_SOC_deviation: 275.3634 Fuel Consumption: 74.7668\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 134.865\n",
      "Episode: 16 Exploration P: 0.7028 Total reward: -8190.686891558127 SOC: 1.0000 Cumulative_SOC_deviation: 800.8659 Fuel Consumption: 182.0274\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 157.376\n",
      "Episode: 17 Exploration P: 0.6675 Total reward: -9587.15044997666 SOC: 1.0000 Cumulative_SOC_deviation: 938.2827 Fuel Consumption: 204.3233\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 112.421\n",
      "Episode: 18 Exploration P: 0.6433 Total reward: -5415.860232896654 SOC: 1.0000 Cumulative_SOC_deviation: 526.9002 Fuel Consumption: 146.8587\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 120.303\n",
      "Episode: 19 Exploration P: 0.6184 Total reward: -7051.6900071812015 SOC: 1.0000 Cumulative_SOC_deviation: 691.0719 Fuel Consumption: 140.9711\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 117.947\n",
      "Episode: 20 Exploration P: 0.5945 Total reward: -7026.249627901492 SOC: 1.0000 Cumulative_SOC_deviation: 689.2653 Fuel Consumption: 133.5962\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.236\n",
      "Episode: 21 Exploration P: 0.5742 Total reward: -6082.06664065406 SOC: 1.0000 Cumulative_SOC_deviation: 596.2725 Fuel Consumption: 119.3412\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.235\n",
      "Episode: 22 Exploration P: 0.5547 Total reward: -5778.441950781466 SOC: 1.0000 Cumulative_SOC_deviation: 567.6813 Fuel Consumption: 101.6292\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.506\n",
      "Episode: 23 Exploration P: 0.5388 Total reward: -4718.568118927071 SOC: 1.0000 Cumulative_SOC_deviation: 463.1066 Fuel Consumption: 87.5020\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.923\n",
      "Episode: 24 Exploration P: 0.5274 Total reward: -3310.231581816326 SOC: 1.0000 Cumulative_SOC_deviation: 324.1476 Fuel Consumption: 68.7558\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.374\n",
      "Episode: 25 Exploration P: 0.5110 Total reward: -5163.235865612405 SOC: 1.0000 Cumulative_SOC_deviation: 506.6886 Fuel Consumption: 96.3495\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.504\n",
      "Episode: 26 Exploration P: 0.5002 Total reward: -3171.5319368863447 SOC: 1.0000 Cumulative_SOC_deviation: 310.4514 Fuel Consumption: 67.0176\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.722\n",
      "Episode: 27 Exploration P: 0.4896 Total reward: -3185.0074604571455 SOC: 1.0000 Cumulative_SOC_deviation: 312.1406 Fuel Consumption: 63.6016\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.588\n",
      "Episode: 28 Exploration P: 0.4799 Total reward: -2747.764043412718 SOC: 1.0000 Cumulative_SOC_deviation: 269.0426 Fuel Consumption: 57.3380\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.411\n",
      "Episode: 29 Exploration P: 0.4700 Total reward: -1741.151633117906 SOC: 0.8107 Cumulative_SOC_deviation: 167.8112 Fuel Consumption: 63.0393\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 136.757\n",
      "Episode: 30 Exploration P: 0.4496 Total reward: -7353.265234038738 SOC: 1.0000 Cumulative_SOC_deviation: 723.2809 Fuel Consumption: 120.4564\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 137.348\n",
      "Episode: 31 Exploration P: 0.4301 Total reward: -7281.911064666935 SOC: 1.0000 Cumulative_SOC_deviation: 716.5192 Fuel Consumption: 116.7187\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 119.696\n",
      "Episode: 32 Exploration P: 0.4136 Total reward: -6357.543281528198 SOC: 1.0000 Cumulative_SOC_deviation: 626.0632 Fuel Consumption: 96.9110\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.812\n",
      "Episode: 33 Exploration P: 0.3996 Total reward: -5494.123150234906 SOC: 1.0000 Cumulative_SOC_deviation: 541.3691 Fuel Consumption: 80.4324\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.422\n",
      "Episode: 34 Exploration P: 0.3914 Total reward: -1082.4271117322721 SOC: 0.6590 Cumulative_SOC_deviation: 103.1630 Fuel Consumption: 50.7975\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.483\n",
      "Episode: 35 Exploration P: 0.3803 Total reward: -3780.534379360662 SOC: 1.0000 Cumulative_SOC_deviation: 371.7999 Fuel Consumption: 62.5358\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.877\n",
      "Episode: 36 Exploration P: 0.3723 Total reward: -2845.0482386506715 SOC: 1.0000 Cumulative_SOC_deviation: 279.4002 Fuel Consumption: 51.0467\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.657\n",
      "Episode: 37 Exploration P: 0.3608 Total reward: -4623.819563497522 SOC: 1.0000 Cumulative_SOC_deviation: 455.5125 Fuel Consumption: 68.6941\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.023\n",
      "Episode: 38 Exploration P: 0.3533 Total reward: -2610.1005323774866 SOC: 1.0000 Cumulative_SOC_deviation: 256.5627 Fuel Consumption: 44.4733\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 137.621\n",
      "Episode: 39 Exploration P: 0.3380 Total reward: -6833.242664213547 SOC: 1.0000 Cumulative_SOC_deviation: 674.2884 Fuel Consumption: 90.3590\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.510\n",
      "Episode: 40 Exploration P: 0.3283 Total reward: -2747.1768554042055 SOC: 0.9420 Cumulative_SOC_deviation: 268.5411 Fuel Consumption: 61.7658\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.591\n",
      "Episode: 41 Exploration P: 0.3191 Total reward: -3095.4857971099327 SOC: 1.0000 Cumulative_SOC_deviation: 303.4364 Fuel Consumption: 61.1222\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.526\n",
      "Episode: 42 Exploration P: 0.3124 Total reward: -2261.93216107677 SOC: 1.0000 Cumulative_SOC_deviation: 221.9970 Fuel Consumption: 41.9623\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.438\n",
      "Episode: 43 Exploration P: 0.3061 Total reward: -1284.6768820132863 SOC: 0.4664 Cumulative_SOC_deviation: 124.7742 Fuel Consumption: 36.9354\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.422\n",
      "Episode: 44 Exploration P: 0.3000 Total reward: -2020.9788763361366 SOC: 0.9506 Cumulative_SOC_deviation: 198.2306 Fuel Consumption: 38.6725\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 177.427\n",
      "Episode: 45 Exploration P: 0.2835 Total reward: -9886.591120675143 SOC: 1.0000 Cumulative_SOC_deviation: 978.5511 Fuel Consumption: 101.0805\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.846\n",
      "Episode: 46 Exploration P: 0.2776 Total reward: -2197.7702726548605 SOC: 0.9597 Cumulative_SOC_deviation: 215.6562 Fuel Consumption: 41.2080\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.988\n",
      "Episode: 47 Exploration P: 0.2698 Total reward: -2428.4887818064867 SOC: 0.9342 Cumulative_SOC_deviation: 237.6799 Fuel Consumption: 51.6902\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 36.278\n",
      "Episode: 48 Exploration P: 0.2667 Total reward: -680.3504732559237 SOC: 0.8031 Cumulative_SOC_deviation: 65.8438 Fuel Consumption: 21.9125\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Empty_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 129.299\n",
      "Episode: 49 Exploration P: 0.2560 Total reward: -3977.772206302353 SOC: 1.0000 Cumulative_SOC_deviation: 390.8007 Fuel Consumption: 69.7655\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 175.676\n",
      "Episode: 50 Exploration P: 0.2420 Total reward: -9339.916135180709 SOC: 1.0000 Cumulative_SOC_deviation: 925.6220 Fuel Consumption: 83.6961\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 54.159\n",
      "Episode: 51 Exploration P: 0.2379 Total reward: -335.59819202725777 SOC: 0.6845 Cumulative_SOC_deviation: 31.1236 Fuel Consumption: 24.3627\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.607\n",
      "Episode: 52 Exploration P: 0.2312 Total reward: -1580.0523723131244 SOC: 0.8229 Cumulative_SOC_deviation: 153.7334 Fuel Consumption: 42.7179\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 120.128\n",
      "Episode: 53 Exploration P: 0.2225 Total reward: -3744.0037673909974 SOC: 0.9753 Cumulative_SOC_deviation: 368.6065 Fuel Consumption: 57.9390\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.266\n",
      "Episode: 54 Exploration P: 0.2182 Total reward: -1630.9659437894288 SOC: 0.8685 Cumulative_SOC_deviation: 159.8654 Fuel Consumption: 32.3117\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 36.280\n",
      "Episode: 55 Exploration P: 0.2157 Total reward: -530.0063550941377 SOC: 0.7724 Cumulative_SOC_deviation: 51.0550 Fuel Consumption: 19.4561\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 121.423\n",
      "Episode: 56 Exploration P: 0.2077 Total reward: -3149.249264971247 SOC: 0.9123 Cumulative_SOC_deviation: 309.6849 Fuel Consumption: 52.3999\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.211\n",
      "Episode: 57 Exploration P: 0.2023 Total reward: -2464.0144881330043 SOC: 0.4193 Cumulative_SOC_deviation: 242.9104 Fuel Consumption: 34.9107\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 175.327\n",
      "Episode: 58 Exploration P: 0.1913 Total reward: -8282.044330659402 SOC: 1.0000 Cumulative_SOC_deviation: 821.1081 Fuel Consumption: 70.9630\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.724\n",
      "Episode: 59 Exploration P: 0.1850 Total reward: -2301.615845196253 SOC: 0.8963 Cumulative_SOC_deviation: 225.8437 Fuel Consumption: 43.1784\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.976\n",
      "Episode: 60 Exploration P: 0.1799 Total reward: -659.8552612042761 SOC: 0.7086 Cumulative_SOC_deviation: 62.6184 Fuel Consumption: 33.6709\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.529\n",
      "Episode: 61 Exploration P: 0.1745 Total reward: -1692.0277870704833 SOC: 0.8221 Cumulative_SOC_deviation: 165.5626 Fuel Consumption: 36.4018\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.455\n",
      "Episode: 62 Exploration P: 0.1712 Total reward: -816.1878807613836 SOC: 0.7249 Cumulative_SOC_deviation: 79.5693 Fuel Consumption: 20.4951\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.262\n",
      "Episode: 63 Exploration P: 0.1661 Total reward: -1438.8363610445613 SOC: 0.8027 Cumulative_SOC_deviation: 140.3673 Fuel Consumption: 35.1635\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.541\n",
      "Episode: 64 Exploration P: 0.1615 Total reward: -404.1297537628281 SOC: 0.6812 Cumulative_SOC_deviation: 37.2858 Fuel Consumption: 31.2719\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.842\n",
      "Episode: 65 Exploration P: 0.1583 Total reward: -1064.9321029605626 SOC: 0.7899 Cumulative_SOC_deviation: 104.0857 Fuel Consumption: 24.0751\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.234\n",
      "Episode: 66 Exploration P: 0.1551 Total reward: -1128.9685366619085 SOC: 0.8002 Cumulative_SOC_deviation: 110.4118 Fuel Consumption: 24.8508\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.326\n",
      "Episode: 67 Exploration P: 0.1497 Total reward: -4778.941218140353 SOC: 0.0761 Cumulative_SOC_deviation: 473.9210 Fuel Consumption: 39.7308\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 176.278\n",
      "Episode: 68 Exploration P: 0.1417 Total reward: -7389.8282815442835 SOC: 1.0000 Cumulative_SOC_deviation: 733.4219 Fuel Consumption: 55.6098\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.094\n",
      "Episode: 69 Exploration P: 0.1378 Total reward: -753.6070603602393 SOC: 0.5127 Cumulative_SOC_deviation: 72.6015 Fuel Consumption: 27.5916\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.681\n",
      "Episode: 70 Exploration P: 0.1338 Total reward: -915.5841066619031 SOC: 0.7501 Cumulative_SOC_deviation: 88.4561 Fuel Consumption: 31.0235\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 176.923\n",
      "Episode: 71 Exploration P: 0.1267 Total reward: -6796.768404822846 SOC: 1.0000 Cumulative_SOC_deviation: 674.4075 Fuel Consumption: 52.6937\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.304\n",
      "Episode: 72 Exploration P: 0.1230 Total reward: -686.706031812012 SOC: 0.7007 Cumulative_SOC_deviation: 65.9871 Fuel Consumption: 26.8347\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.002\n",
      "Episode: 73 Exploration P: 0.1199 Total reward: -3948.3524653419836 SOC: 0.2085 Cumulative_SOC_deviation: 392.9525 Fuel Consumption: 18.8277\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.254\n",
      "Episode: 74 Exploration P: 0.1177 Total reward: -539.4255163911648 SOC: 0.6974 Cumulative_SOC_deviation: 52.1037 Fuel Consumption: 18.3889\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 53.545\n",
      "Episode: 75 Exploration P: 0.1158 Total reward: -279.1257058900711 SOC: 0.5673 Cumulative_SOC_deviation: 26.3687 Fuel Consumption: 15.4392\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.370\n",
      "Episode: 76 Exploration P: 0.1129 Total reward: -3622.43341391787 SOC: 0.2494 Cumulative_SOC_deviation: 360.0563 Fuel Consumption: 21.8702\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.626\n",
      "Episode: 77 Exploration P: 0.1094 Total reward: -486.42708374328254 SOC: 0.6736 Cumulative_SOC_deviation: 46.1101 Fuel Consumption: 25.3256\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RECL\\Desktop\\Song\\graduate_paper\\program\\experiment\\generalization5\\vehicle_model_DDPG1.py:251: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n",
      "C:\\Users\\RECL\\Desktop\\Song\\graduate_paper\\program\\experiment\\generalization5\\vehicle_model_DDPG1.py:277: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOC is nan...\n",
      "elapsed_time: 96.733\n",
      "Episode: 78 Exploration P: 0.1062 Total reward: -14784.98165206004 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 23.7337\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.564\n",
      "Episode: 79 Exploration P: 0.1034 Total reward: -579.8153493826854 SOC: 0.4833 Cumulative_SOC_deviation: 55.9127 Fuel Consumption: 20.6884\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 95.690\n",
      "Episode: 80 Exploration P: 0.1005 Total reward: -14455.100057075151 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 23.1333\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.057\n",
      "Episode: 81 Exploration P: 0.0985 Total reward: -438.0669742099939 SOC: 0.6945 Cumulative_SOC_deviation: 42.1568 Fuel Consumption: 16.4990\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 178.197\n",
      "Episode: 82 Exploration P: 0.0935 Total reward: -4110.882657457106 SOC: 0.8288 Cumulative_SOC_deviation: 407.3327 Fuel Consumption: 37.5559\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.949\n",
      "Episode: 83 Exploration P: 0.0912 Total reward: -3689.414004322294 SOC: 0.2239 Cumulative_SOC_deviation: 366.9897 Fuel Consumption: 19.5172\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.433\n",
      "Episode: 84 Exploration P: 0.0888 Total reward: -679.7003731648673 SOC: 0.4574 Cumulative_SOC_deviation: 66.1552 Fuel Consumption: 18.1486\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.807\n",
      "Episode: 85 Exploration P: 0.0865 Total reward: -1220.3671658692538 SOC: 0.4329 Cumulative_SOC_deviation: 119.8852 Fuel Consumption: 21.5153\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.072\n",
      "Episode: 86 Exploration P: 0.0849 Total reward: -256.60794132334985 SOC: 0.6518 Cumulative_SOC_deviation: 24.3651 Fuel Consumption: 12.9566\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 36.359\n",
      "Episode: 87 Exploration P: 0.0840 Total reward: -50.240635165050534 SOC: 0.6257 Cumulative_SOC_deviation: 4.2756 Fuel Consumption: 7.4844\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 53.341\n",
      "Episode: 88 Exploration P: 0.0827 Total reward: -423.2433515699869 SOC: 0.5195 Cumulative_SOC_deviation: 41.1749 Fuel Consumption: 11.4946\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.645\n",
      "Episode: 89 Exploration P: 0.0805 Total reward: -1618.8089824502958 SOC: 0.3604 Cumulative_SOC_deviation: 160.3054 Fuel Consumption: 15.7549\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.600\n",
      "Episode: 90 Exploration P: 0.0791 Total reward: -278.7271275739443 SOC: 0.6139 Cumulative_SOC_deviation: 26.7075 Fuel Consumption: 11.6520\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 36.423\n",
      "Episode: 91 Exploration P: 0.0783 Total reward: -66.08659804046026 SOC: 0.6218 Cumulative_SOC_deviation: 5.8938 Fuel Consumption: 7.1482\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 54.515\n",
      "Episode: 92 Exploration P: 0.0770 Total reward: -151.52490787604867 SOC: 0.5921 Cumulative_SOC_deviation: 13.5173 Fuel Consumption: 16.3523\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 54.359\n",
      "Episode: 93 Exploration P: 0.0759 Total reward: -95.60763909318936 SOC: 0.5951 Cumulative_SOC_deviation: 7.9184 Fuel Consumption: 16.4240\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.366\n",
      "Episode: 94 Exploration P: 0.0739 Total reward: -253.86462624857737 SOC: 0.5977 Cumulative_SOC_deviation: 22.2029 Fuel Consumption: 31.8351\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 54.275\n",
      "Episode: 95 Exploration P: 0.0728 Total reward: -113.18061517270405 SOC: 0.5858 Cumulative_SOC_deviation: 9.7056 Fuel Consumption: 16.1248\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Empty_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 128.017\n",
      "Episode: 96 Exploration P: 0.0702 Total reward: -659.0726674071534 SOC: 0.6673 Cumulative_SOC_deviation: 62.0290 Fuel Consumption: 38.7824\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.889\n",
      "Episode: 97 Exploration P: 0.0689 Total reward: -186.39715491582234 SOC: 0.6287 Cumulative_SOC_deviation: 17.5302 Fuel Consumption: 11.0949\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.428\n",
      "Episode: 98 Exploration P: 0.0676 Total reward: -242.02349303858568 SOC: 0.6613 Cumulative_SOC_deviation: 22.8310 Fuel Consumption: 13.7136\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 158.754\n",
      "Episode: 99 Exploration P: 0.0647 Total reward: -443.117086079949 SOC: 0.6342 Cumulative_SOC_deviation: 40.8569 Fuel Consumption: 34.5477\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Empty_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 129.322\n",
      "Episode: 100 Exploration P: 0.0624 Total reward: -541.8034579419151 SOC: 0.6289 Cumulative_SOC_deviation: 50.4242 Fuel Consumption: 37.5618\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -241.21694402171718 SOC: 0.6171 Cumulative_SOC_deviation: 22.6597 Fuel Consumption: 14.6202\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.758\n",
      "Episode: 101 Exploration P: 0.0607 Total reward: -339.2559368937738 SOC: 0.6340 Cumulative_SOC_deviation: 31.8218 Fuel Consumption: 21.0377\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.693\n",
      "Episode: 102 Exploration P: 0.0591 Total reward: -497.1802216552748 SOC: 0.6306 Cumulative_SOC_deviation: 47.5820 Fuel Consumption: 21.3604\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.411\n",
      "Episode: 103 Exploration P: 0.0580 Total reward: -432.31156363850624 SOC: 0.6386 Cumulative_SOC_deviation: 42.0323 Fuel Consumption: 11.9888\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.730\n",
      "Episode: 104 Exploration P: 0.0566 Total reward: -419.1029024215204 SOC: 0.6298 Cumulative_SOC_deviation: 38.9086 Fuel Consumption: 30.0167\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.154\n",
      "Episode: 105 Exploration P: 0.0552 Total reward: -345.17668460565676 SOC: 0.6229 Cumulative_SOC_deviation: 32.5128 Fuel Consumption: 20.0486\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.475\n",
      "Episode: 106 Exploration P: 0.0539 Total reward: -180.26425720442768 SOC: 0.6130 Cumulative_SOC_deviation: 13.3925 Fuel Consumption: 46.3396\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.276\n",
      "Episode: 107 Exploration P: 0.0530 Total reward: -263.80583699078545 SOC: 0.6498 Cumulative_SOC_deviation: 21.6508 Fuel Consumption: 47.2982\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.112\n",
      "Episode: 108 Exploration P: 0.0521 Total reward: -236.62201254177657 SOC: 0.6195 Cumulative_SOC_deviation: 22.4621 Fuel Consumption: 12.0011\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.864\n",
      "Episode: 109 Exploration P: 0.0512 Total reward: -272.9630273131337 SOC: 0.6287 Cumulative_SOC_deviation: 26.1906 Fuel Consumption: 11.0566\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.057\n",
      "Episode: 110 Exploration P: 0.0504 Total reward: -213.926427425375 SOC: 0.6109 Cumulative_SOC_deviation: 20.2723 Fuel Consumption: 11.2030\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -91.79022954486854 SOC: 0.6058 Cumulative_SOC_deviation: 7.7952 Fuel Consumption: 13.8381\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 111.998\n",
      "Episode: 111 Exploration P: 0.0489 Total reward: -208.61426405407016 SOC: 0.6103 Cumulative_SOC_deviation: 13.4421 Fuel Consumption: 74.1931\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.212\n",
      "Episode: 112 Exploration P: 0.0481 Total reward: -158.40880522125747 SOC: 0.6219 Cumulative_SOC_deviation: 14.6357 Fuel Consumption: 12.0521\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 121.852\n",
      "Episode: 113 Exploration P: 0.0466 Total reward: -163.91636378440109 SOC: 0.6115 Cumulative_SOC_deviation: 13.5757 Fuel Consumption: 28.1590\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.907\n",
      "Episode: 114 Exploration P: 0.0453 Total reward: -251.7594274288019 SOC: 0.6469 Cumulative_SOC_deviation: 22.9246 Fuel Consumption: 22.5129\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.698\n",
      "Episode: 115 Exploration P: 0.0440 Total reward: -202.69154372456202 SOC: 0.6132 Cumulative_SOC_deviation: 13.0094 Fuel Consumption: 72.5980\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 158.966\n",
      "Episode: 116 Exploration P: 0.0423 Total reward: -419.4398536262629 SOC: 0.6479 Cumulative_SOC_deviation: 38.5566 Fuel Consumption: 33.8742\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.375\n",
      "Episode: 117 Exploration P: 0.0413 Total reward: -141.36782021172868 SOC: 0.6052 Cumulative_SOC_deviation: 12.2890 Fuel Consumption: 18.4780\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.477\n",
      "Episode: 118 Exploration P: 0.0406 Total reward: -83.16741082857372 SOC: 0.6266 Cumulative_SOC_deviation: 6.9848 Fuel Consumption: 13.3196\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 54.310\n",
      "Episode: 119 Exploration P: 0.0401 Total reward: -192.86763439857452 SOC: 0.5892 Cumulative_SOC_deviation: 17.6666 Fuel Consumption: 16.2012\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.555\n",
      "Episode: 120 Exploration P: 0.0394 Total reward: -102.64041626877443 SOC: 0.6180 Cumulative_SOC_deviation: 9.2791 Fuel Consumption: 9.8491\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -151.2069588507214 SOC: 0.6082 Cumulative_SOC_deviation: 13.7628 Fuel Consumption: 13.5792\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.934\n",
      "Episode: 121 Exploration P: 0.0386 Total reward: -203.02414028365632 SOC: 0.5969 Cumulative_SOC_deviation: 18.0624 Fuel Consumption: 22.4005\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.401\n",
      "Episode: 122 Exploration P: 0.0377 Total reward: -99.34362951035764 SOC: 0.6029 Cumulative_SOC_deviation: 8.1168 Fuel Consumption: 18.1756\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 177.474\n",
      "Episode: 123 Exploration P: 0.0361 Total reward: -689.4716580625733 SOC: 0.6157 Cumulative_SOC_deviation: 66.9198 Fuel Consumption: 20.2740\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 36.711\n",
      "Episode: 124 Exploration P: 0.0358 Total reward: -55.9571745689565 SOC: 0.5894 Cumulative_SOC_deviation: 5.1622 Fuel Consumption: 4.3348\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Empty_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 129.886\n",
      "Episode: 125 Exploration P: 0.0347 Total reward: -182.4611612415834 SOC: 0.5926 Cumulative_SOC_deviation: 14.8450 Fuel Consumption: 34.0115\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.620\n",
      "Episode: 126 Exploration P: 0.0338 Total reward: -111.29142091238617 SOC: 0.5975 Cumulative_SOC_deviation: 9.2165 Fuel Consumption: 19.1264\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.360\n",
      "Episode: 127 Exploration P: 0.0333 Total reward: -128.53423608421463 SOC: 0.6162 Cumulative_SOC_deviation: 8.4212 Fuel Consumption: 44.3221\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.868\n",
      "Episode: 128 Exploration P: 0.0328 Total reward: -69.90050549250817 SOC: 0.5955 Cumulative_SOC_deviation: 6.1658 Fuel Consumption: 8.2427\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 54.454\n",
      "Episode: 129 Exploration P: 0.0324 Total reward: -128.76509781731667 SOC: 0.6054 Cumulative_SOC_deviation: 11.1379 Fuel Consumption: 17.3862\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.531\n",
      "Episode: 130 Exploration P: 0.0320 Total reward: -129.64701197263864 SOC: 0.6120 Cumulative_SOC_deviation: 8.5665 Fuel Consumption: 43.9822\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -255.9069457742958 SOC: 0.5659 Cumulative_SOC_deviation: 24.4910 Fuel Consumption: 10.9970\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.868\n",
      "Episode: 131 Exploration P: 0.0311 Total reward: -798.9134960187646 SOC: 0.5779 Cumulative_SOC_deviation: 72.7821 Fuel Consumption: 71.0927\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.589\n",
      "Episode: 132 Exploration P: 0.0305 Total reward: -125.59681339367312 SOC: 0.5978 Cumulative_SOC_deviation: 10.2701 Fuel Consumption: 22.8954\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.148\n",
      "Episode: 133 Exploration P: 0.0300 Total reward: -127.56181383579529 SOC: 0.5987 Cumulative_SOC_deviation: 8.4968 Fuel Consumption: 42.5936\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.158\n",
      "Episode: 134 Exploration P: 0.0294 Total reward: -95.24371352829583 SOC: 0.6107 Cumulative_SOC_deviation: 6.8109 Fuel Consumption: 27.1351\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 136.730\n",
      "Episode: 135 Exploration P: 0.0285 Total reward: -260.88501400503344 SOC: 0.5910 Cumulative_SOC_deviation: 23.1974 Fuel Consumption: 28.9111\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.848\n",
      "Episode: 136 Exploration P: 0.0282 Total reward: -80.48998145499132 SOC: 0.5954 Cumulative_SOC_deviation: 7.0385 Fuel Consumption: 10.1048\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 54.108\n",
      "Episode: 137 Exploration P: 0.0278 Total reward: -62.57165207204169 SOC: 0.5993 Cumulative_SOC_deviation: 4.5569 Fuel Consumption: 17.0025\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.189\n",
      "Episode: 138 Exploration P: 0.0273 Total reward: -79.50747267415461 SOC: 0.6137 Cumulative_SOC_deviation: 5.2070 Fuel Consumption: 27.4375\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.776\n",
      "Episode: 139 Exploration P: 0.0268 Total reward: -100.91909877744047 SOC: 0.5991 Cumulative_SOC_deviation: 7.7906 Fuel Consumption: 23.0130\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.054\n",
      "Episode: 140 Exploration P: 0.0264 Total reward: -79.49950825677342 SOC: 0.6084 Cumulative_SOC_deviation: 7.0063 Fuel Consumption: 9.4363\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -86.50107311882526 SOC: 0.5932 Cumulative_SOC_deviation: 7.3534 Fuel Consumption: 12.9666\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 54.318\n",
      "Episode: 141 Exploration P: 0.0262 Total reward: -70.85091847195898 SOC: 0.6074 Cumulative_SOC_deviation: 5.3950 Fuel Consumption: 16.9013\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 120.852\n",
      "Episode: 142 Exploration P: 0.0255 Total reward: -122.95155463018713 SOC: 0.6035 Cumulative_SOC_deviation: 9.6252 Fuel Consumption: 26.6995\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 156.833\n",
      "Episode: 143 Exploration P: 0.0247 Total reward: -197.7478505344313 SOC: 0.5944 Cumulative_SOC_deviation: 16.8748 Fuel Consumption: 28.9996\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 36.591\n",
      "Episode: 144 Exploration P: 0.0245 Total reward: -64.21288153989848 SOC: 0.5888 Cumulative_SOC_deviation: 5.9915 Fuel Consumption: 4.2978\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 121.809\n",
      "Episode: 145 Exploration P: 0.0240 Total reward: -506.8461727336681 SOC: 0.5761 Cumulative_SOC_deviation: 48.2293 Fuel Consumption: 24.5536\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 120.314\n",
      "Episode: 146 Exploration P: 0.0234 Total reward: -476.3254097055843 SOC: 0.5770 Cumulative_SOC_deviation: 45.1336 Fuel Consumption: 24.9897\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 36.079\n",
      "Episode: 147 Exploration P: 0.0233 Total reward: -26.667853484695737 SOC: 0.5934 Cumulative_SOC_deviation: 2.2065 Fuel Consumption: 4.6030\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.155\n",
      "Episode: 148 Exploration P: 0.0230 Total reward: -188.22059915551844 SOC: 0.5714 Cumulative_SOC_deviation: 18.2008 Fuel Consumption: 6.2125\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.405\n",
      "Episode: 149 Exploration P: 0.0227 Total reward: -229.5731955661855 SOC: 0.5886 Cumulative_SOC_deviation: 18.7642 Fuel Consumption: 41.9314\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 177.089\n",
      "Episode: 150 Exploration P: 0.0220 Total reward: -304.0874585147107 SOC: 0.5711 Cumulative_SOC_deviation: 28.7810 Fuel Consumption: 16.2771\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -300.6146385669181 SOC: 0.5716 Cumulative_SOC_deviation: 28.9885 Fuel Consumption: 10.7300\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.476\n",
      "Episode: 151 Exploration P: 0.0215 Total reward: -750.1936289613557 SOC: 0.5418 Cumulative_SOC_deviation: 68.1778 Fuel Consumption: 68.4152\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.755\n",
      "Episode: 152 Exploration P: 0.0212 Total reward: -720.7328981791452 SOC: 0.5653 Cumulative_SOC_deviation: 69.6315 Fuel Consumption: 24.4182\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 35.851\n",
      "Episode: 153 Exploration P: 0.0211 Total reward: -86.40555990627355 SOC: 0.5806 Cumulative_SOC_deviation: 8.2642 Fuel Consumption: 3.7640\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.900\n",
      "Episode: 154 Exploration P: 0.0207 Total reward: -864.7325887229339 SOC: 0.5244 Cumulative_SOC_deviation: 85.2562 Fuel Consumption: 12.1704\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 122.341\n",
      "Episode: 155 Exploration P: 0.0203 Total reward: -383.1112669691387 SOC: 0.6025 Cumulative_SOC_deviation: 35.6359 Fuel Consumption: 26.7524\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 160.164\n",
      "Episode: 156 Exploration P: 0.0198 Total reward: -263.39229809143734 SOC: 0.5891 Cumulative_SOC_deviation: 23.4806 Fuel Consumption: 28.5859\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.373\n",
      "Episode: 157 Exploration P: 0.0196 Total reward: -228.69295129277435 SOC: 0.6006 Cumulative_SOC_deviation: 22.0252 Fuel Consumption: 8.4407\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 121.379\n",
      "Episode: 158 Exploration P: 0.0192 Total reward: -665.6148400352697 SOC: 0.5457 Cumulative_SOC_deviation: 64.3694 Fuel Consumption: 21.9212\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 158.373\n",
      "Episode: 159 Exploration P: 0.0187 Total reward: -1880.0447775502332 SOC: 0.5525 Cumulative_SOC_deviation: 185.2980 Fuel Consumption: 27.0649\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.001\n",
      "Episode: 160 Exploration P: 0.0185 Total reward: -1211.269795643105 SOC: 0.4686 Cumulative_SOC_deviation: 117.5825 Fuel Consumption: 35.4453\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -997.9415781378364 SOC: 0.4690 Cumulative_SOC_deviation: 99.4284 Fuel Consumption: 3.6578\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 100.203\n",
      "Episode: 161 Exploration P: 0.0182 Total reward: -13285.422578647418 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 28.8694\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 138.370\n",
      "Episode: 162 Exploration P: 0.0178 Total reward: -820.0945195643054 SOC: 0.6017 Cumulative_SOC_deviation: 79.1625 Fuel Consumption: 28.4693\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.772\n",
      "Episode: 163 Exploration P: 0.0176 Total reward: -503.00094516856416 SOC: 0.5350 Cumulative_SOC_deviation: 48.4188 Fuel Consumption: 18.8125\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.867\n",
      "Episode: 164 Exploration P: 0.0174 Total reward: -430.34909072810393 SOC: 0.5629 Cumulative_SOC_deviation: 41.3466 Fuel Consumption: 16.8835\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 176.722\n",
      "Episode: 165 Exploration P: 0.0169 Total reward: -273.30522955010105 SOC: 0.5942 Cumulative_SOC_deviation: 25.5156 Fuel Consumption: 18.1489\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.573\n",
      "Episode: 166 Exploration P: 0.0167 Total reward: -462.3406936424682 SOC: 0.5472 Cumulative_SOC_deviation: 44.2713 Fuel Consumption: 19.6280\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.203\n",
      "Episode: 167 Exploration P: 0.0166 Total reward: -404.7696777407328 SOC: 0.5188 Cumulative_SOC_deviation: 40.0953 Fuel Consumption: 3.8162\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.683\n",
      "Episode: 168 Exploration P: 0.0165 Total reward: -265.7136342405356 SOC: 0.5537 Cumulative_SOC_deviation: 26.0643 Fuel Consumption: 5.0703\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "SOC is nan...\n",
      "elapsed_time: 96.262\n",
      "Episode: 169 Exploration P: 0.0162 Total reward: -13394.74151234804 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 21.2076\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 54.446\n",
      "Episode: 170 Exploration P: 0.0161 Total reward: -944.5278068663112 SOC: 0.4141 Cumulative_SOC_deviation: 94.1276 Fuel Consumption: 3.2523\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1036.681070841338 SOC: 0.4638 Cumulative_SOC_deviation: 103.3333 Fuel Consumption: 3.3484\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.308\n",
      "Episode: 171 Exploration P: 0.0159 Total reward: -2548.1896856062212 SOC: 0.2307 Cumulative_SOC_deviation: 249.7862 Fuel Consumption: 50.3276\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.390\n",
      "Episode: 172 Exploration P: 0.0157 Total reward: -1177.6007758888902 SOC: 0.4680 Cumulative_SOC_deviation: 116.4356 Fuel Consumption: 13.2446\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.757\n",
      "Episode: 173 Exploration P: 0.0156 Total reward: -114.04036585748278 SOC: 0.5679 Cumulative_SOC_deviation: 10.5672 Fuel Consumption: 8.3679\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.405\n",
      "Episode: 174 Exploration P: 0.0155 Total reward: -173.36801140593158 SOC: 0.5878 Cumulative_SOC_deviation: 14.7772 Fuel Consumption: 25.5959\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.999\n",
      "Episode: 175 Exploration P: 0.0153 Total reward: -1978.6049218910994 SOC: 0.1289 Cumulative_SOC_deviation: 196.7371 Fuel Consumption: 11.2336\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Empty_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 128.793\n",
      "Episode: 176 Exploration P: 0.0151 Total reward: -3796.303467695325 SOC: 0.3022 Cumulative_SOC_deviation: 378.5731 Fuel Consumption: 10.5720\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.565\n",
      "Episode: 177 Exploration P: 0.0150 Total reward: -1621.9087923492443 SOC: 0.3501 Cumulative_SOC_deviation: 159.5925 Fuel Consumption: 25.9837\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.669\n",
      "Episode: 178 Exploration P: 0.0149 Total reward: -565.2220968575456 SOC: 0.5383 Cumulative_SOC_deviation: 52.6330 Fuel Consumption: 38.8924\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.677\n",
      "Episode: 179 Exploration P: 0.0147 Total reward: -508.0129973385838 SOC: 0.6005 Cumulative_SOC_deviation: 48.1083 Fuel Consumption: 26.9300\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Empty_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 127.951\n",
      "Episode: 180 Exploration P: 0.0145 Total reward: -2687.059647855355 SOC: 0.3582 Cumulative_SOC_deviation: 267.2361 Fuel Consumption: 14.6983\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -272.2896243019761 SOC: 0.5562 Cumulative_SOC_deviation: 26.2160 Fuel Consumption: 10.1297\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 119.973\n",
      "Episode: 181 Exploration P: 0.0144 Total reward: -392.7432219163153 SOC: 0.6059 Cumulative_SOC_deviation: 36.5625 Fuel Consumption: 27.1179\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.638\n",
      "Episode: 182 Exploration P: 0.0143 Total reward: -225.98812854157822 SOC: 0.6055 Cumulative_SOC_deviation: 21.7186 Fuel Consumption: 8.8017\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.913\n",
      "Episode: 183 Exploration P: 0.0142 Total reward: -76.92577474695948 SOC: 0.6080 Cumulative_SOC_deviation: 6.6560 Fuel Consumption: 10.3654\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RECL\\Desktop\\Song\\graduate_paper\\program\\experiment\\generalization5\\vehicle_model_DDPG1.py:252: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  2 * r_dis)) * (v_dis - (v_dis ** 2 - 4 * r_dis * p_bat) ** (0.5)) * (p_bat >= 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.982\n",
      "Episode: 184 Exploration P: 0.0140 Total reward: -7273.284968753471 SOC: -0.0586 Cumulative_SOC_deviation: 724.5680 Fuel Consumption: 27.6052\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.845\n",
      "Episode: 185 Exploration P: 0.0139 Total reward: -322.00042618841104 SOC: 0.5452 Cumulative_SOC_deviation: 31.7628 Fuel Consumption: 4.3722\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 35.945\n",
      "Episode: 186 Exploration P: 0.0139 Total reward: -101.82729390042324 SOC: 0.5806 Cumulative_SOC_deviation: 9.8201 Fuel Consumption: 3.6264\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 178.342\n",
      "Episode: 187 Exploration P: 0.0137 Total reward: -850.2603721694869 SOC: 0.5057 Cumulative_SOC_deviation: 83.8975 Fuel Consumption: 11.2853\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 54.161\n",
      "Episode: 188 Exploration P: 0.0136 Total reward: -942.4983672119685 SOC: 0.4064 Cumulative_SOC_deviation: 93.9873 Fuel Consumption: 2.6256\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.739\n",
      "Episode: 189 Exploration P: 0.0135 Total reward: -1909.3074162903138 SOC: 0.1927 Cumulative_SOC_deviation: 189.4759 Fuel Consumption: 14.5486\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Empty_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 127.773\n",
      "Episode: 190 Exploration P: 0.0134 Total reward: -4201.222359439505 SOC: 0.2759 Cumulative_SOC_deviation: 419.2459 Fuel Consumption: 8.7634\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.031\n",
      "Episode: 191 Exploration P: 0.0133 Total reward: -279.43289622079226 SOC: 0.5060 Cumulative_SOC_deviation: 27.5157 Fuel Consumption: 4.2758\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 36.370\n",
      "Episode: 192 Exploration P: 0.0133 Total reward: -118.03311021929564 SOC: 0.5697 Cumulative_SOC_deviation: 11.5260 Fuel Consumption: 2.7728\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.904\n",
      "Episode: 193 Exploration P: 0.0132 Total reward: -297.2348500795941 SOC: 0.5029 Cumulative_SOC_deviation: 29.3243 Fuel Consumption: 3.9914\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.850\n",
      "Episode: 194 Exploration P: 0.0131 Total reward: -1677.4645576721625 SOC: 0.3969 Cumulative_SOC_deviation: 166.9200 Fuel Consumption: 8.2648\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.909\n",
      "Episode: 195 Exploration P: 0.0130 Total reward: -1928.3399061616374 SOC: 0.3598 Cumulative_SOC_deviation: 192.2609 Fuel Consumption: 5.7312\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.225\n",
      "Episode: 196 Exploration P: 0.0129 Total reward: -4180.1768505069185 SOC: 0.1118 Cumulative_SOC_deviation: 416.9896 Fuel Consumption: 10.2813\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.951\n",
      "Episode: 197 Exploration P: 0.0129 Total reward: -1764.274561850163 SOC: 1.0000 Cumulative_SOC_deviation: 165.6463 Fuel Consumption: 107.8116\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.834\n",
      "Episode: 198 Exploration P: 0.0128 Total reward: -4280.587692666507 SOC: 1.0000 Cumulative_SOC_deviation: 404.7308 Fuel Consumption: 233.2801\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.795\n",
      "Episode: 199 Exploration P: 0.0127 Total reward: -4284.872191587471 SOC: 1.0000 Cumulative_SOC_deviation: 405.0788 Fuel Consumption: 234.0846\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.452\n",
      "Episode: 200 Exploration P: 0.0127 Total reward: -5456.06045036635 SOC: 1.0000 Cumulative_SOC_deviation: 515.8490 Fuel Consumption: 297.5705\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -5641.035927475313 SOC: 1.0000 Cumulative_SOC_deviation: 533.6285 Fuel Consumption: 304.7514\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.215\n",
      "Episode: 201 Exploration P: 0.0126 Total reward: -6486.181124514496 SOC: 1.0000 Cumulative_SOC_deviation: 614.1382 Fuel Consumption: 344.7995\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 114.387\n",
      "Episode: 202 Exploration P: 0.0125 Total reward: -7567.448596087115 SOC: 1.0000 Cumulative_SOC_deviation: 716.2955 Fuel Consumption: 404.4936\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.873\n",
      "Episode: 203 Exploration P: 0.0124 Total reward: -4159.056187018666 SOC: 1.0000 Cumulative_SOC_deviation: 392.6597 Fuel Consumption: 232.4593\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.426\n",
      "Episode: 204 Exploration P: 0.0124 Total reward: -4045.3680448180558 SOC: 1.0000 Cumulative_SOC_deviation: 382.1759 Fuel Consumption: 223.6094\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.736\n",
      "Episode: 205 Exploration P: 0.0123 Total reward: -4158.267520452093 SOC: 1.0000 Cumulative_SOC_deviation: 392.6308 Fuel Consumption: 231.9594\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.282\n",
      "Episode: 206 Exploration P: 0.0123 Total reward: -5456.168051725093 SOC: 1.0000 Cumulative_SOC_deviation: 515.9006 Fuel Consumption: 297.1625\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.809\n",
      "Episode: 207 Exploration P: 0.0122 Total reward: -5986.518456936083 SOC: 1.0000 Cumulative_SOC_deviation: 567.2140 Fuel Consumption: 314.3788\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.947\n",
      "Episode: 208 Exploration P: 0.0121 Total reward: -6486.171040799731 SOC: 1.0000 Cumulative_SOC_deviation: 614.2567 Fuel Consumption: 343.6044\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.301\n",
      "Episode: 209 Exploration P: 0.0121 Total reward: -4283.742319679462 SOC: 1.0000 Cumulative_SOC_deviation: 405.0721 Fuel Consumption: 233.0216\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.111\n",
      "Episode: 210 Exploration P: 0.0120 Total reward: -7571.661994200478 SOC: 1.0000 Cumulative_SOC_deviation: 716.6809 Fuel Consumption: 404.8528\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -5641.035927475313 SOC: 1.0000 Cumulative_SOC_deviation: 533.6285 Fuel Consumption: 304.7514\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 122.587\n",
      "Episode: 211 Exploration P: 0.0119 Total reward: -8119.4977199299465 SOC: 1.0000 Cumulative_SOC_deviation: 769.0952 Fuel Consumption: 428.5455\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.006\n",
      "Episode: 212 Exploration P: 0.0119 Total reward: -4043.0646495228702 SOC: 1.0000 Cumulative_SOC_deviation: 382.1274 Fuel Consumption: 221.7908\n",
      "\n",
      "../data/driving_cycles/city\\FTP_75_cycle.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.003\n",
      "Episode: 213 Exploration P: 0.0118 Total reward: -7574.873510234353 SOC: 1.0000 Cumulative_SOC_deviation: 716.9024 Fuel Consumption: 405.8497\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.519\n",
      "Episode: 214 Exploration P: 0.0118 Total reward: -4283.170915327708 SOC: 1.0000 Cumulative_SOC_deviation: 404.9124 Fuel Consumption: 234.0472\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.484\n",
      "Episode: 215 Exploration P: 0.0117 Total reward: -6491.497376044532 SOC: 1.0000 Cumulative_SOC_deviation: 614.6741 Fuel Consumption: 344.7564\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 177.771\n",
      "Episode: 216 Exploration P: 0.0116 Total reward: -11653.06968063348 SOC: 0.9288 Cumulative_SOC_deviation: 1118.7679 Fuel Consumption: 465.3907\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.284\n",
      "Episode: 217 Exploration P: 0.0116 Total reward: -317.2628670116499 SOC: 0.5223 Cumulative_SOC_deviation: 31.2954 Fuel Consumption: 4.3087\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.412\n",
      "Episode: 218 Exploration P: 0.0116 Total reward: -1594.3330909170095 SOC: 0.3257 Cumulative_SOC_deviation: 157.0580 Fuel Consumption: 23.7527\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.644\n",
      "Episode: 219 Exploration P: 0.0115 Total reward: -2129.9303506846545 SOC: 0.3771 Cumulative_SOC_deviation: 211.3090 Fuel Consumption: 16.8408\n",
      "\n",
      "../data/driving_cycles/city\\VITO_DUBDC.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 54.901\n",
      "Episode: 220 Exploration P: 0.0115 Total reward: -854.28825428493 SOC: 0.4242 Cumulative_SOC_deviation: 85.0289 Fuel Consumption: 3.9995\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -1042.2947551629077 SOC: 0.4632 Cumulative_SOC_deviation: 103.8983 Fuel Consumption: 3.3120\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 121.512\n",
      "Episode: 221 Exploration P: 0.0114 Total reward: -1335.9683150542355 SOC: 0.6857 Cumulative_SOC_deviation: 130.0734 Fuel Consumption: 35.2344\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.700\n",
      "Episode: 222 Exploration P: 0.0114 Total reward: -4283.025405734236 SOC: 1.0000 Cumulative_SOC_deviation: 404.9717 Fuel Consumption: 233.3089\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 135.957\n",
      "Episode: 223 Exploration P: 0.0113 Total reward: -9225.471469901435 SOC: 1.0000 Cumulative_SOC_deviation: 874.0810 Fuel Consumption: 484.6619\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 35.408\n",
      "Episode: 224 Exploration P: 0.0113 Total reward: -2221.766691019252 SOC: 1.0000 Cumulative_SOC_deviation: 209.2519 Fuel Consumption: 129.2473\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 178.986\n",
      "Episode: 225 Exploration P: 0.0112 Total reward: -12087.61362202569 SOC: 1.0000 Cumulative_SOC_deviation: 1145.7059 Fuel Consumption: 630.5545\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 139.823\n",
      "Episode: 226 Exploration P: 0.0112 Total reward: -8124.134992546787 SOC: 1.0000 Cumulative_SOC_deviation: 769.4753 Fuel Consumption: 429.3815\n",
      "\n",
      "../data/driving_cycles/city\\nuremberg_r36.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.054\n",
      "Episode: 227 Exploration P: 0.0112 Total reward: -4255.275546525497 SOC: 1.0000 Cumulative_SOC_deviation: 402.4609 Fuel Consumption: 230.6670\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.647\n",
      "Episode: 228 Exploration P: 0.0111 Total reward: -5985.382198385883 SOC: 1.0000 Cumulative_SOC_deviation: 567.2075 Fuel Consumption: 313.3072\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.463\n",
      "Episode: 229 Exploration P: 0.0111 Total reward: -4284.08355127934 SOC: 1.0000 Cumulative_SOC_deviation: 405.0145 Fuel Consumption: 233.9381\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 123.641\n",
      "Episode: 230 Exploration P: 0.0111 Total reward: -8121.82077945095 SOC: 1.0000 Cumulative_SOC_deviation: 769.3686 Fuel Consumption: 428.1346\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -5641.035927475313 SOC: 1.0000 Cumulative_SOC_deviation: 533.6285 Fuel Consumption: 304.7514\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.628\n",
      "Episode: 231 Exploration P: 0.0110 Total reward: -8124.947575576525 SOC: 1.0000 Cumulative_SOC_deviation: 769.5707 Fuel Consumption: 429.2407\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "Available condition is not avail... SOC: 1\n",
      "elapsed_time: 10.232\n",
      "Episode: 232 Exploration P: 0.0110 Total reward: -463.2175936185601 SOC: 1.0000 Cumulative_SOC_deviation: 42.1416 Fuel Consumption: 41.8012\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.804\n",
      "Episode: 233 Exploration P: 0.0110 Total reward: -5604.401461344412 SOC: 0.8716 Cumulative_SOC_deviation: 554.4037 Fuel Consumption: 60.3646\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.746\n",
      "Episode: 234 Exploration P: 0.0110 Total reward: -1855.5570001137962 SOC: 0.3679 Cumulative_SOC_deviation: 184.5328 Fuel Consumption: 10.2292\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 165.960\n",
      "Episode: 235 Exploration P: 0.0109 Total reward: -921.689477982876 SOC: 0.4956 Cumulative_SOC_deviation: 91.1051 Fuel Consumption: 10.6389\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.116\n",
      "Episode: 236 Exploration P: 0.0109 Total reward: -1561.05192007537 SOC: 0.5592 Cumulative_SOC_deviation: 153.6000 Fuel Consumption: 25.0515\n",
      "\n",
      "../data/driving_cycles/city\\VITO_MOLCity.mat\n",
      "Available condition is not avail... SOC: 1\n",
      "elapsed_time: 52.153\n",
      "Episode: 237 Exploration P: 0.0109 Total reward: -3546.6708878818035 SOC: 1.0000 Cumulative_SOC_deviation: 335.1469 Fuel Consumption: 195.2024\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.102\n",
      "Episode: 238 Exploration P: 0.0108 Total reward: -4283.790630834651 SOC: 1.0000 Cumulative_SOC_deviation: 404.9970 Fuel Consumption: 233.8203\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 149.957\n",
      "Episode: 239 Exploration P: 0.0108 Total reward: -10702.879987754302 SOC: 1.0000 Cumulative_SOC_deviation: 1014.6906 Fuel Consumption: 555.9739\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_traffic.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 34.422\n",
      "Episode: 240 Exploration P: 0.0108 Total reward: -2221.901721334845 SOC: 1.0000 Cumulative_SOC_deviation: 209.2519 Fuel Consumption: 129.3823\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -5641.035927475313 SOC: 1.0000 Cumulative_SOC_deviation: 533.6285 Fuel Consumption: 304.7514\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.901\n",
      "Episode: 241 Exploration P: 0.0108 Total reward: -8120.5973077661865 SOC: 1.0000 Cumulative_SOC_deviation: 769.2241 Fuel Consumption: 428.3559\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 117.971\n",
      "Episode: 242 Exploration P: 0.0107 Total reward: -9112.90708513517 SOC: 0.9773 Cumulative_SOC_deviation: 870.1798 Fuel Consumption: 411.1087\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 134.289\n",
      "Episode: 243 Exploration P: 0.0107 Total reward: -4959.7491671632615 SOC: 0.3247 Cumulative_SOC_deviation: 494.9869 Fuel Consumption: 9.8797\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Full_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 134.407\n",
      "Episode: 244 Exploration P: 0.0107 Total reward: -6837.4323296898565 SOC: 1.0000 Cumulative_SOC_deviation: 653.5833 Fuel Consumption: 301.5995\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.427\n",
      "Episode: 245 Exploration P: 0.0106 Total reward: -1375.371906621884 SOC: 0.4567 Cumulative_SOC_deviation: 135.9770 Fuel Consumption: 15.6017\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 55.997\n",
      "Episode: 246 Exploration P: 0.0106 Total reward: -366.1053074329268 SOC: 0.5377 Cumulative_SOC_deviation: 36.2354 Fuel Consumption: 3.7516\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.513\n",
      "Episode: 247 Exploration P: 0.0106 Total reward: -1355.3418921364812 SOC: 0.4470 Cumulative_SOC_deviation: 134.8879 Fuel Consumption: 6.4626\n",
      "\n",
      "../data/driving_cycles/city\\01_FTP72_fuds.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.618\n",
      "Episode: 248 Exploration P: 0.0106 Total reward: -1600.91315371229 SOC: 0.5380 Cumulative_SOC_deviation: 156.0124 Fuel Consumption: 40.7892\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_TMB_Line24N_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 147.460\n",
      "Episode: 249 Exploration P: 0.0105 Total reward: -856.1547784018697 SOC: 0.6671 Cumulative_SOC_deviation: 83.2958 Fuel Consumption: 23.1971\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 52.888\n",
      "Episode: 250 Exploration P: 0.0105 Total reward: -77.45412410070955 SOC: 0.6014 Cumulative_SOC_deviation: 6.8192 Fuel Consumption: 9.2623\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -69.10748130073148 SOC: 0.6037 Cumulative_SOC_deviation: 5.6346 Fuel Consumption: 12.7619\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.565\n",
      "Episode: 251 Exploration P: 0.0105 Total reward: -1665.228778014859 SOC: 0.3386 Cumulative_SOC_deviation: 165.2549 Fuel Consumption: 12.6793\n",
      "\n",
      "../data/driving_cycles/city\\07_manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 55.410\n",
      "Episode: 252 Exploration P: 0.0105 Total reward: -329.09993158225427 SOC: 0.5434 Cumulative_SOC_deviation: 32.4831 Fuel Consumption: 4.2687\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Medium_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 115.542\n",
      "Episode: 253 Exploration P: 0.0105 Total reward: -4884.763449846053 SOC: 0.9844 Cumulative_SOC_deviation: 473.6472 Fuel Consumption: 148.2916\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_BUS_VH_Brussels_Empty_1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.966\n",
      "Episode: 254 Exploration P: 0.0105 Total reward: -339.7127089333145 SOC: 0.6013 Cumulative_SOC_deviation: 30.9548 Fuel Consumption: 30.1646\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 52.440\n",
      "Episode: 255 Exploration P: 0.0105 Total reward: -50.38344806147761 SOC: 0.5955 Cumulative_SOC_deviation: 4.1524 Fuel Consumption: 8.8592\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.031\n",
      "Episode: 256 Exploration P: 0.0104 Total reward: -113.17443622454279 SOC: 0.5940 Cumulative_SOC_deviation: 9.7091 Fuel Consumption: 16.0836\n",
      "\n",
      "../data/driving_cycles/city\\manhattan.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 53.868\n",
      "Episode: 257 Exploration P: 0.0104 Total reward: -76.36118563679732 SOC: 0.5998 Cumulative_SOC_deviation: 6.8317 Fuel Consumption: 8.0446\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.757\n",
      "Episode: 258 Exploration P: 0.0104 Total reward: -1117.426256836993 SOC: 0.6027 Cumulative_SOC_deviation: 109.0861 Fuel Consumption: 26.5652\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.688\n",
      "Episode: 259 Exploration P: 0.0104 Total reward: -327.1477215279207 SOC: 0.6252 Cumulative_SOC_deviation: 30.8687 Fuel Consumption: 18.4604\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Antwerp1_May19c.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 52.081\n",
      "Episode: 260 Exploration P: 0.0104 Total reward: -298.094693962226 SOC: 0.6502 Cumulative_SOC_deviation: 28.5383 Fuel Consumption: 12.7119\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "../data/driving_cycles/city\\wvucity.mat\n",
      "Total reward: -728.8473373023218 SOC: 0.6504 Cumulative_SOC_deviation: 71.2500 Fuel Consumption: 16.3469\n",
      "******************* Test is done *****************\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.620\n",
      "Episode: 261 Exploration P: 0.0104 Total reward: -554.576581651105 SOC: 0.5736 Cumulative_SOC_deviation: 53.4222 Fuel Consumption: 20.3545\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.960\n",
      "Episode: 262 Exploration P: 0.0104 Total reward: -554.3734946109171 SOC: 0.5233 Cumulative_SOC_deviation: 52.8193 Fuel Consumption: 26.1800\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Polo_BCN_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.299\n",
      "Episode: 263 Exploration P: 0.0104 Total reward: -980.0035288865083 SOC: 0.5746 Cumulative_SOC_deviation: 95.9001 Fuel Consumption: 21.0028\n",
      "\n",
      "../data/driving_cycles/city\\06_udds_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 53.734\n",
      "Episode: 264 Exploration P: 0.0104 Total reward: -663.42334699647 SOC: 0.5693 Cumulative_SOC_deviation: 62.3838 Fuel Consumption: 39.5856\n",
      "\n",
      "../data/driving_cycles/city\\ny_city_composite_truck.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 52.313\n",
      "Episode: 265 Exploration P: 0.0103 Total reward: -149.8776424780005 SOC: 0.5898 Cumulative_SOC_deviation: 14.0708 Fuel Consumption: 9.1696\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Jumper_MOL_City1.mat\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.933\n",
      "Episode: 266 Exploration P: 0.0103 Total reward: -1082.4667479227628 SOC: 0.5632 Cumulative_SOC_deviation: 106.0166 Fuel Consumption: 22.3003\n",
      "\n",
      "../data/driving_cycles/city\\VITO_RW_Decade_Octavia_MOL_City1.mat\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-063fecaadcf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mDELAY_TRAINING\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mupdate_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m                 eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n\u001b[0;32m     46\u001b[0m                                                                         -DELAY_TRAINING))\n",
      "\u001b[1;32m<ipython-input-5-732055c3c3b0>\u001b[0m in \u001b[0;36mupdate_target\u001b[1;34m(tau)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtarget_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_actor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactor_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mnew_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_variables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtarget_actor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2.1_song\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_run_op\u001b[1;34m(a, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m     \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_run_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2.1_song\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mvalue\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    527\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_as_graph_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2.1_song\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[0mvariable_accessed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     result = gen_resource_variable_ops.read_variable_op(self._handle,\n\u001b[1;32m--> 613\u001b[1;33m                                                         self._dtype)\n\u001b[0m\u001b[0;32m    614\u001b[0m     \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2.1_song\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    468\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m    469\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ReadVariableOp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m         tld.op_callbacks, resource, \"dtype\", dtype)\n\u001b[0m\u001b[0;32m    471\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(env.version)\n",
    "\n",
    "num_trials = 1\n",
    "results_dict = {} \n",
    "driving_cycle_paths = glob.glob(\"../data/driving_cycles/city/*.mat\")[:20]\n",
    "\n",
    "for trial in range(num_trials): \n",
    "    print(\"\")\n",
    "    print(\"Trial {}\".format(trial))\n",
    "    print(\"\")\n",
    "    \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer = initialization()\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    episode_test_history = [] \n",
    "    episode_num_test = [] \n",
    "    for ep in range(total_episodes): \n",
    "        driving_cycle_path = np.random.choice(driving_cycle_paths)\n",
    "        print(driving_cycle_path)\n",
    "        env = initialization_env(driving_cycle_path, 10)\n",
    "        \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
    "                                                                        -DELAY_TRAINING))\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_SOCs.append(env.SOC)\n",
    "        episode_FCs.append(env.fuel_consumption) \n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        print(\n",
    "              'Episode: {}'.format(ep + 1),\n",
    "              \"Exploration P: {:.4f}\".format(eps),\n",
    "              'Total reward: {}'.format(episodic_reward), \n",
    "              \"SOC: {:.4f}\".format(env.SOC), \n",
    "              \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "              \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "        )\n",
    "        print(\"\")\n",
    "        \n",
    "        if (ep + 1) % 10 == 0: \n",
    "            history = test_agent(actor_model, 10, -1)\n",
    "            episode_test_history.append(history) \n",
    "            episode_num_test.append(ep + 1)\n",
    "    \n",
    "    root = \"DDPG4_trial{}\".format(trial+1)\n",
    "    save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "    \n",
    "    results_dict[trial + 1] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs, \n",
    "        \"test_history\": episode_test_history, \n",
    "        \"test_episode_num\": episode_num_test, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDPG4.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
