{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "\n",
    "from vehicle_model_DDPG2 import Environment \n",
    "from cell_model import CellModel \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_e-4wd_Battery.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_id_75_110_Westinghouse.mat\"\n",
    "cell_model = CellModel()\n",
    "env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64): \n",
    "        self.power_mean = 0 \n",
    "        self.power_std = 0\n",
    "        self.sum = 0 \n",
    "        self.sum_deviation = 0 \n",
    "        self.N = 0 \n",
    "        \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        self.N += 1 \n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "        power = obs_tuple[0][0] \n",
    "        \n",
    "        self.sum += power \n",
    "        self.power_mean = self.sum / self.N \n",
    "        self.sum_deviation += (power - self.power_mean) ** 2  \n",
    "        self.power_std = np.sqrt(self.sum_deviation / self.N) \n",
    "            \n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "        \n",
    "        state_batch = self.state_buffer[batch_indices]\n",
    "        power_batch = (state_batch[:, 0] - self.power_mean) / self.power_std\n",
    "        state_batch[:, 0] = power_batch \n",
    "        \n",
    "        next_state_batch = self.next_state_buffer[batch_indices]\n",
    "        power_batch = (next_state_batch[:, 0] - self.power_mean) / self.power_std\n",
    "        next_state_batch[:, 0] = power_batch \n",
    "#         print(state_batch)\n",
    "        \n",
    "        state_batch = tf.convert_to_tensor(state_batch)\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(next_state_batch)\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_input)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 200\n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 3000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(reward_factor): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "\n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    \n",
    "    env = Environment(cell_model, drving_cycle, battery_path, motor_path, reward_factor)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer, env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_model, critic_model, target_actor, target_critic, root): \n",
    "    actor_model.save_weights(\"./{}/actor_model_checkpoint\".format(root))\n",
    "    critic_model.save_weights(\"./{}/critic_model_checkpoint\".format(root))\n",
    "    target_actor.save_weights(\"./{}/target_actor_checkpoint\".format(root))\n",
    "    target_critic.save_weights(\"./{}/target_critic_checkpoint\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "\n",
      "Trial 1\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 17.817\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -995.6136010468043 SOC: 0.8193 Cumulative_SOC_deviation: 93.3047 Fuel Consumption: 62.5670\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 16.736\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -841.1839912199556 SOC: 0.7747 Cumulative_SOC_deviation: 78.2230 Fuel Consumption: 58.9540\n",
      "WARNING:tensorflow:Layer dense_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_13 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 52.403\n",
      "Episode: 3 Exploration P: 0.9217 Total reward: -851.256816484997 SOC: 0.7763 Cumulative_SOC_deviation: 79.2099 Fuel Consumption: 59.1574\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.434\n",
      "Episode: 4 Exploration P: 0.8970 Total reward: -817.0248576919671 SOC: 0.7585 Cumulative_SOC_deviation: 75.9357 Fuel Consumption: 57.6683\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.331\n",
      "Episode: 5 Exploration P: 0.8730 Total reward: -745.5654013327678 SOC: 0.7142 Cumulative_SOC_deviation: 69.1369 Fuel Consumption: 54.1959\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.395\n",
      "Episode: 6 Exploration P: 0.8496 Total reward: -730.2716602540095 SOC: 0.7143 Cumulative_SOC_deviation: 67.5981 Fuel Consumption: 54.2904\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.134\n",
      "Episode: 7 Exploration P: 0.8269 Total reward: -812.1436495745035 SOC: 0.6903 Cumulative_SOC_deviation: 75.9595 Fuel Consumption: 52.5487\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.239\n",
      "Episode: 8 Exploration P: 0.8048 Total reward: -814.8053541808163 SOC: 0.6632 Cumulative_SOC_deviation: 76.4387 Fuel Consumption: 50.4186\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.194\n",
      "Episode: 9 Exploration P: 0.7832 Total reward: -898.3640003625093 SOC: 0.6374 Cumulative_SOC_deviation: 85.0011 Fuel Consumption: 48.3526\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.215\n",
      "Episode: 10 Exploration P: 0.7623 Total reward: -883.5408790123253 SOC: 0.6486 Cumulative_SOC_deviation: 83.4352 Fuel Consumption: 49.1893\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.490\n",
      "Episode: 11 Exploration P: 0.7419 Total reward: -964.0751145587886 SOC: 0.6278 Cumulative_SOC_deviation: 91.6370 Fuel Consumption: 47.7054\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.627\n",
      "Episode: 12 Exploration P: 0.7221 Total reward: -1032.4398067434597 SOC: 0.6111 Cumulative_SOC_deviation: 98.6281 Fuel Consumption: 46.1583\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.784\n",
      "Episode: 13 Exploration P: 0.7028 Total reward: -1183.9790330926303 SOC: 0.5776 Cumulative_SOC_deviation: 114.0168 Fuel Consumption: 43.8110\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.389\n",
      "Episode: 14 Exploration P: 0.6840 Total reward: -1419.4826807977943 SOC: 0.5502 Cumulative_SOC_deviation: 137.7745 Fuel Consumption: 41.7376\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.024\n",
      "Episode: 15 Exploration P: 0.6658 Total reward: -1203.5826269914878 SOC: 0.5826 Cumulative_SOC_deviation: 115.9133 Fuel Consumption: 44.4497\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.709\n",
      "Episode: 16 Exploration P: 0.6480 Total reward: -1463.0202338550428 SOC: 0.5372 Cumulative_SOC_deviation: 142.2309 Fuel Consumption: 40.7116\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.270\n",
      "Episode: 17 Exploration P: 0.6307 Total reward: -1453.3004110192117 SOC: 0.5418 Cumulative_SOC_deviation: 141.2010 Fuel Consumption: 41.2904\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.475\n",
      "Episode: 18 Exploration P: 0.6139 Total reward: -1568.5101528620196 SOC: 0.5202 Cumulative_SOC_deviation: 152.8838 Fuel Consumption: 39.6717\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.404\n",
      "Episode: 19 Exploration P: 0.5976 Total reward: -1863.3123848455914 SOC: 0.4778 Cumulative_SOC_deviation: 182.7045 Fuel Consumption: 36.2674\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.368\n",
      "Episode: 20 Exploration P: 0.5816 Total reward: -1834.443074953154 SOC: 0.4900 Cumulative_SOC_deviation: 179.7227 Fuel Consumption: 37.2163\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.659\n",
      "Episode: 21 Exploration P: 0.5662 Total reward: -1973.9071420568862 SOC: 0.4637 Cumulative_SOC_deviation: 193.8499 Fuel Consumption: 35.4082\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.609\n",
      "Episode: 22 Exploration P: 0.5511 Total reward: -2017.2606591112376 SOC: 0.4642 Cumulative_SOC_deviation: 198.1928 Fuel Consumption: 35.3323\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.447\n",
      "Episode: 23 Exploration P: 0.5364 Total reward: -2294.158502045736 SOC: 0.4357 Cumulative_SOC_deviation: 226.0925 Fuel Consumption: 33.2332\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.427\n",
      "Episode: 24 Exploration P: 0.5222 Total reward: -1224.224552307045 SOC: 0.6770 Cumulative_SOC_deviation: 117.2124 Fuel Consumption: 52.1008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.492\n",
      "Episode: 25 Exploration P: 0.5083 Total reward: -662.8688534301347 SOC: 0.6905 Cumulative_SOC_deviation: 61.0669 Fuel Consumption: 52.1995\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.567\n",
      "Episode: 26 Exploration P: 0.4948 Total reward: -614.683984028929 SOC: 0.6794 Cumulative_SOC_deviation: 56.3277 Fuel Consumption: 51.4068\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.829\n",
      "Episode: 27 Exploration P: 0.4817 Total reward: -629.9066508487747 SOC: 0.6824 Cumulative_SOC_deviation: 57.8358 Fuel Consumption: 51.5485\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.212\n",
      "Episode: 28 Exploration P: 0.4689 Total reward: -621.313153270886 SOC: 0.6838 Cumulative_SOC_deviation: 56.9605 Fuel Consumption: 51.7080\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.168\n",
      "Episode: 29 Exploration P: 0.4565 Total reward: -539.1016307825864 SOC: 0.6688 Cumulative_SOC_deviation: 48.8538 Fuel Consumption: 50.5638\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.279\n",
      "Episode: 30 Exploration P: 0.4444 Total reward: -608.893023124817 SOC: 0.6832 Cumulative_SOC_deviation: 55.7155 Fuel Consumption: 51.7382\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.604\n",
      "Episode: 31 Exploration P: 0.4326 Total reward: -564.203083255425 SOC: 0.6682 Cumulative_SOC_deviation: 51.3581 Fuel Consumption: 50.6217\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.313\n",
      "Episode: 32 Exploration P: 0.4212 Total reward: -568.0007902316445 SOC: 0.6719 Cumulative_SOC_deviation: 51.7140 Fuel Consumption: 50.8609\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.356\n",
      "Episode: 33 Exploration P: 0.4100 Total reward: -548.0704403833441 SOC: 0.6773 Cumulative_SOC_deviation: 49.6759 Fuel Consumption: 51.3112\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.037\n",
      "Episode: 34 Exploration P: 0.3992 Total reward: -545.7972049849218 SOC: 0.6726 Cumulative_SOC_deviation: 49.4901 Fuel Consumption: 50.8962\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.309\n",
      "Episode: 35 Exploration P: 0.3887 Total reward: -503.0498481703628 SOC: 0.6598 Cumulative_SOC_deviation: 45.3162 Fuel Consumption: 49.8883\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.143\n",
      "Episode: 36 Exploration P: 0.3784 Total reward: -487.2877946340984 SOC: 0.6470 Cumulative_SOC_deviation: 43.8526 Fuel Consumption: 48.7613\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.260\n",
      "Episode: 37 Exploration P: 0.3684 Total reward: -465.43295989096214 SOC: 0.6470 Cumulative_SOC_deviation: 41.6515 Fuel Consumption: 48.9180\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.602\n",
      "Episode: 38 Exploration P: 0.3587 Total reward: -460.60847664975887 SOC: 0.6494 Cumulative_SOC_deviation: 41.1415 Fuel Consumption: 49.1931\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.585\n",
      "Episode: 39 Exploration P: 0.3493 Total reward: -424.5212999953302 SOC: 0.6368 Cumulative_SOC_deviation: 37.6259 Fuel Consumption: 48.2620\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.281\n",
      "Episode: 40 Exploration P: 0.3401 Total reward: -455.35022515198057 SOC: 0.6390 Cumulative_SOC_deviation: 40.7051 Fuel Consumption: 48.2989\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.287\n",
      "Episode: 41 Exploration P: 0.3311 Total reward: -429.5878818869286 SOC: 0.6493 Cumulative_SOC_deviation: 38.0602 Fuel Consumption: 48.9858\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.443\n",
      "Episode: 42 Exploration P: 0.3224 Total reward: -377.9216357464965 SOC: 0.6340 Cumulative_SOC_deviation: 33.0155 Fuel Consumption: 47.7664\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.496\n",
      "Episode: 43 Exploration P: 0.3140 Total reward: -383.1223315651529 SOC: 0.6315 Cumulative_SOC_deviation: 33.5447 Fuel Consumption: 47.6754\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.388\n",
      "Episode: 44 Exploration P: 0.3057 Total reward: -376.5329271224634 SOC: 0.6337 Cumulative_SOC_deviation: 32.8803 Fuel Consumption: 47.7299\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.418\n",
      "Episode: 45 Exploration P: 0.2977 Total reward: -347.0334246557767 SOC: 0.6370 Cumulative_SOC_deviation: 29.9164 Fuel Consumption: 47.8692\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.425\n",
      "Episode: 46 Exploration P: 0.2899 Total reward: -375.5866716194145 SOC: 0.6289 Cumulative_SOC_deviation: 32.8258 Fuel Consumption: 47.3292\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.988\n",
      "Episode: 47 Exploration P: 0.2824 Total reward: -372.91237040865747 SOC: 0.6316 Cumulative_SOC_deviation: 32.5289 Fuel Consumption: 47.6236\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.203\n",
      "Episode: 48 Exploration P: 0.2750 Total reward: -391.2510496739623 SOC: 0.6321 Cumulative_SOC_deviation: 34.3794 Fuel Consumption: 47.4572\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.426\n",
      "Episode: 49 Exploration P: 0.2678 Total reward: -384.16171032013114 SOC: 0.6331 Cumulative_SOC_deviation: 33.6541 Fuel Consumption: 47.6208\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.606\n",
      "Episode: 50 Exploration P: 0.2608 Total reward: -370.706474977384 SOC: 0.6274 Cumulative_SOC_deviation: 32.3493 Fuel Consumption: 47.2133\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.441\n",
      "Episode: 51 Exploration P: 0.2540 Total reward: -357.7737282376651 SOC: 0.6309 Cumulative_SOC_deviation: 31.0371 Fuel Consumption: 47.4025\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.524\n",
      "Episode: 52 Exploration P: 0.2474 Total reward: -379.5261729609278 SOC: 0.6326 Cumulative_SOC_deviation: 33.1999 Fuel Consumption: 47.5275\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.463\n",
      "Episode: 53 Exploration P: 0.2410 Total reward: -331.63673919032277 SOC: 0.6250 Cumulative_SOC_deviation: 28.4763 Fuel Consumption: 46.8740\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.644\n",
      "Episode: 54 Exploration P: 0.2347 Total reward: -348.4342219320746 SOC: 0.6295 Cumulative_SOC_deviation: 30.1170 Fuel Consumption: 47.2641\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.499\n",
      "Episode: 55 Exploration P: 0.2286 Total reward: -341.6761684606491 SOC: 0.6264 Cumulative_SOC_deviation: 29.4672 Fuel Consumption: 47.0040\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.686\n",
      "Episode: 56 Exploration P: 0.2227 Total reward: -347.2793459303972 SOC: 0.6220 Cumulative_SOC_deviation: 30.0507 Fuel Consumption: 46.7722\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.464\n",
      "Episode: 57 Exploration P: 0.2170 Total reward: -331.9756477328865 SOC: 0.6224 Cumulative_SOC_deviation: 28.5399 Fuel Consumption: 46.5767\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.660\n",
      "Episode: 58 Exploration P: 0.2114 Total reward: -327.5581867691755 SOC: 0.6240 Cumulative_SOC_deviation: 28.0890 Fuel Consumption: 46.6678\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.639\n",
      "Episode: 59 Exploration P: 0.2059 Total reward: -328.66925710412016 SOC: 0.6203 Cumulative_SOC_deviation: 28.2143 Fuel Consumption: 46.5265\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.562\n",
      "Episode: 60 Exploration P: 0.2006 Total reward: -305.30133496646965 SOC: 0.6277 Cumulative_SOC_deviation: 25.8200 Fuel Consumption: 47.1009\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.579\n",
      "Episode: 61 Exploration P: 0.1954 Total reward: -313.3179552345218 SOC: 0.6210 Cumulative_SOC_deviation: 26.6828 Fuel Consumption: 46.4904\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.648\n",
      "Episode: 62 Exploration P: 0.1904 Total reward: -331.2072981464557 SOC: 0.6207 Cumulative_SOC_deviation: 28.4752 Fuel Consumption: 46.4550\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.534\n",
      "Episode: 63 Exploration P: 0.1855 Total reward: -355.3416907996178 SOC: 0.6294 Cumulative_SOC_deviation: 30.8178 Fuel Consumption: 47.1635\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.595\n",
      "Episode: 64 Exploration P: 0.1808 Total reward: -321.43677162160304 SOC: 0.6287 Cumulative_SOC_deviation: 27.4407 Fuel Consumption: 47.0294\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.435\n",
      "Episode: 65 Exploration P: 0.1761 Total reward: -324.79974498565616 SOC: 0.6222 Cumulative_SOC_deviation: 27.8280 Fuel Consumption: 46.5201\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.795\n",
      "Episode: 66 Exploration P: 0.1716 Total reward: -325.42034478512585 SOC: 0.6182 Cumulative_SOC_deviation: 27.9192 Fuel Consumption: 46.2280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.989\n",
      "Episode: 67 Exploration P: 0.1673 Total reward: -300.31572096466715 SOC: 0.6261 Cumulative_SOC_deviation: 25.3563 Fuel Consumption: 46.7526\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.382\n",
      "Episode: 68 Exploration P: 0.1630 Total reward: -282.9284324728633 SOC: 0.6170 Cumulative_SOC_deviation: 23.6775 Fuel Consumption: 46.1532\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.605\n",
      "Episode: 69 Exploration P: 0.1589 Total reward: -319.26287747670335 SOC: 0.6148 Cumulative_SOC_deviation: 27.3318 Fuel Consumption: 45.9453\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.692\n",
      "Episode: 70 Exploration P: 0.1548 Total reward: -325.81370467341566 SOC: 0.6201 Cumulative_SOC_deviation: 27.9256 Fuel Consumption: 46.5578\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.630\n",
      "Episode: 71 Exploration P: 0.1509 Total reward: -297.6322389887327 SOC: 0.6200 Cumulative_SOC_deviation: 25.1256 Fuel Consumption: 46.3761\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.525\n",
      "Episode: 72 Exploration P: 0.1471 Total reward: -303.4293875478022 SOC: 0.6209 Cumulative_SOC_deviation: 25.6920 Fuel Consumption: 46.5090\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.814\n",
      "Episode: 73 Exploration P: 0.1434 Total reward: -284.5803745445435 SOC: 0.6147 Cumulative_SOC_deviation: 23.8631 Fuel Consumption: 45.9497\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.548\n",
      "Episode: 74 Exploration P: 0.1398 Total reward: -290.88772230789965 SOC: 0.6150 Cumulative_SOC_deviation: 24.4844 Fuel Consumption: 46.0433\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.090\n",
      "Episode: 75 Exploration P: 0.1362 Total reward: -304.0105484522409 SOC: 0.6189 Cumulative_SOC_deviation: 25.7727 Fuel Consumption: 46.2832\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.762\n",
      "Episode: 76 Exploration P: 0.1328 Total reward: -312.79006141426333 SOC: 0.6235 Cumulative_SOC_deviation: 26.6040 Fuel Consumption: 46.7502\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.466\n",
      "Episode: 77 Exploration P: 0.1295 Total reward: -286.39918284948124 SOC: 0.6190 Cumulative_SOC_deviation: 24.0041 Fuel Consumption: 46.3584\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.240\n",
      "Episode: 78 Exploration P: 0.1263 Total reward: -320.4538355554625 SOC: 0.6163 Cumulative_SOC_deviation: 27.4245 Fuel Consumption: 46.2092\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.130\n",
      "Episode: 79 Exploration P: 0.1231 Total reward: -320.9846301438821 SOC: 0.6219 Cumulative_SOC_deviation: 27.4250 Fuel Consumption: 46.7348\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.616\n",
      "Episode: 80 Exploration P: 0.1200 Total reward: -297.19906214827375 SOC: 0.6171 Cumulative_SOC_deviation: 25.1086 Fuel Consumption: 46.1131\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.901\n",
      "Episode: 81 Exploration P: 0.1171 Total reward: -308.8013942689602 SOC: 0.6202 Cumulative_SOC_deviation: 26.2495 Fuel Consumption: 46.3068\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.158\n",
      "Episode: 82 Exploration P: 0.1142 Total reward: -307.7073993380967 SOC: 0.6214 Cumulative_SOC_deviation: 26.1107 Fuel Consumption: 46.6000\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.437\n",
      "Episode: 83 Exploration P: 0.1113 Total reward: -295.3410730902832 SOC: 0.6147 Cumulative_SOC_deviation: 24.9282 Fuel Consumption: 46.0589\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.285\n",
      "Episode: 84 Exploration P: 0.1086 Total reward: -271.0659831028765 SOC: 0.6154 Cumulative_SOC_deviation: 22.5013 Fuel Consumption: 46.0532\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.003\n",
      "Episode: 85 Exploration P: 0.1059 Total reward: -287.62310851948564 SOC: 0.6135 Cumulative_SOC_deviation: 24.1614 Fuel Consumption: 46.0088\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.624\n",
      "Episode: 86 Exploration P: 0.1033 Total reward: -301.28275290311643 SOC: 0.6149 Cumulative_SOC_deviation: 25.5330 Fuel Consumption: 45.9529\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.738\n",
      "Episode: 87 Exploration P: 0.1008 Total reward: -264.5763548527157 SOC: 0.6160 Cumulative_SOC_deviation: 21.8447 Fuel Consumption: 46.1297\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.877\n",
      "Episode: 88 Exploration P: 0.0983 Total reward: -273.7176132774253 SOC: 0.6169 Cumulative_SOC_deviation: 22.7458 Fuel Consumption: 46.2599\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.881\n",
      "Episode: 89 Exploration P: 0.0960 Total reward: -287.8655549841317 SOC: 0.6138 Cumulative_SOC_deviation: 24.1954 Fuel Consumption: 45.9113\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.836\n",
      "Episode: 90 Exploration P: 0.0936 Total reward: -276.99604413033813 SOC: 0.6146 Cumulative_SOC_deviation: 23.1033 Fuel Consumption: 45.9630\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.844\n",
      "Episode: 91 Exploration P: 0.0914 Total reward: -285.25005726119934 SOC: 0.6158 Cumulative_SOC_deviation: 23.9164 Fuel Consumption: 46.0863\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.653\n",
      "Episode: 92 Exploration P: 0.0892 Total reward: -264.7586894730852 SOC: 0.6113 Cumulative_SOC_deviation: 21.8666 Fuel Consumption: 46.0930\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.630\n",
      "Episode: 93 Exploration P: 0.0870 Total reward: -259.48986713568604 SOC: 0.6124 Cumulative_SOC_deviation: 21.3569 Fuel Consumption: 45.9205\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.968\n",
      "Episode: 94 Exploration P: 0.0849 Total reward: -267.86328911170267 SOC: 0.6142 Cumulative_SOC_deviation: 22.1899 Fuel Consumption: 45.9645\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.831\n",
      "Episode: 95 Exploration P: 0.0829 Total reward: -260.1673208707635 SOC: 0.6161 Cumulative_SOC_deviation: 21.4030 Fuel Consumption: 46.1371\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.788\n",
      "Episode: 96 Exploration P: 0.0809 Total reward: -286.20053721803146 SOC: 0.6138 Cumulative_SOC_deviation: 24.0239 Fuel Consumption: 45.9613\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.936\n",
      "Episode: 97 Exploration P: 0.0790 Total reward: -267.3810129575389 SOC: 0.6133 Cumulative_SOC_deviation: 22.0859 Fuel Consumption: 46.5225\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.384\n",
      "Episode: 98 Exploration P: 0.0771 Total reward: -250.852169245173 SOC: 0.6104 Cumulative_SOC_deviation: 20.4842 Fuel Consumption: 46.0104\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 56.909\n",
      "Episode: 99 Exploration P: 0.0753 Total reward: -266.44097705198254 SOC: 0.6098 Cumulative_SOC_deviation: 22.0196 Fuel Consumption: 46.2448\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.667\n",
      "Episode: 100 Exploration P: 0.0735 Total reward: -258.638988569581 SOC: 0.6104 Cumulative_SOC_deviation: 21.2707 Fuel Consumption: 45.9324\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.902\n",
      "Episode: 101 Exploration P: 0.0718 Total reward: -259.45095686614115 SOC: 0.6104 Cumulative_SOC_deviation: 21.3490 Fuel Consumption: 45.9610\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 56.549\n",
      "Episode: 102 Exploration P: 0.0701 Total reward: -264.99337398357517 SOC: 0.6104 Cumulative_SOC_deviation: 21.8987 Fuel Consumption: 46.0066\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.034\n",
      "Episode: 103 Exploration P: 0.0685 Total reward: -273.4025561665453 SOC: 0.6111 Cumulative_SOC_deviation: 22.7486 Fuel Consumption: 45.9165\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 56.444\n",
      "Episode: 104 Exploration P: 0.0669 Total reward: -285.63398819604345 SOC: 0.6176 Cumulative_SOC_deviation: 23.9193 Fuel Consumption: 46.4406\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 56.401\n",
      "Episode: 105 Exploration P: 0.0654 Total reward: -269.24054295468886 SOC: 0.6131 Cumulative_SOC_deviation: 22.2873 Fuel Consumption: 46.3670\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 56.689\n",
      "Episode: 106 Exploration P: 0.0639 Total reward: -240.68509583275022 SOC: 0.6060 Cumulative_SOC_deviation: 19.5045 Fuel Consumption: 45.6400\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.243\n",
      "Episode: 107 Exploration P: 0.0624 Total reward: -252.06512565148532 SOC: 0.6081 Cumulative_SOC_deviation: 20.6049 Fuel Consumption: 46.0157\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.617\n",
      "Episode: 108 Exploration P: 0.0610 Total reward: -263.9902391012886 SOC: 0.6109 Cumulative_SOC_deviation: 21.8095 Fuel Consumption: 45.8956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.227\n",
      "Episode: 109 Exploration P: 0.0596 Total reward: -260.3270441987932 SOC: 0.6088 Cumulative_SOC_deviation: 21.4924 Fuel Consumption: 45.4035\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.059\n",
      "Episode: 110 Exploration P: 0.0583 Total reward: -250.7905200794421 SOC: 0.6141 Cumulative_SOC_deviation: 20.4562 Fuel Consumption: 46.2283\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.297\n",
      "Episode: 111 Exploration P: 0.0570 Total reward: -253.07637710119425 SOC: 0.6104 Cumulative_SOC_deviation: 20.7258 Fuel Consumption: 45.8186\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.435\n",
      "Episode: 112 Exploration P: 0.0557 Total reward: -265.3346768084512 SOC: 0.6126 Cumulative_SOC_deviation: 21.9647 Fuel Consumption: 45.6882\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.229\n",
      "Episode: 113 Exploration P: 0.0545 Total reward: -264.01710481482615 SOC: 0.6169 Cumulative_SOC_deviation: 21.7840 Fuel Consumption: 46.1775\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.039\n",
      "Episode: 114 Exploration P: 0.0533 Total reward: -272.9467029171791 SOC: 0.6110 Cumulative_SOC_deviation: 22.7112 Fuel Consumption: 45.8348\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.085\n",
      "Episode: 115 Exploration P: 0.0521 Total reward: -265.07836049315637 SOC: 0.6157 Cumulative_SOC_deviation: 21.8903 Fuel Consumption: 46.1753\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.344\n",
      "Episode: 116 Exploration P: 0.0510 Total reward: -264.57166348380485 SOC: 0.6153 Cumulative_SOC_deviation: 21.8582 Fuel Consumption: 45.9900\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.852\n",
      "Episode: 117 Exploration P: 0.0498 Total reward: -243.4870869493545 SOC: 0.6079 Cumulative_SOC_deviation: 19.7843 Fuel Consumption: 45.6443\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.352\n",
      "Episode: 118 Exploration P: 0.0488 Total reward: -265.6950841493188 SOC: 0.6112 Cumulative_SOC_deviation: 21.9915 Fuel Consumption: 45.7796\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.730\n",
      "Episode: 119 Exploration P: 0.0477 Total reward: -259.8516330561028 SOC: 0.6123 Cumulative_SOC_deviation: 21.3884 Fuel Consumption: 45.9678\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.667\n",
      "Episode: 120 Exploration P: 0.0467 Total reward: -221.86720241818827 SOC: 0.6099 Cumulative_SOC_deviation: 17.5745 Fuel Consumption: 46.1221\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 56.717\n",
      "Episode: 121 Exploration P: 0.0457 Total reward: -261.06656397169587 SOC: 0.6076 Cumulative_SOC_deviation: 21.5334 Fuel Consumption: 45.7325\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.420\n",
      "Episode: 122 Exploration P: 0.0447 Total reward: -269.79271667418544 SOC: 0.6087 Cumulative_SOC_deviation: 22.4174 Fuel Consumption: 45.6184\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.335\n",
      "Episode: 123 Exploration P: 0.0438 Total reward: -262.2556877219783 SOC: 0.6095 Cumulative_SOC_deviation: 21.6384 Fuel Consumption: 45.8718\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.875\n",
      "Episode: 124 Exploration P: 0.0429 Total reward: -232.0796713372552 SOC: 0.6038 Cumulative_SOC_deviation: 18.6447 Fuel Consumption: 45.6323\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.939\n",
      "Episode: 125 Exploration P: 0.0420 Total reward: -228.83862496616877 SOC: 0.6078 Cumulative_SOC_deviation: 18.2739 Fuel Consumption: 46.0999\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.000\n",
      "Episode: 126 Exploration P: 0.0411 Total reward: -259.8026046917327 SOC: 0.6120 Cumulative_SOC_deviation: 21.3223 Fuel Consumption: 46.5791\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.219\n",
      "Episode: 127 Exploration P: 0.0403 Total reward: -227.29280267125745 SOC: 0.6059 Cumulative_SOC_deviation: 18.1594 Fuel Consumption: 45.6985\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.005\n",
      "Episode: 128 Exploration P: 0.0395 Total reward: -250.97948090380535 SOC: 0.6062 Cumulative_SOC_deviation: 20.4874 Fuel Consumption: 46.1058\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.111\n",
      "Episode: 129 Exploration P: 0.0387 Total reward: -240.0069596924741 SOC: 0.6080 Cumulative_SOC_deviation: 19.4128 Fuel Consumption: 45.8785\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.013\n",
      "Episode: 130 Exploration P: 0.0379 Total reward: -243.0963712267635 SOC: 0.6102 Cumulative_SOC_deviation: 19.6914 Fuel Consumption: 46.1828\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.600\n",
      "Episode: 131 Exploration P: 0.0371 Total reward: -253.19571659270912 SOC: 0.6058 Cumulative_SOC_deviation: 20.7702 Fuel Consumption: 45.4941\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.222\n",
      "Episode: 132 Exploration P: 0.0364 Total reward: -240.9395766610636 SOC: 0.6105 Cumulative_SOC_deviation: 19.5015 Fuel Consumption: 45.9243\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.301\n",
      "Episode: 133 Exploration P: 0.0357 Total reward: -232.1544442871826 SOC: 0.6074 Cumulative_SOC_deviation: 18.6567 Fuel Consumption: 45.5871\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.564\n",
      "Episode: 134 Exploration P: 0.0350 Total reward: -237.3029229174028 SOC: 0.6123 Cumulative_SOC_deviation: 19.1424 Fuel Consumption: 45.8787\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.112\n",
      "Episode: 135 Exploration P: 0.0343 Total reward: -252.73516984106627 SOC: 0.6144 Cumulative_SOC_deviation: 20.6634 Fuel Consumption: 46.1013\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.616\n",
      "Episode: 136 Exploration P: 0.0336 Total reward: -230.25973405436568 SOC: 0.6063 Cumulative_SOC_deviation: 18.4973 Fuel Consumption: 45.2862\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.272\n",
      "Episode: 137 Exploration P: 0.0330 Total reward: -227.4113566858095 SOC: 0.6059 Cumulative_SOC_deviation: 18.1835 Fuel Consumption: 45.5759\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.408\n",
      "Episode: 138 Exploration P: 0.0324 Total reward: -257.12014833352094 SOC: 0.6148 Cumulative_SOC_deviation: 21.1019 Fuel Consumption: 46.1015\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.633\n",
      "Episode: 139 Exploration P: 0.0318 Total reward: -237.70629878895215 SOC: 0.6070 Cumulative_SOC_deviation: 19.2305 Fuel Consumption: 45.4008\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.907\n",
      "Episode: 140 Exploration P: 0.0312 Total reward: -222.25634423507836 SOC: 0.6065 Cumulative_SOC_deviation: 17.6715 Fuel Consumption: 45.5413\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.223\n",
      "Episode: 141 Exploration P: 0.0306 Total reward: -194.51368412649407 SOC: 0.6044 Cumulative_SOC_deviation: 14.9212 Fuel Consumption: 45.3017\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.753\n",
      "Episode: 142 Exploration P: 0.0301 Total reward: -230.49747939272518 SOC: 0.6078 Cumulative_SOC_deviation: 18.4888 Fuel Consumption: 45.6096\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.013\n",
      "Episode: 143 Exploration P: 0.0295 Total reward: -221.39685225041248 SOC: 0.6124 Cumulative_SOC_deviation: 17.5363 Fuel Consumption: 46.0339\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.687\n",
      "Episode: 144 Exploration P: 0.0290 Total reward: -236.2207372404874 SOC: 0.6055 Cumulative_SOC_deviation: 19.0559 Fuel Consumption: 45.6615\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.349\n",
      "Episode: 145 Exploration P: 0.0285 Total reward: -215.4340258504221 SOC: 0.6110 Cumulative_SOC_deviation: 16.9577 Fuel Consumption: 45.8567\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.125\n",
      "Episode: 146 Exploration P: 0.0280 Total reward: -252.0138165058923 SOC: 0.6144 Cumulative_SOC_deviation: 20.5790 Fuel Consumption: 46.2237\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.078\n",
      "Episode: 147 Exploration P: 0.0275 Total reward: -221.16494502526274 SOC: 0.6085 Cumulative_SOC_deviation: 17.5541 Fuel Consumption: 45.6236\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.332\n",
      "Episode: 148 Exploration P: 0.0270 Total reward: -231.80152413669265 SOC: 0.6153 Cumulative_SOC_deviation: 18.5653 Fuel Consumption: 46.1482\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.212\n",
      "Episode: 149 Exploration P: 0.0265 Total reward: -243.0714895774572 SOC: 0.6125 Cumulative_SOC_deviation: 19.7049 Fuel Consumption: 46.0228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.369\n",
      "Episode: 150 Exploration P: 0.0261 Total reward: -243.76683057004723 SOC: 0.6085 Cumulative_SOC_deviation: 19.8095 Fuel Consumption: 45.6718\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.134\n",
      "Episode: 151 Exploration P: 0.0257 Total reward: -233.86531013096402 SOC: 0.6095 Cumulative_SOC_deviation: 18.8164 Fuel Consumption: 45.7016\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.553\n",
      "Episode: 152 Exploration P: 0.0252 Total reward: -226.0000416406831 SOC: 0.6052 Cumulative_SOC_deviation: 18.0641 Fuel Consumption: 45.3589\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 133.355\n",
      "Episode: 153 Exploration P: 0.0248 Total reward: -240.2145847786676 SOC: 0.6149 Cumulative_SOC_deviation: 19.4011 Fuel Consumption: 46.2033\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.546\n",
      "Episode: 154 Exploration P: 0.0244 Total reward: -224.07862369633608 SOC: 0.6105 Cumulative_SOC_deviation: 17.8271 Fuel Consumption: 45.8078\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 146.742\n",
      "Episode: 155 Exploration P: 0.0240 Total reward: -258.8171127026243 SOC: 0.6090 Cumulative_SOC_deviation: 21.3065 Fuel Consumption: 45.7519\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 165.723\n",
      "Episode: 156 Exploration P: 0.0237 Total reward: -254.67964098550863 SOC: 0.6168 Cumulative_SOC_deviation: 20.8288 Fuel Consumption: 46.3915\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.168\n",
      "Episode: 157 Exploration P: 0.0233 Total reward: -251.64165436505579 SOC: 0.6116 Cumulative_SOC_deviation: 20.5756 Fuel Consumption: 45.8859\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.698\n",
      "Episode: 158 Exploration P: 0.0229 Total reward: -233.87876800937667 SOC: 0.6123 Cumulative_SOC_deviation: 18.7920 Fuel Consumption: 45.9587\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.583\n",
      "Episode: 159 Exploration P: 0.0226 Total reward: -215.4691134630698 SOC: 0.6130 Cumulative_SOC_deviation: 16.9539 Fuel Consumption: 45.9303\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.525\n",
      "Episode: 160 Exploration P: 0.0222 Total reward: -250.97030515530503 SOC: 0.6098 Cumulative_SOC_deviation: 20.5262 Fuel Consumption: 45.7084\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.532\n",
      "Episode: 161 Exploration P: 0.0219 Total reward: -261.8781408832912 SOC: 0.6094 Cumulative_SOC_deviation: 21.5928 Fuel Consumption: 45.9502\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.462\n",
      "Episode: 162 Exploration P: 0.0216 Total reward: -245.8186066046363 SOC: 0.6067 Cumulative_SOC_deviation: 20.0314 Fuel Consumption: 45.5044\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 131.068\n",
      "Episode: 163 Exploration P: 0.0213 Total reward: -218.04154357869035 SOC: 0.6102 Cumulative_SOC_deviation: 17.2346 Fuel Consumption: 45.6958\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 146.439\n",
      "Episode: 164 Exploration P: 0.0210 Total reward: -231.40016671916987 SOC: 0.6104 Cumulative_SOC_deviation: 18.5557 Fuel Consumption: 45.8430\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.440\n",
      "Episode: 165 Exploration P: 0.0207 Total reward: -246.532555521029 SOC: 0.6128 Cumulative_SOC_deviation: 20.0540 Fuel Consumption: 45.9926\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.828\n",
      "Episode: 166 Exploration P: 0.0204 Total reward: -280.81716127145006 SOC: 0.6169 Cumulative_SOC_deviation: 23.4330 Fuel Consumption: 46.4875\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 103.528\n",
      "Episode: 167 Exploration P: 0.0201 Total reward: -245.34419897153944 SOC: 0.6130 Cumulative_SOC_deviation: 19.9253 Fuel Consumption: 46.0910\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 103.235\n",
      "Episode: 168 Exploration P: 0.0198 Total reward: -270.8916694833171 SOC: 0.6150 Cumulative_SOC_deviation: 22.4638 Fuel Consumption: 46.2534\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.469\n",
      "Episode: 169 Exploration P: 0.0196 Total reward: -240.43299013122603 SOC: 0.6137 Cumulative_SOC_deviation: 19.4294 Fuel Consumption: 46.1385\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.550\n",
      "Episode: 170 Exploration P: 0.0193 Total reward: -276.50093255039127 SOC: 0.6178 Cumulative_SOC_deviation: 23.0029 Fuel Consumption: 46.4715\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.628\n",
      "Episode: 171 Exploration P: 0.0190 Total reward: -273.11134229422436 SOC: 0.6132 Cumulative_SOC_deviation: 22.6933 Fuel Consumption: 46.1783\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.610\n",
      "Episode: 172 Exploration P: 0.0188 Total reward: -249.47496143849986 SOC: 0.6120 Cumulative_SOC_deviation: 20.3499 Fuel Consumption: 45.9762\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.816\n",
      "Episode: 173 Exploration P: 0.0186 Total reward: -275.49512194969054 SOC: 0.6113 Cumulative_SOC_deviation: 22.9481 Fuel Consumption: 46.0143\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.665\n",
      "Episode: 174 Exploration P: 0.0183 Total reward: -257.7203043740021 SOC: 0.6172 Cumulative_SOC_deviation: 21.1329 Fuel Consumption: 46.3918\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.680\n",
      "Episode: 175 Exploration P: 0.0181 Total reward: -266.79117836407386 SOC: 0.6112 Cumulative_SOC_deviation: 22.0812 Fuel Consumption: 45.9788\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.986\n",
      "Episode: 176 Exploration P: 0.0179 Total reward: -264.21945755357814 SOC: 0.6168 Cumulative_SOC_deviation: 21.7826 Fuel Consumption: 46.3932\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.927\n",
      "Episode: 177 Exploration P: 0.0177 Total reward: -240.21410701899748 SOC: 0.6104 Cumulative_SOC_deviation: 19.4367 Fuel Consumption: 45.8469\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.969\n",
      "Episode: 178 Exploration P: 0.0175 Total reward: -242.05801040617092 SOC: 0.6061 Cumulative_SOC_deviation: 19.6456 Fuel Consumption: 45.6016\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.932\n",
      "Episode: 179 Exploration P: 0.0173 Total reward: -260.3070323766052 SOC: 0.6146 Cumulative_SOC_deviation: 21.4161 Fuel Consumption: 46.1459\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.801\n",
      "Episode: 180 Exploration P: 0.0171 Total reward: -255.14735469569086 SOC: 0.6121 Cumulative_SOC_deviation: 20.9098 Fuel Consumption: 46.0497\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.887\n",
      "Episode: 181 Exploration P: 0.0169 Total reward: -281.062707598865 SOC: 0.6159 Cumulative_SOC_deviation: 23.4692 Fuel Consumption: 46.3704\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.724\n",
      "Episode: 182 Exploration P: 0.0167 Total reward: -250.18694002886141 SOC: 0.6124 Cumulative_SOC_deviation: 20.4190 Fuel Consumption: 45.9968\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.647\n",
      "Episode: 183 Exploration P: 0.0165 Total reward: -237.07060616269078 SOC: 0.6154 Cumulative_SOC_deviation: 19.0808 Fuel Consumption: 46.2621\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.612\n",
      "Episode: 184 Exploration P: 0.0163 Total reward: -285.7922265954361 SOC: 0.6120 Cumulative_SOC_deviation: 23.9781 Fuel Consumption: 46.0109\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.694\n",
      "Episode: 185 Exploration P: 0.0162 Total reward: -272.0706024900417 SOC: 0.6217 Cumulative_SOC_deviation: 22.5251 Fuel Consumption: 46.8196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.675\n",
      "Episode: 186 Exploration P: 0.0160 Total reward: -274.96437826337785 SOC: 0.6203 Cumulative_SOC_deviation: 22.8303 Fuel Consumption: 46.6609\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.716\n",
      "Episode: 187 Exploration P: 0.0158 Total reward: -256.48454418562113 SOC: 0.6087 Cumulative_SOC_deviation: 21.0702 Fuel Consumption: 45.7828\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.851\n",
      "Episode: 188 Exploration P: 0.0157 Total reward: -260.04304399126954 SOC: 0.6121 Cumulative_SOC_deviation: 21.4005 Fuel Consumption: 46.0378\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.395\n",
      "Episode: 189 Exploration P: 0.0155 Total reward: -270.71795683536084 SOC: 0.6200 Cumulative_SOC_deviation: 22.4052 Fuel Consumption: 46.6663\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.077\n",
      "Episode: 190 Exploration P: 0.0154 Total reward: -271.39302476992066 SOC: 0.6182 Cumulative_SOC_deviation: 22.4954 Fuel Consumption: 46.4386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.850\n",
      "Episode: 191 Exploration P: 0.0152 Total reward: -274.23324741788076 SOC: 0.6163 Cumulative_SOC_deviation: 22.7889 Fuel Consumption: 46.3440\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.645\n",
      "Episode: 192 Exploration P: 0.0151 Total reward: -272.57726259271897 SOC: 0.6162 Cumulative_SOC_deviation: 22.6280 Fuel Consumption: 46.2974\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.393\n",
      "Episode: 193 Exploration P: 0.0149 Total reward: -255.88724524653202 SOC: 0.6048 Cumulative_SOC_deviation: 21.0488 Fuel Consumption: 45.3993\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.051\n",
      "Episode: 194 Exploration P: 0.0148 Total reward: -262.5482261653755 SOC: 0.6156 Cumulative_SOC_deviation: 21.6306 Fuel Consumption: 46.2420\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.725\n",
      "Episode: 195 Exploration P: 0.0147 Total reward: -287.5743264748975 SOC: 0.6139 Cumulative_SOC_deviation: 24.1372 Fuel Consumption: 46.2021\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.798\n",
      "Episode: 196 Exploration P: 0.0146 Total reward: -253.70600379308684 SOC: 0.6161 Cumulative_SOC_deviation: 20.7431 Fuel Consumption: 46.2752\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.495\n",
      "Episode: 197 Exploration P: 0.0144 Total reward: -253.90777368174412 SOC: 0.6148 Cumulative_SOC_deviation: 20.7706 Fuel Consumption: 46.2020\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.906\n",
      "Episode: 198 Exploration P: 0.0143 Total reward: -246.96925726128043 SOC: 0.6161 Cumulative_SOC_deviation: 20.0730 Fuel Consumption: 46.2390\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.820\n",
      "Episode: 199 Exploration P: 0.0142 Total reward: -268.8291456071476 SOC: 0.6194 Cumulative_SOC_deviation: 22.2227 Fuel Consumption: 46.6022\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.713\n",
      "Episode: 200 Exploration P: 0.0141 Total reward: -253.78979325493628 SOC: 0.6129 Cumulative_SOC_deviation: 20.7710 Fuel Consumption: 46.0800\n",
      "model is saved..\n",
      "\n",
      "Trial 2\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 18.381\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -927.0785142242017 SOC: 0.7974 Cumulative_SOC_deviation: 86.6280 Fuel Consumption: 60.7985\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 18.075\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -904.5523952838132 SOC: 0.7841 Cumulative_SOC_deviation: 84.4785 Fuel Consumption: 59.7671\n",
      "WARNING:tensorflow:Layer dense_27 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_31 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_22 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_23 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_18 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.824\n",
      "Episode: 3 Exploration P: 0.9217 Total reward: -781.0493437413221 SOC: 0.7536 Cumulative_SOC_deviation: 72.3679 Fuel Consumption: 57.3705\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.581\n",
      "Episode: 4 Exploration P: 0.8970 Total reward: -736.4048077085098 SOC: 0.7078 Cumulative_SOC_deviation: 68.2764 Fuel Consumption: 53.6410\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 65.058\n",
      "Episode: 5 Exploration P: 0.8730 Total reward: -795.9259479056307 SOC: 0.7177 Cumulative_SOC_deviation: 74.1402 Fuel Consumption: 54.5237\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.534\n",
      "Episode: 6 Exploration P: 0.8496 Total reward: -841.94650775371 SOC: 0.6734 Cumulative_SOC_deviation: 79.0808 Fuel Consumption: 51.1386\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.619\n",
      "Episode: 7 Exploration P: 0.8269 Total reward: -812.2238089611142 SOC: 0.6822 Cumulative_SOC_deviation: 76.0352 Fuel Consumption: 51.8715\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.195\n",
      "Episode: 8 Exploration P: 0.8048 Total reward: -823.2045022951827 SOC: 0.6471 Cumulative_SOC_deviation: 77.4183 Fuel Consumption: 49.0213\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 56.881\n",
      "Episode: 9 Exploration P: 0.7832 Total reward: -970.8754099801613 SOC: 0.6331 Cumulative_SOC_deviation: 92.2677 Fuel Consumption: 48.1986\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.579\n",
      "Episode: 10 Exploration P: 0.7623 Total reward: -1155.4303258094685 SOC: 0.5875 Cumulative_SOC_deviation: 111.0913 Fuel Consumption: 44.5171\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.680\n",
      "Episode: 11 Exploration P: 0.7419 Total reward: -1057.3875721550999 SOC: 0.5997 Cumulative_SOC_deviation: 101.1714 Fuel Consumption: 45.6737\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.882\n",
      "Episode: 12 Exploration P: 0.7221 Total reward: -1021.3915832463397 SOC: 0.6100 Cumulative_SOC_deviation: 97.5143 Fuel Consumption: 46.2482\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.337\n",
      "Episode: 13 Exploration P: 0.7028 Total reward: -1215.7884466180815 SOC: 0.5793 Cumulative_SOC_deviation: 117.1803 Fuel Consumption: 43.9854\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.779\n",
      "Episode: 14 Exploration P: 0.6840 Total reward: -1286.3761289872014 SOC: 0.5641 Cumulative_SOC_deviation: 124.3530 Fuel Consumption: 42.8460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.497\n",
      "Episode: 15 Exploration P: 0.6658 Total reward: -1508.6381363405021 SOC: 0.5448 Cumulative_SOC_deviation: 146.7309 Fuel Consumption: 41.3289\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.497\n",
      "Episode: 16 Exploration P: 0.6480 Total reward: -1737.214748676926 SOC: 0.5061 Cumulative_SOC_deviation: 169.8934 Fuel Consumption: 38.2809\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.295\n",
      "Episode: 17 Exploration P: 0.6307 Total reward: -1777.3551487615557 SOC: 0.5038 Cumulative_SOC_deviation: 173.9065 Fuel Consumption: 38.2905\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.479\n",
      "Episode: 18 Exploration P: 0.6139 Total reward: -1730.0022011802205 SOC: 0.5038 Cumulative_SOC_deviation: 169.1764 Fuel Consumption: 38.2381\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.657\n",
      "Episode: 19 Exploration P: 0.5976 Total reward: -1897.3216008268423 SOC: 0.4854 Cumulative_SOC_deviation: 186.0389 Fuel Consumption: 36.9328\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.318\n",
      "Episode: 20 Exploration P: 0.5816 Total reward: -1688.5498752453202 SOC: 0.5045 Cumulative_SOC_deviation: 165.0184 Fuel Consumption: 38.3654\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.523\n",
      "Episode: 21 Exploration P: 0.5662 Total reward: -1935.3595050666975 SOC: 0.4664 Cumulative_SOC_deviation: 189.9893 Fuel Consumption: 35.4660\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.644\n",
      "Episode: 22 Exploration P: 0.5511 Total reward: -2033.4033871985118 SOC: 0.4549 Cumulative_SOC_deviation: 199.8684 Fuel Consumption: 34.7193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.502\n",
      "Episode: 23 Exploration P: 0.5364 Total reward: -1938.1842973833068 SOC: 0.4787 Cumulative_SOC_deviation: 190.1820 Fuel Consumption: 36.3647\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.720\n",
      "Episode: 24 Exploration P: 0.5222 Total reward: -2149.216211451323 SOC: 0.4409 Cumulative_SOC_deviation: 211.5498 Fuel Consumption: 33.7179\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.306\n",
      "Episode: 25 Exploration P: 0.5083 Total reward: -2549.175837716428 SOC: 0.3890 Cumulative_SOC_deviation: 251.9418 Fuel Consumption: 29.7583\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.057\n",
      "Episode: 26 Exploration P: 0.4948 Total reward: -2611.0973167747984 SOC: 0.3873 Cumulative_SOC_deviation: 258.1197 Fuel Consumption: 29.9005\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 56.944\n",
      "Episode: 27 Exploration P: 0.4817 Total reward: -2326.2831916999735 SOC: 0.4162 Cumulative_SOC_deviation: 229.4505 Fuel Consumption: 31.7782\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.782\n",
      "Episode: 28 Exploration P: 0.4689 Total reward: -2554.955066242404 SOC: 0.3845 Cumulative_SOC_deviation: 252.5307 Fuel Consumption: 29.6481\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.011\n",
      "Episode: 29 Exploration P: 0.4565 Total reward: -2693.3722667683023 SOC: 0.3606 Cumulative_SOC_deviation: 266.5502 Fuel Consumption: 27.8699\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.142\n",
      "Episode: 30 Exploration P: 0.4444 Total reward: -2684.783471571948 SOC: 0.3647 Cumulative_SOC_deviation: 265.6602 Fuel Consumption: 28.1813\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.102\n",
      "Episode: 31 Exploration P: 0.4326 Total reward: -2735.636298988352 SOC: 0.3462 Cumulative_SOC_deviation: 270.8845 Fuel Consumption: 26.7915\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.057\n",
      "Episode: 32 Exploration P: 0.4212 Total reward: -2606.8506638149443 SOC: 0.3878 Cumulative_SOC_deviation: 257.6845 Fuel Consumption: 30.0054\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.165\n",
      "Episode: 33 Exploration P: 0.4100 Total reward: -2752.4752114042003 SOC: 0.3406 Cumulative_SOC_deviation: 272.6058 Fuel Consumption: 26.4170\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.274\n",
      "Episode: 34 Exploration P: 0.3992 Total reward: -2939.0065926047637 SOC: 0.3388 Cumulative_SOC_deviation: 291.2592 Fuel Consumption: 26.4149\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.290\n",
      "Episode: 35 Exploration P: 0.3887 Total reward: -3262.2941948388675 SOC: 0.2956 Cumulative_SOC_deviation: 323.9009 Fuel Consumption: 23.2855\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.200\n",
      "Episode: 36 Exploration P: 0.3784 Total reward: -2926.3902373094384 SOC: 0.3306 Cumulative_SOC_deviation: 290.0649 Fuel Consumption: 25.7409\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.352\n",
      "Episode: 37 Exploration P: 0.3684 Total reward: -3171.4462449365747 SOC: 0.2980 Cumulative_SOC_deviation: 314.7976 Fuel Consumption: 23.4706\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.907\n",
      "Episode: 38 Exploration P: 0.3587 Total reward: -3122.9924845122446 SOC: 0.3085 Cumulative_SOC_deviation: 309.8707 Fuel Consumption: 24.2859\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.584\n",
      "Episode: 39 Exploration P: 0.3493 Total reward: -3043.998262169684 SOC: 0.3141 Cumulative_SOC_deviation: 301.9282 Fuel Consumption: 24.7159\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.422\n",
      "Episode: 40 Exploration P: 0.3401 Total reward: -3106.337841637956 SOC: 0.2956 Cumulative_SOC_deviation: 308.3088 Fuel Consumption: 23.2502\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 54.676\n",
      "Episode: 41 Exploration P: 0.3311 Total reward: -3564.353274945735 SOC: 0.2547 Cumulative_SOC_deviation: 354.3816 Fuel Consumption: 20.5370\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.763\n",
      "Episode: 42 Exploration P: 0.3224 Total reward: -3572.0414214325683 SOC: 0.2478 Cumulative_SOC_deviation: 355.1846 Fuel Consumption: 20.1957\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.845\n",
      "Episode: 43 Exploration P: 0.3140 Total reward: -3429.8007662499267 SOC: 0.2546 Cumulative_SOC_deviation: 340.9250 Fuel Consumption: 20.5509\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.968\n",
      "Episode: 44 Exploration P: 0.3057 Total reward: -3627.1727965154 SOC: 0.2280 Cumulative_SOC_deviation: 360.8507 Fuel Consumption: 18.6658\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.230\n",
      "Episode: 45 Exploration P: 0.2977 Total reward: -3600.6103070460017 SOC: 0.2315 Cumulative_SOC_deviation: 358.1702 Fuel Consumption: 18.9087\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.101\n",
      "Episode: 46 Exploration P: 0.2899 Total reward: -3648.2443182155275 SOC: 0.2180 Cumulative_SOC_deviation: 363.0419 Fuel Consumption: 17.8249\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.065\n",
      "Episode: 47 Exploration P: 0.2824 Total reward: -1719.7132397142077 SOC: 0.6711 Cumulative_SOC_deviation: 166.8137 Fuel Consumption: 51.5767\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.181\n",
      "Episode: 48 Exploration P: 0.2750 Total reward: -551.4766548331501 SOC: 0.6568 Cumulative_SOC_deviation: 50.2869 Fuel Consumption: 48.6078\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.246\n",
      "Episode: 49 Exploration P: 0.2678 Total reward: -470.1365364364388 SOC: 0.6527 Cumulative_SOC_deviation: 42.1492 Fuel Consumption: 48.6450\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.160\n",
      "Episode: 50 Exploration P: 0.2608 Total reward: -435.67389456498836 SOC: 0.6406 Cumulative_SOC_deviation: 38.8000 Fuel Consumption: 47.6735\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.001\n",
      "Episode: 51 Exploration P: 0.2540 Total reward: -437.90497342674564 SOC: 0.6432 Cumulative_SOC_deviation: 38.9997 Fuel Consumption: 47.9082\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.185\n",
      "Episode: 52 Exploration P: 0.2474 Total reward: -404.9630663042139 SOC: 0.6360 Cumulative_SOC_deviation: 35.7590 Fuel Consumption: 47.3726\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.030\n",
      "Episode: 53 Exploration P: 0.2410 Total reward: -400.39661800272785 SOC: 0.6354 Cumulative_SOC_deviation: 35.3054 Fuel Consumption: 47.3426\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 57.951\n",
      "Episode: 54 Exploration P: 0.2347 Total reward: -404.9440696870417 SOC: 0.6407 Cumulative_SOC_deviation: 35.7204 Fuel Consumption: 47.7403\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.547\n",
      "Episode: 55 Exploration P: 0.2286 Total reward: -395.7681239132627 SOC: 0.6339 Cumulative_SOC_deviation: 34.8565 Fuel Consumption: 47.2035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.466\n",
      "Episode: 56 Exploration P: 0.2227 Total reward: -403.20223935517436 SOC: 0.6330 Cumulative_SOC_deviation: 35.6040 Fuel Consumption: 47.1622\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 58.980\n",
      "Episode: 57 Exploration P: 0.2170 Total reward: -375.5482816300528 SOC: 0.6312 Cumulative_SOC_deviation: 32.8529 Fuel Consumption: 47.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.110\n",
      "Episode: 58 Exploration P: 0.2114 Total reward: -396.9463383042171 SOC: 0.6367 Cumulative_SOC_deviation: 34.9506 Fuel Consumption: 47.4400\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.662\n",
      "Episode: 59 Exploration P: 0.2059 Total reward: -397.7018625067235 SOC: 0.6368 Cumulative_SOC_deviation: 35.0183 Fuel Consumption: 47.5191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.351\n",
      "Episode: 60 Exploration P: 0.2006 Total reward: -373.76657903758115 SOC: 0.6315 Cumulative_SOC_deviation: 32.6780 Fuel Consumption: 46.9871\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.649\n",
      "Episode: 61 Exploration P: 0.1954 Total reward: -405.26490128869057 SOC: 0.6382 Cumulative_SOC_deviation: 35.7704 Fuel Consumption: 47.5605\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.932\n",
      "Episode: 62 Exploration P: 0.1904 Total reward: -393.28613362943975 SOC: 0.6341 Cumulative_SOC_deviation: 34.6030 Fuel Consumption: 47.2558\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.543\n",
      "Episode: 63 Exploration P: 0.1855 Total reward: -389.237044109552 SOC: 0.6302 Cumulative_SOC_deviation: 34.2278 Fuel Consumption: 46.9591\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.393\n",
      "Episode: 64 Exploration P: 0.1808 Total reward: -410.9157925118724 SOC: 0.6355 Cumulative_SOC_deviation: 36.3502 Fuel Consumption: 47.4139\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.959\n",
      "Episode: 65 Exploration P: 0.1761 Total reward: -426.79320238556664 SOC: 0.6396 Cumulative_SOC_deviation: 37.9074 Fuel Consumption: 47.7189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.634\n",
      "Episode: 66 Exploration P: 0.1716 Total reward: -402.8528014461702 SOC: 0.6367 Cumulative_SOC_deviation: 35.5369 Fuel Consumption: 47.4838\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.754\n",
      "Episode: 67 Exploration P: 0.1673 Total reward: -410.7630600075731 SOC: 0.6445 Cumulative_SOC_deviation: 36.2677 Fuel Consumption: 48.0860\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.799\n",
      "Episode: 68 Exploration P: 0.1630 Total reward: -376.5827926574717 SOC: 0.6299 Cumulative_SOC_deviation: 32.9644 Fuel Consumption: 46.9386\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.582\n",
      "Episode: 69 Exploration P: 0.1589 Total reward: -361.56838507510713 SOC: 0.6354 Cumulative_SOC_deviation: 31.4293 Fuel Consumption: 47.2751\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.598\n",
      "Episode: 70 Exploration P: 0.1548 Total reward: -357.1174676056818 SOC: 0.6291 Cumulative_SOC_deviation: 31.0294 Fuel Consumption: 46.8230\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.896\n",
      "Episode: 71 Exploration P: 0.1509 Total reward: -390.73067345811955 SOC: 0.6290 Cumulative_SOC_deviation: 34.3870 Fuel Consumption: 46.8610\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.159\n",
      "Episode: 72 Exploration P: 0.1471 Total reward: -392.4641727408043 SOC: 0.6389 Cumulative_SOC_deviation: 34.4818 Fuel Consumption: 47.6464\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.783\n",
      "Episode: 73 Exploration P: 0.1434 Total reward: -356.10026615473936 SOC: 0.6294 Cumulative_SOC_deviation: 30.9350 Fuel Consumption: 46.7503\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.193\n",
      "Episode: 74 Exploration P: 0.1398 Total reward: -341.40028585000164 SOC: 0.6269 Cumulative_SOC_deviation: 29.4781 Fuel Consumption: 46.6195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.055\n",
      "Episode: 75 Exploration P: 0.1362 Total reward: -381.976509333639 SOC: 0.6285 Cumulative_SOC_deviation: 33.5322 Fuel Consumption: 46.6547\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 64.249\n",
      "Episode: 76 Exploration P: 0.1328 Total reward: -361.4631907506872 SOC: 0.6277 Cumulative_SOC_deviation: 31.4733 Fuel Consumption: 46.7306\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.370\n",
      "Episode: 77 Exploration P: 0.1295 Total reward: -366.8791945579997 SOC: 0.6270 Cumulative_SOC_deviation: 32.0312 Fuel Consumption: 46.5668\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.123\n",
      "Episode: 78 Exploration P: 0.1263 Total reward: -374.565417196019 SOC: 0.6343 Cumulative_SOC_deviation: 32.7401 Fuel Consumption: 47.1640\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.227\n",
      "Episode: 79 Exploration P: 0.1231 Total reward: -337.6927355123648 SOC: 0.6330 Cumulative_SOC_deviation: 29.0726 Fuel Consumption: 46.9669\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.510\n",
      "Episode: 80 Exploration P: 0.1200 Total reward: -362.67884292573075 SOC: 0.6312 Cumulative_SOC_deviation: 31.5791 Fuel Consumption: 46.8880\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.431\n",
      "Episode: 81 Exploration P: 0.1171 Total reward: -377.2736984068905 SOC: 0.6361 Cumulative_SOC_deviation: 33.0021 Fuel Consumption: 47.2525\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.109\n",
      "Episode: 82 Exploration P: 0.1142 Total reward: -362.73221975527287 SOC: 0.6305 Cumulative_SOC_deviation: 31.5953 Fuel Consumption: 46.7791\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.873\n",
      "Episode: 83 Exploration P: 0.1113 Total reward: -377.4671938840026 SOC: 0.6331 Cumulative_SOC_deviation: 33.0433 Fuel Consumption: 47.0345\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.580\n",
      "Episode: 84 Exploration P: 0.1086 Total reward: -363.74615389875885 SOC: 0.6309 Cumulative_SOC_deviation: 31.6998 Fuel Consumption: 46.7486\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.363\n",
      "Episode: 85 Exploration P: 0.1059 Total reward: -373.4923557500684 SOC: 0.6328 Cumulative_SOC_deviation: 32.6616 Fuel Consumption: 46.8763\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.283\n",
      "Episode: 86 Exploration P: 0.1033 Total reward: -394.0202021217112 SOC: 0.6352 Cumulative_SOC_deviation: 34.6831 Fuel Consumption: 47.1895\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.730\n",
      "Episode: 87 Exploration P: 0.1008 Total reward: -386.8848703667968 SOC: 0.6350 Cumulative_SOC_deviation: 33.9730 Fuel Consumption: 47.1553\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.171\n",
      "Episode: 88 Exploration P: 0.0983 Total reward: -416.46778983474326 SOC: 0.6390 Cumulative_SOC_deviation: 36.8919 Fuel Consumption: 47.5487\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 60.201\n",
      "Episode: 89 Exploration P: 0.0960 Total reward: -398.7210163310373 SOC: 0.6405 Cumulative_SOC_deviation: 35.1037 Fuel Consumption: 47.6844\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.471\n",
      "Episode: 90 Exploration P: 0.0936 Total reward: -384.40257003302503 SOC: 0.6413 Cumulative_SOC_deviation: 33.6751 Fuel Consumption: 47.6517\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.077\n",
      "Episode: 91 Exploration P: 0.0914 Total reward: -407.010742331998 SOC: 0.6391 Cumulative_SOC_deviation: 35.9582 Fuel Consumption: 47.4284\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.716\n",
      "Episode: 92 Exploration P: 0.0892 Total reward: -387.3761640899299 SOC: 0.6309 Cumulative_SOC_deviation: 34.0593 Fuel Consumption: 46.7834\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.742\n",
      "Episode: 93 Exploration P: 0.0870 Total reward: -409.1296551312244 SOC: 0.6340 Cumulative_SOC_deviation: 36.2157 Fuel Consumption: 46.9727\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.158\n",
      "Episode: 94 Exploration P: 0.0849 Total reward: -402.58450911682144 SOC: 0.6388 Cumulative_SOC_deviation: 35.5276 Fuel Consumption: 47.3086\n"
     ]
    }
   ],
   "source": [
    "print(env.version)\n",
    "\n",
    "num_trials = 5\n",
    "reward_factor = 10\n",
    "results_dict = {} \n",
    "for trial in range(num_trials): \n",
    "    print()\n",
    "    print(\"Trial {}\".format(trial + 1))\n",
    "    \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer, env = initialization(\n",
    "        reward_factor\n",
    "    )\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    for ep in range(total_episodes): \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * steps)\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_SOCs.append(env.SOC)\n",
    "        episode_FCs.append(env.fuel_consumption) \n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        print(\n",
    "              'Episode: {}'.format(ep + 1),\n",
    "              \"Exploration P: {:.4f}\".format(eps),\n",
    "              'Total reward: {}'.format(episodic_reward), \n",
    "              \"SOC: {:.4f}\".format(env.SOC), \n",
    "              \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "              \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "        )\n",
    "    \n",
    "    root = \"DDPG2_trial{}\".format(trial+1)\n",
    "    save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "    \n",
    "    results_dict[trial + 1] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs, \n",
    "        \"mean\": buffer.power_mean, \n",
    "        \"std\": buffer.power_std, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDPG2.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
