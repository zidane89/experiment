{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-30627.831470329067\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "\n",
    "from vehicle_model_original import Environment \n",
    "from cell_model import CellModel \n",
    "from driver_MDP import Driver_MDP \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_nimh_6_240_panasonic_MY01_Prius.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_pm_95_145_X2.mat\"\n",
    "cell_model = CellModel()\n",
    "# env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "driver = Driver_MDP(0.02)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):      \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    inputs_batchnorm = layers.BatchNormalization()(inputs)\n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs_batchnorm)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_input_batchnorm = layers.BatchNormalization()(state_input)\n",
    "    \n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input_batchnorm)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 300 \n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1.0 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "#     actor_model.load_weights(\"./DDPG1_trial1/actor_model_checkpoint\")\n",
    "#     critic_model.load_weights(\"./DDPG1_trial1/critic_model_checkpoint\")\n",
    "#     target_actor.load_weights(\"./DDPG1_trial1/target_actor_checkpoint\")\n",
    "#     target_critic.load_weights(\"./DDPG1_trial1/target_critic_checkpoint\")\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_model, critic_model, target_actor, target_critic, root): \n",
    "    actor_model.save_weights(\"./{}/actor_model.h5\".format(root))\n",
    "    critic_model.save_weights(\"./{}/critic_model.h5\".format(root))\n",
    "    target_actor.save_weights(\"./{}/target_actor.h5\".format(root))\n",
    "    target_critic.save_weights(\"./{}/target_critic.h5\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_env(driving_path, reward_factor):\n",
    "    env = Environment(cell_model, driving_path, battery_path, motor_path, reward_factor)\n",
    "    return env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(actor_model, reward_factor):\n",
    "    test_cycle = driver.get_cycle() \n",
    "    env = initialization_env(test_cycle, reward_factor)\n",
    "    \n",
    "    total_reward = 0\n",
    "    state = env.reset() \n",
    "    while True: \n",
    "        tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "        action = policy_epsilon_greedy(tf_state, -1)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        \n",
    "        state = next_state \n",
    "        total_reward += reward \n",
    "        \n",
    "        if done: \n",
    "            break \n",
    "        \n",
    "    SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "    \n",
    "    print(\"******************* Test is start *****************\")\n",
    "#     print(test_cycle)\n",
    "    print('Total reward: {}'.format(total_reward), \n",
    "          \"SOC: {:.4f}\".format(env.SOC), \n",
    "          \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "          \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption))\n",
    "    print(\"******************* Test is done *****************\")\n",
    "    print(\"\")\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(test_cycle)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(env.history[\"Action\"])\n",
    "    plt.show() \n",
    "    return env.history  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment\\generalization_MDP_environment\\vehicle_model_original.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n",
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment\\generalization_MDP_environment\\vehicle_model_original.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  2 * r_dis)) * (v_dis - (v_dis ** 2 - 4 * r_dis * p_bat) ** (0.5)) * (p_bat >= 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 9.122\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -3602.991568269222 SOC: 1.0000 Cumulative_SOC_deviation: 351.7392 Fuel Consumption: 85.5994\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 8.315\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -3567.6120973071306 SOC: 1.0000 Cumulative_SOC_deviation: 348.7288 Fuel Consumption: 80.3243\n",
      "\n",
      "Available condition is not avail... SOC: 0.9860685660911964, P_stack_set: [1.22897588e+00 1.19869422e+04 2.34705471e+04 3.45955527e+04\n",
      " 4.53876540e+04 5.58509191e+04 6.59782805e+04 7.57551171e+04\n",
      " 8.51610619e+04 9.41711648e+04], P_battery_set: [ -27426.05715767  -39411.77041227  -50895.37529626  -62020.38085282\n",
      "  -72812.48214829  -83275.7472714   -93403.10867551 -103179.94530536\n",
      " -112585.89005609 -121595.99295356]\n",
      "elapsed_time: 5.505\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -3236.4683432785796 SOC: 0.9861 Cumulative_SOC_deviation: 217.6105 Fuel Consumption: 64.5856\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 8.422\n",
      "Episode: 4 Exploration P: 1.0000 Total reward: -3568.2721159121966 SOC: 1.0000 Cumulative_SOC_deviation: 348.7716 Fuel Consumption: 80.5564\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 8.395\n",
      "Episode: 5 Exploration P: 1.0000 Total reward: -3562.9687632020728 SOC: 1.0000 Cumulative_SOC_deviation: 348.2025 Fuel Consumption: 80.9434\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Available condition is not avail... SOC: 1, P_stack_set: [1.22897588e+00 1.19869422e+04 2.34705471e+04 3.45955527e+04\n",
      " 4.53876540e+04 5.58509191e+04 6.59782805e+04 7.57551171e+04\n",
      " 8.51610619e+04 9.41711648e+04], P_battery_set: [ -22526.54980127  -34512.26305587  -45995.86793986  -57120.87349642\n",
      "  -67912.97479189  -78376.239915    -88503.60131911  -98280.43794896\n",
      " -107686.38269969 -116696.48559716]\n",
      "elapsed_time: 27.874\n",
      "Episode: 6 Exploration P: 0.9911 Total reward: -3673.861759127122 SOC: 1.0000 Cumulative_SOC_deviation: 260.9573 Fuel Consumption: 68.3143\n",
      "\n",
      "Available condition is not avail... SOC: 0.9981284798793564, P_stack_set: [1.22897588e+00 1.19869422e+04 2.34705471e+04 3.45955527e+04\n",
      " 4.53876540e+04 5.58509191e+04 6.59782805e+04 7.57551171e+04\n",
      " 8.51610619e+04 9.41711648e+04], P_battery_set: [ -22783.95841447  -34769.67166908  -46253.27655306  -57378.28210963\n",
      "  -68170.38340509  -78633.64852821  -88761.00993232  -98537.84656217\n",
      " -107943.79131289 -116953.89421037]\n",
      "elapsed_time: 32.420\n",
      "Episode: 7 Exploration P: 0.9794 Total reward: -2975.323558283685 SOC: 0.9981 Cumulative_SOC_deviation: 192.0962 Fuel Consumption: 58.6522\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 53.199\n",
      "Episode: 8 Exploration P: 0.9602 Total reward: -3556.2778989974295 SOC: 1.0000 Cumulative_SOC_deviation: 347.1736 Fuel Consumption: 84.5418\n",
      "\n",
      "Available condition is not avail... SOC: 0.9755994375810548, P_stack_set: [1.22897588e+00 1.19869422e+04 2.34705471e+04 3.45955527e+04\n",
      " 4.53876540e+04 5.58509191e+04 6.59782805e+04 7.57551171e+04\n",
      " 8.51610619e+04 9.41711648e+04], P_battery_set: [ -24934.41199587  -36920.12525047  -48403.73013446  -59528.73569102\n",
      "  -70320.83698649  -80784.1021096   -90911.46351371 -100688.30014356\n",
      " -110094.24489429 -119104.34779176]\n",
      "elapsed_time: 33.850\n",
      "Episode: 9 Exploration P: 0.9488 Total reward: -2878.904979826557 SOC: 0.9756 Cumulative_SOC_deviation: 182.4202 Fuel Consumption: 58.6649\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 59.590\n",
      "Episode: 10 Exploration P: 0.9302 Total reward: -3505.823947139087 SOC: 1.0000 Cumulative_SOC_deviation: 343.1794 Fuel Consumption: 74.0302\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "******************* Test is start *****************\n",
      "Total reward: -892.0066845360583 SOC: 0.3862 Cumulative_SOC_deviation: 89.0125 Fuel Consumption: 1.8815\n",
      "******************* Test is done *****************\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 53.811\n",
      "Episode: 11 Exploration P: 0.9120 Total reward: -3535.8640491104616 SOC: 1.0000 Cumulative_SOC_deviation: 346.3743 Fuel Consumption: 72.1213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ValueCreatorSong\\Desktop\\Academic\\graduate_paper\\degradation_model\\experiment\\generalization_MDP_environment\\vehicle_model_original.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available condition is not avail... SOC: 0.9070751709763124, P_stack_set: [1.22897588e+00 1.19869422e+04 2.34705471e+04 3.45955527e+04\n",
      " 4.53876540e+04 5.58509191e+04 6.59782805e+04 7.57551171e+04\n",
      " 8.51610619e+04 9.41711648e+04], P_battery_set: [ -34934.04206822  -46919.75532283  -58403.36020681  -69528.36576338\n",
      "  -80320.46705885  -90783.73218196 -100911.09358607 -110687.93021592\n",
      " -120093.87496664 -129103.97786412]\n",
      "elapsed_time: 12.344\n",
      "Episode: 12 Exploration P: 0.9079 Total reward: -1395.0357588886186 SOC: 0.9071 Cumulative_SOC_deviation: 36.8749 Fuel Consumption: 29.3962\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 61.326\n",
      "Episode: 13 Exploration P: 0.8901 Total reward: -3469.2178582795495 SOC: 0.9949 Cumulative_SOC_deviation: 339.6207 Fuel Consumption: 73.0113\n",
      "\n",
      "Available condition is not avail... SOC: 0.999345764007702, P_stack_set: [1.22897588e+00 1.19869422e+04 2.34705471e+04 3.45955527e+04\n",
      " 4.53876540e+04 5.58509191e+04 6.59782805e+04 7.57551171e+04\n",
      " 8.51610619e+04 9.41711648e+04], P_battery_set: [ -23590.73778976  -35576.45104436  -47060.05592835  -58185.06148491\n",
      "  -68977.16278038  -79440.42790349  -89567.7893076   -99344.62593745\n",
      " -108750.57068817 -117760.67358565]\n",
      "elapsed_time: 28.507\n",
      "Episode: 14 Exploration P: 0.8819 Total reward: -2284.1909366948953 SOC: 0.9993 Cumulative_SOC_deviation: 124.7165 Fuel Consumption: 41.1743\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-0751f86c6c23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mDELAY_TRAINING\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[0mupdate_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                 eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
      "\u001b[1;32m<ipython-input-4-4679c004126e>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactor_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mcritic_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcritic_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mactor_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcritic_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mactor_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactor_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactor_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.1_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6110\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6111\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6112\u001b[1;33m         transpose_a, \"transpose_b\", transpose_b)\n\u001b[0m\u001b[0;32m   6113\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6114\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print(env.version)\n",
    "\n",
    "num_trials = 1\n",
    "results_dict = {} \n",
    "# driving_cycle_paths = glob.glob(\"../data/driving_cycles/city/*.mat\")[:1]\n",
    "\n",
    "for trial in range(num_trials): \n",
    "    print(\"\")\n",
    "    print(\"Trial {}\".format(trial))\n",
    "    print(\"\")\n",
    "    \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer = initialization()\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    episode_test_history = [] \n",
    "    episode_num_test = [] \n",
    "    for ep in range(total_episodes): \n",
    "        \n",
    "        driving_cycle = driver.get_cycle() \n",
    "        env = initialization_env(driving_cycle, 10)\n",
    "        \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
    "                                                                        -DELAY_TRAINING))\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_SOCs.append(env.SOC)\n",
    "        episode_FCs.append(env.fuel_consumption) \n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        print(\n",
    "              'Episode: {}'.format(ep + 1),\n",
    "              \"Exploration P: {:.4f}\".format(eps),\n",
    "              'Total reward: {}'.format(episodic_reward), \n",
    "              \"SOC: {:.4f}\".format(env.SOC), \n",
    "              \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "              \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "        )\n",
    "        print(\"\")\n",
    "        \n",
    "        if (ep + 1) % 10 == 0: \n",
    "            history = test_agent(actor_model, 10)\n",
    "            episode_test_history.append(history) \n",
    "            episode_num_test.append(ep + 1)\n",
    "            \n",
    "    root = \"DDPG_original_trained\"\n",
    "    save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "    \n",
    "    results_dict[trial + 1] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs, \n",
    "        \"test_history\": episode_test_history, \n",
    "        \"test_episode_num\": episode_num_test, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDPG_original.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
