{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "\n",
    "from vehicle_model_DDPG1 import Environment \n",
    "from cell_model import CellModel \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_nimh_6_240_panasonic_MY01_Prius.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_pm_95_145_X2.mat\"\n",
    "cell_model = CellModel()\n",
    "env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):      \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    \n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 200\n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 3000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(reward_factor): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "\n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    env = Environment(cell_model, drving_cycle, battery_path, motor_path, reward_factor)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer, env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_model, critic_model, target_actor, target_critic, root): \n",
    "    actor_model.save_weights(\"./{}/actor_model_checkpoint\".format(root))\n",
    "    critic_model.save_weights(\"./{}/critic_model_checkpoint\".format(root))\n",
    "    target_actor.save_weights(\"./{}/target_actor_checkpoint\".format(root))\n",
    "    target_critic.save_weights(\"./{}/target_critic_checkpoint\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "Trial 0\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 31.199\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -5120.667015600076 SOC: 1.0000 Cumulative_SOC_deviation: 496.5048 Fuel Consumption: 155.6193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 30.611\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -5114.857023349722 SOC: 1.0000 Cumulative_SOC_deviation: 496.1869 Fuel Consumption: 152.9882\n",
      "WARNING:tensorflow:Layer dense_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.526\n",
      "Episode: 3 Exploration P: 0.9217 Total reward: -5061.981499272178 SOC: 1.0000 Cumulative_SOC_deviation: 491.5518 Fuel Consumption: 146.4636\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.403\n",
      "Episode: 4 Exploration P: 0.8970 Total reward: -5086.199102697233 SOC: 1.0000 Cumulative_SOC_deviation: 494.5716 Fuel Consumption: 140.4826\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.304\n",
      "Episode: 5 Exploration P: 0.8730 Total reward: -5038.453137631626 SOC: 1.0000 Cumulative_SOC_deviation: 489.8332 Fuel Consumption: 140.1215\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.009\n",
      "Episode: 6 Exploration P: 0.8496 Total reward: -4872.5829005674605 SOC: 1.0000 Cumulative_SOC_deviation: 474.3636 Fuel Consumption: 128.9469\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.041\n",
      "Episode: 7 Exploration P: 0.8269 Total reward: -4952.209763210422 SOC: 1.0000 Cumulative_SOC_deviation: 481.7970 Fuel Consumption: 134.2401\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.073\n",
      "Episode: 8 Exploration P: 0.8048 Total reward: -4811.191619974567 SOC: 1.0000 Cumulative_SOC_deviation: 468.3792 Fuel Consumption: 127.3992\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.729\n",
      "Episode: 9 Exploration P: 0.7832 Total reward: -4857.473424758514 SOC: 1.0000 Cumulative_SOC_deviation: 473.0528 Fuel Consumption: 126.9452\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.338\n",
      "Episode: 10 Exploration P: 0.7623 Total reward: -4626.001574008722 SOC: 1.0000 Cumulative_SOC_deviation: 450.0470 Fuel Consumption: 125.5316\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.793\n",
      "Episode: 11 Exploration P: 0.7419 Total reward: -4842.288495601431 SOC: 1.0000 Cumulative_SOC_deviation: 472.3206 Fuel Consumption: 119.0828\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.493\n",
      "Episode: 12 Exploration P: 0.7221 Total reward: -4753.2492706670755 SOC: 1.0000 Cumulative_SOC_deviation: 463.0617 Fuel Consumption: 122.6322\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.515\n",
      "Episode: 13 Exploration P: 0.7028 Total reward: -4447.148438670922 SOC: 1.0000 Cumulative_SOC_deviation: 433.2172 Fuel Consumption: 114.9762\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.969\n",
      "Episode: 14 Exploration P: 0.6840 Total reward: -4528.712084862978 SOC: 1.0000 Cumulative_SOC_deviation: 441.4458 Fuel Consumption: 114.2539\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.838\n",
      "Episode: 15 Exploration P: 0.6658 Total reward: -4500.242806649995 SOC: 1.0000 Cumulative_SOC_deviation: 438.6154 Fuel Consumption: 114.0888\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.099\n",
      "Episode: 16 Exploration P: 0.6480 Total reward: -4534.520317343722 SOC: 1.0000 Cumulative_SOC_deviation: 442.1680 Fuel Consumption: 112.8403\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.498\n",
      "Episode: 17 Exploration P: 0.6307 Total reward: -4374.001336687097 SOC: 1.0000 Cumulative_SOC_deviation: 426.7692 Fuel Consumption: 106.3089\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.677\n",
      "Episode: 18 Exploration P: 0.6139 Total reward: -4276.500246034126 SOC: 1.0000 Cumulative_SOC_deviation: 417.0810 Fuel Consumption: 105.6899\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.479\n",
      "Episode: 19 Exploration P: 0.5976 Total reward: -4409.1607835660725 SOC: 1.0000 Cumulative_SOC_deviation: 430.5896 Fuel Consumption: 103.2651\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.942\n",
      "Episode: 20 Exploration P: 0.5816 Total reward: -4615.097001776045 SOC: 1.0000 Cumulative_SOC_deviation: 443.7387 Fuel Consumption: 177.7103\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.212\n",
      "Episode: 21 Exploration P: 0.5662 Total reward: -5362.552795878669 SOC: 1.0000 Cumulative_SOC_deviation: 515.7716 Fuel Consumption: 204.8367\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.003\n",
      "Episode: 22 Exploration P: 0.5511 Total reward: -5362.07291289214 SOC: 1.0000 Cumulative_SOC_deviation: 515.1902 Fuel Consumption: 210.1713\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.065\n",
      "Episode: 23 Exploration P: 0.5364 Total reward: -5374.534442583845 SOC: 1.0000 Cumulative_SOC_deviation: 516.4208 Fuel Consumption: 210.3261\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.000\n",
      "Episode: 24 Exploration P: 0.5222 Total reward: -5363.476913134856 SOC: 1.0000 Cumulative_SOC_deviation: 515.2841 Fuel Consumption: 210.6356\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.520\n",
      "Episode: 25 Exploration P: 0.5083 Total reward: -5356.179473529848 SOC: 1.0000 Cumulative_SOC_deviation: 514.7102 Fuel Consumption: 209.0776\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.458\n",
      "Episode: 26 Exploration P: 0.4948 Total reward: -5395.771629915968 SOC: 1.0000 Cumulative_SOC_deviation: 518.2711 Fuel Consumption: 213.0604\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.811\n",
      "Episode: 27 Exploration P: 0.4817 Total reward: -5274.593558152616 SOC: 1.0000 Cumulative_SOC_deviation: 514.1839 Fuel Consumption: 132.7546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.219\n",
      "Episode: 28 Exploration P: 0.4689 Total reward: -3707.3019071637527 SOC: 1.0000 Cumulative_SOC_deviation: 361.3714 Fuel Consumption: 93.5876\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.617\n",
      "Episode: 29 Exploration P: 0.4565 Total reward: -3391.5038066849274 SOC: 1.0000 Cumulative_SOC_deviation: 329.8330 Fuel Consumption: 93.1740\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.211\n",
      "Episode: 30 Exploration P: 0.4444 Total reward: -2729.620120756504 SOC: 1.0000 Cumulative_SOC_deviation: 264.3442 Fuel Consumption: 86.1783\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.081\n",
      "Episode: 31 Exploration P: 0.4326 Total reward: -2454.6320476280184 SOC: 1.0000 Cumulative_SOC_deviation: 236.9527 Fuel Consumption: 85.1052\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.281\n",
      "Episode: 32 Exploration P: 0.4212 Total reward: -1962.9324940443319 SOC: 0.9825 Cumulative_SOC_deviation: 188.0541 Fuel Consumption: 82.3915\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.708\n",
      "Episode: 33 Exploration P: 0.4100 Total reward: -2455.731805530217 SOC: 1.0000 Cumulative_SOC_deviation: 237.0008 Fuel Consumption: 85.7243\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.529\n",
      "Episode: 34 Exploration P: 0.3992 Total reward: -2252.2099992862672 SOC: 0.9945 Cumulative_SOC_deviation: 216.8911 Fuel Consumption: 83.2995\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.617\n",
      "Episode: 35 Exploration P: 0.3887 Total reward: -2589.530491546237 SOC: 0.9991 Cumulative_SOC_deviation: 250.6066 Fuel Consumption: 83.4646\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.182\n",
      "Episode: 36 Exploration P: 0.3784 Total reward: -1925.3460217962538 SOC: 0.9449 Cumulative_SOC_deviation: 184.6040 Fuel Consumption: 79.3064\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.703\n",
      "Episode: 37 Exploration P: 0.3684 Total reward: -1550.6181949434065 SOC: 0.8980 Cumulative_SOC_deviation: 147.4242 Fuel Consumption: 76.3760\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.418\n",
      "Episode: 38 Exploration P: 0.3587 Total reward: -1320.6785843480452 SOC: 0.9155 Cumulative_SOC_deviation: 124.2817 Fuel Consumption: 77.8618\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.171\n",
      "Episode: 39 Exploration P: 0.3493 Total reward: -1718.8443904559165 SOC: 0.9448 Cumulative_SOC_deviation: 163.8475 Fuel Consumption: 80.3691\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.229\n",
      "Episode: 40 Exploration P: 0.3401 Total reward: -1341.1066262965908 SOC: 0.9038 Cumulative_SOC_deviation: 126.4204 Fuel Consumption: 76.9022\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.536\n",
      "Episode: 41 Exploration P: 0.3311 Total reward: -1298.953647250584 SOC: 0.8828 Cumulative_SOC_deviation: 122.3537 Fuel Consumption: 75.4164\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.498\n",
      "Episode: 42 Exploration P: 0.3224 Total reward: -1544.488178287005 SOC: 0.8834 Cumulative_SOC_deviation: 146.9288 Fuel Consumption: 75.1998\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.983\n",
      "Episode: 43 Exploration P: 0.3140 Total reward: -1054.631908083173 SOC: 0.8208 Cumulative_SOC_deviation: 98.3828 Fuel Consumption: 70.8042\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.888\n",
      "Episode: 44 Exploration P: 0.3057 Total reward: -1099.4442528955442 SOC: 0.8541 Cumulative_SOC_deviation: 102.6153 Fuel Consumption: 73.2909\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.962\n",
      "Episode: 45 Exploration P: 0.2977 Total reward: -1087.4615813927178 SOC: 0.7365 Cumulative_SOC_deviation: 102.2673 Fuel Consumption: 64.7887\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.750\n",
      "Episode: 46 Exploration P: 0.2899 Total reward: -1018.100250774517 SOC: 0.8168 Cumulative_SOC_deviation: 94.6966 Fuel Consumption: 71.1344\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.301\n",
      "Episode: 47 Exploration P: 0.2824 Total reward: -914.3966227808721 SOC: 0.6629 Cumulative_SOC_deviation: 85.5128 Fuel Consumption: 59.2685\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.084\n",
      "Episode: 48 Exploration P: 0.2750 Total reward: -833.3772440289964 SOC: 0.6898 Cumulative_SOC_deviation: 77.2241 Fuel Consumption: 61.1361\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.850\n",
      "Episode: 49 Exploration P: 0.2678 Total reward: -1016.5879958567102 SOC: 0.7306 Cumulative_SOC_deviation: 95.1861 Fuel Consumption: 64.7268\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.001\n",
      "Episode: 50 Exploration P: 0.2608 Total reward: -1085.7804499702988 SOC: 0.6887 Cumulative_SOC_deviation: 102.4201 Fuel Consumption: 61.5798\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.123\n",
      "Episode: 51 Exploration P: 0.2540 Total reward: -1323.768172406627 SOC: 0.6312 Cumulative_SOC_deviation: 126.6501 Fuel Consumption: 57.2668\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.274\n",
      "Episode: 52 Exploration P: 0.2474 Total reward: -887.573585252775 SOC: 0.6441 Cumulative_SOC_deviation: 82.9502 Fuel Consumption: 58.0716\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.500\n",
      "Episode: 53 Exploration P: 0.2410 Total reward: -1159.4548412081922 SOC: 0.6160 Cumulative_SOC_deviation: 110.3467 Fuel Consumption: 55.9874\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.958\n",
      "Episode: 54 Exploration P: 0.2347 Total reward: -818.8638000589892 SOC: 0.6853 Cumulative_SOC_deviation: 75.7821 Fuel Consumption: 61.0433\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.486\n",
      "Episode: 55 Exploration P: 0.2286 Total reward: -2184.1547169555506 SOC: 0.4490 Cumulative_SOC_deviation: 214.0817 Fuel Consumption: 43.3373\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.718\n",
      "Episode: 56 Exploration P: 0.2227 Total reward: -1566.1668023565878 SOC: 0.5652 Cumulative_SOC_deviation: 151.3667 Fuel Consumption: 52.4998\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.060\n",
      "Episode: 57 Exploration P: 0.2170 Total reward: -2081.4004195277766 SOC: 0.4766 Cumulative_SOC_deviation: 203.5762 Fuel Consumption: 45.6383\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.456\n",
      "Episode: 58 Exploration P: 0.2114 Total reward: -2092.1197465874047 SOC: 0.4883 Cumulative_SOC_deviation: 204.5656 Fuel Consumption: 46.4637\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.327\n",
      "Episode: 59 Exploration P: 0.2059 Total reward: -2178.129096299016 SOC: 0.4473 Cumulative_SOC_deviation: 213.4750 Fuel Consumption: 43.3786\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.658\n",
      "Episode: 60 Exploration P: 0.2006 Total reward: -1919.1127752255682 SOC: 0.4670 Cumulative_SOC_deviation: 187.4744 Fuel Consumption: 44.3692\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.944\n",
      "Episode: 61 Exploration P: 0.1954 Total reward: -1861.3622438512277 SOC: 0.4802 Cumulative_SOC_deviation: 181.5868 Fuel Consumption: 45.4938\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.785\n",
      "Episode: 62 Exploration P: 0.1904 Total reward: -2817.845022954823 SOC: 0.4011 Cumulative_SOC_deviation: 277.7644 Fuel Consumption: 40.2006\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.091\n",
      "Episode: 63 Exploration P: 0.1855 Total reward: -2194.846526468417 SOC: 0.4360 Cumulative_SOC_deviation: 215.2603 Fuel Consumption: 42.2436\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.537\n",
      "Episode: 64 Exploration P: 0.1808 Total reward: -2639.1645482302783 SOC: 0.3943 Cumulative_SOC_deviation: 260.0047 Fuel Consumption: 39.1172\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.531\n",
      "Episode: 65 Exploration P: 0.1761 Total reward: -3173.5686381369333 SOC: 0.3178 Cumulative_SOC_deviation: 313.9095 Fuel Consumption: 34.4741\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.244\n",
      "Episode: 66 Exploration P: 0.1716 Total reward: -2730.9919645711466 SOC: 0.4231 Cumulative_SOC_deviation: 268.8831 Fuel Consumption: 42.1611\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.109\n",
      "Episode: 67 Exploration P: 0.1673 Total reward: -3462.365203401141 SOC: 0.3121 Cumulative_SOC_deviation: 342.8036 Fuel Consumption: 34.3296\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.292\n",
      "Episode: 68 Exploration P: 0.1630 Total reward: -3739.759986136119 SOC: 0.2336 Cumulative_SOC_deviation: 371.1446 Fuel Consumption: 28.3141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 194.884\n",
      "Episode: 69 Exploration P: 0.1589 Total reward: -3228.340718569124 SOC: 0.2907 Cumulative_SOC_deviation: 319.6137 Fuel Consumption: 32.2041\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.102\n",
      "Episode: 70 Exploration P: 0.1548 Total reward: -3025.893008950376 SOC: 0.3127 Cumulative_SOC_deviation: 299.1801 Fuel Consumption: 34.0923\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 197.337\n",
      "Episode: 71 Exploration P: 0.1509 Total reward: -3226.904806610637 SOC: 0.2825 Cumulative_SOC_deviation: 319.4897 Fuel Consumption: 32.0080\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 197.637\n",
      "Episode: 72 Exploration P: 0.1471 Total reward: -2870.1514555222584 SOC: 0.3438 Cumulative_SOC_deviation: 283.4450 Fuel Consumption: 35.7019\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.083\n",
      "Episode: 73 Exploration P: 0.1434 Total reward: -3693.258372463346 SOC: 0.2361 Cumulative_SOC_deviation: 366.4707 Fuel Consumption: 28.5514\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 197.652\n",
      "Episode: 74 Exploration P: 0.1398 Total reward: -3201.5409561501174 SOC: 0.2761 Cumulative_SOC_deviation: 317.0235 Fuel Consumption: 31.3064\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 197.857\n",
      "Episode: 75 Exploration P: 0.1362 Total reward: -3612.140667002204 SOC: 0.2192 Cumulative_SOC_deviation: 358.4765 Fuel Consumption: 27.3752\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 197.276\n",
      "Episode: 76 Exploration P: 0.1328 Total reward: -3325.857792852364 SOC: 0.2689 Cumulative_SOC_deviation: 329.4882 Fuel Consumption: 30.9762\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 196.975\n",
      "Episode: 77 Exploration P: 0.1295 Total reward: -3616.75131181892 SOC: 0.2683 Cumulative_SOC_deviation: 358.5497 Fuel Consumption: 31.2548\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 197.475\n",
      "Episode: 78 Exploration P: 0.1263 Total reward: -3644.9507927924706 SOC: 0.2332 Cumulative_SOC_deviation: 361.6503 Fuel Consumption: 28.4483\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 196.981\n",
      "Episode: 79 Exploration P: 0.1231 Total reward: -4220.953127249399 SOC: 0.1435 Cumulative_SOC_deviation: 419.8603 Fuel Consumption: 22.3502\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 195.404\n",
      "Episode: 80 Exploration P: 0.1200 Total reward: -4174.091892742875 SOC: 0.1872 Cumulative_SOC_deviation: 414.8801 Fuel Consumption: 25.2909\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 197.502\n",
      "Episode: 81 Exploration P: 0.1171 Total reward: -3869.307633512639 SOC: 0.2232 Cumulative_SOC_deviation: 384.1406 Fuel Consumption: 27.9014\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 197.120\n",
      "Episode: 82 Exploration P: 0.1142 Total reward: -4413.147873546664 SOC: 0.1569 Cumulative_SOC_deviation: 438.9498 Fuel Consumption: 23.6503\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 196.108\n",
      "Episode: 83 Exploration P: 0.1113 Total reward: -3747.4443261693687 SOC: 0.2136 Cumulative_SOC_deviation: 372.0410 Fuel Consumption: 27.0347\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 194.364\n",
      "Episode: 84 Exploration P: 0.1086 Total reward: -4500.000166877615 SOC: 0.1214 Cumulative_SOC_deviation: 447.9239 Fuel Consumption: 20.7613\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.498\n",
      "Episode: 85 Exploration P: 0.1059 Total reward: -4486.39357214174 SOC: 0.1158 Cumulative_SOC_deviation: 446.6035 Fuel Consumption: 20.3588\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 197.750\n",
      "Episode: 86 Exploration P: 0.1033 Total reward: -4289.769269402431 SOC: 0.1585 Cumulative_SOC_deviation: 426.6150 Fuel Consumption: 23.6194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.438\n",
      "Episode: 87 Exploration P: 0.1008 Total reward: -4608.230881920987 SOC: 0.1106 Cumulative_SOC_deviation: 458.7645 Fuel Consumption: 20.5858\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.652\n",
      "Episode: 88 Exploration P: 0.0983 Total reward: -4732.370321138122 SOC: 0.1094 Cumulative_SOC_deviation: 471.2311 Fuel Consumption: 20.0596\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 197.948\n",
      "Episode: 89 Exploration P: 0.0960 Total reward: -4563.970633940399 SOC: 0.0941 Cumulative_SOC_deviation: 454.4933 Fuel Consumption: 19.0381\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.120\n",
      "Episode: 90 Exploration P: 0.0936 Total reward: -4344.877412985016 SOC: 0.1288 Cumulative_SOC_deviation: 432.3363 Fuel Consumption: 21.5145\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 199.117\n",
      "Episode: 91 Exploration P: 0.0914 Total reward: -4501.955324618322 SOC: 0.1187 Cumulative_SOC_deviation: 448.0874 Fuel Consumption: 21.0811\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 197.851\n",
      "Episode: 92 Exploration P: 0.0892 Total reward: -4227.433358522755 SOC: 0.1478 Cumulative_SOC_deviation: 420.4732 Fuel Consumption: 22.7011\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.268\n",
      "Episode: 93 Exploration P: 0.0870 Total reward: -5056.559577352727 SOC: 0.0546 Cumulative_SOC_deviation: 504.0091 Fuel Consumption: 16.4689\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 196.505\n",
      "Episode: 94 Exploration P: 0.0849 Total reward: -4547.513399290256 SOC: 0.1034 Cumulative_SOC_deviation: 452.7908 Fuel Consumption: 19.6056\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.472\n",
      "Episode: 95 Exploration P: 0.0829 Total reward: -4505.846103461554 SOC: 0.1017 Cumulative_SOC_deviation: 448.5910 Fuel Consumption: 19.9358\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.546\n",
      "Episode: 96 Exploration P: 0.0809 Total reward: -4928.302275891323 SOC: 0.0829 Cumulative_SOC_deviation: 490.9966 Fuel Consumption: 18.3365\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 189.584\n",
      "Episode: 97 Exploration P: 0.0790 Total reward: -5006.470380420531 SOC: 0.0679 Cumulative_SOC_deviation: 498.9073 Fuel Consumption: 17.3975\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 181.804\n",
      "Episode: 98 Exploration P: 0.0771 Total reward: -4639.28379756369 SOC: 0.1061 Cumulative_SOC_deviation: 461.9585 Fuel Consumption: 19.6985\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 186.025\n",
      "Episode: 99 Exploration P: 0.0753 Total reward: -4719.331249262542 SOC: 0.0954 Cumulative_SOC_deviation: 469.9911 Fuel Consumption: 19.4199\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 185.244\n",
      "Episode: 100 Exploration P: 0.0735 Total reward: -5037.021272392637 SOC: 0.0463 Cumulative_SOC_deviation: 502.0883 Fuel Consumption: 16.1387\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 183.513\n",
      "Episode: 101 Exploration P: 0.0718 Total reward: -5174.9175088153315 SOC: 0.0594 Cumulative_SOC_deviation: 515.8170 Fuel Consumption: 16.7475\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 5273.517\n",
      "Episode: 102 Exploration P: 0.0701 Total reward: -5168.960688384965 SOC: 0.0728 Cumulative_SOC_deviation: 515.1006 Fuel Consumption: 17.9547\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 146.323\n",
      "Episode: 103 Exploration P: 0.0685 Total reward: -4896.214735939798 SOC: 0.0791 Cumulative_SOC_deviation: 487.8157 Fuel Consumption: 18.0579\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 113.145\n",
      "Episode: 104 Exploration P: 0.0669 Total reward: -5113.659174458245 SOC: 0.0368 Cumulative_SOC_deviation: 509.8367 Fuel Consumption: 15.2926\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.590\n",
      "Episode: 105 Exploration P: 0.0654 Total reward: -5206.027635565482 SOC: 0.0394 Cumulative_SOC_deviation: 519.0601 Fuel Consumption: 15.4268\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 110.647\n",
      "Episode: 106 Exploration P: 0.0639 Total reward: -5281.674498780291 SOC: 0.0238 Cumulative_SOC_deviation: 526.7176 Fuel Consumption: 14.4981\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 108.410\n",
      "Episode: 107 Exploration P: 0.0624 Total reward: -5337.86737425617 SOC: 0.0145 Cumulative_SOC_deviation: 532.3885 Fuel Consumption: 13.9822\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.725\n",
      "Episode: 108 Exploration P: 0.0610 Total reward: -5591.998910706021 SOC: -0.0089 Cumulative_SOC_deviation: 558.0049 Fuel Consumption: 11.9496\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.366\n",
      "Episode: 109 Exploration P: 0.0596 Total reward: -5544.970950501388 SOC: 0.0056 Cumulative_SOC_deviation: 553.1680 Fuel Consumption: 13.2909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.101\n",
      "Episode: 110 Exploration P: 0.0583 Total reward: -4908.097723088203 SOC: 0.1022 Cumulative_SOC_deviation: 488.7842 Fuel Consumption: 20.2557\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.992\n",
      "Episode: 111 Exploration P: 0.0570 Total reward: -5201.813517237322 SOC: 0.0289 Cumulative_SOC_deviation: 518.7119 Fuel Consumption: 14.6942\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.355\n",
      "Episode: 112 Exploration P: 0.0557 Total reward: -5223.063657800854 SOC: 0.0308 Cumulative_SOC_deviation: 520.8462 Fuel Consumption: 14.6013\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.016\n",
      "Episode: 113 Exploration P: 0.0545 Total reward: -5059.6403498936 SOC: 0.0347 Cumulative_SOC_deviation: 504.4296 Fuel Consumption: 15.3442\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.098\n",
      "Episode: 114 Exploration P: 0.0533 Total reward: -5393.560103796467 SOC: 0.0192 Cumulative_SOC_deviation: 537.9227 Fuel Consumption: 14.3331\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.291\n",
      "Episode: 115 Exploration P: 0.0521 Total reward: -5328.612218531995 SOC: 0.0220 Cumulative_SOC_deviation: 531.4197 Fuel Consumption: 14.4156\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.284\n",
      "Episode: 116 Exploration P: 0.0510 Total reward: -5353.049075146948 SOC: 0.0125 Cumulative_SOC_deviation: 533.9335 Fuel Consumption: 13.7140\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.832\n",
      "Episode: 117 Exploration P: 0.0498 Total reward: -5569.986008782516 SOC: -0.0014 Cumulative_SOC_deviation: 555.7232 Fuel Consumption: 12.7544\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.846\n",
      "Episode: 118 Exploration P: 0.0488 Total reward: -5238.820387635424 SOC: 0.0077 Cumulative_SOC_deviation: 522.5519 Fuel Consumption: 13.3012\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.111\n",
      "Episode: 119 Exploration P: 0.0477 Total reward: -5435.997922426479 SOC: 0.0001 Cumulative_SOC_deviation: 542.3264 Fuel Consumption: 12.7337\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 97.200\n",
      "Episode: 120 Exploration P: 0.0467 Total reward: -5375.297385849533 SOC: 0.0013 Cumulative_SOC_deviation: 536.2233 Fuel Consumption: 13.0639\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.326\n",
      "Episode: 121 Exploration P: 0.0457 Total reward: -5491.718697998579 SOC: -0.0093 Cumulative_SOC_deviation: 547.9449 Fuel Consumption: 12.2694\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.929\n",
      "Episode: 122 Exploration P: 0.0447 Total reward: -5572.1726331929 SOC: -0.0186 Cumulative_SOC_deviation: 556.0625 Fuel Consumption: 11.5472\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.834\n",
      "Episode: 123 Exploration P: 0.0438 Total reward: -5608.890142569104 SOC: -0.0117 Cumulative_SOC_deviation: 559.6672 Fuel Consumption: 12.2178\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.748\n",
      "Episode: 124 Exploration P: 0.0429 Total reward: -5645.5235691083335 SOC: -0.0297 Cumulative_SOC_deviation: 563.4812 Fuel Consumption: 10.7114\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.888\n",
      "Episode: 125 Exploration P: 0.0420 Total reward: -5587.844713956652 SOC: -0.0259 Cumulative_SOC_deviation: 557.6865 Fuel Consumption: 10.9797\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.775\n",
      "Episode: 126 Exploration P: 0.0411 Total reward: -5903.656889206877 SOC: -0.0452 Cumulative_SOC_deviation: 589.3761 Fuel Consumption: 9.8963\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.440\n",
      "Episode: 127 Exploration P: 0.0403 Total reward: -5844.850524827413 SOC: -0.0464 Cumulative_SOC_deviation: 583.5491 Fuel Consumption: 9.3597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RECL\\Desktop\\Song\\graduate_paper\\program\\experiment\\DDPG_batchnorm_comparison_revised\\vehicle_model_DDPG1.py:251: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n",
      "C:\\Users\\RECL\\Desktop\\Song\\graduate_paper\\program\\experiment\\DDPG_batchnorm_comparison_revised\\vehicle_model_DDPG1.py:277: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del_i = (1 / (2 * r_cha)) * (v_cha - (v_cha ** 2 - 4 * r_cha * p_bat) ** (0.5)) * (p_bat < 0) + (1 / (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOC is nan...\n",
      "elapsed_time: 71.570\n",
      "Episode: 128 Exploration P: 0.0396 Total reward: -5700.905003771798 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 6.2729\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.536\n",
      "Episode: 129 Exploration P: 0.0388 Total reward: -6050.162332120844 SOC: -0.0672 Cumulative_SOC_deviation: 604.2030 Fuel Consumption: 8.1319\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.535\n",
      "Episode: 130 Exploration P: 0.0380 Total reward: -5600.278805219993 SOC: -0.0298 Cumulative_SOC_deviation: 558.9423 Fuel Consumption: 10.8558\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.795\n",
      "Episode: 131 Exploration P: 0.0372 Total reward: -5823.548585876469 SOC: -0.0525 Cumulative_SOC_deviation: 581.4385 Fuel Consumption: 9.1637\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.479\n",
      "Episode: 132 Exploration P: 0.0365 Total reward: -5865.855792196197 SOC: -0.0485 Cumulative_SOC_deviation: 585.6166 Fuel Consumption: 9.6899\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.571\n",
      "Episode: 133 Exploration P: 0.0358 Total reward: -5832.764062528393 SOC: -0.0534 Cumulative_SOC_deviation: 582.3858 Fuel Consumption: 8.9057\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.680\n",
      "Episode: 134 Exploration P: 0.0351 Total reward: -5692.161692448135 SOC: -0.0437 Cumulative_SOC_deviation: 568.2554 Fuel Consumption: 9.6073\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.443\n",
      "Episode: 135 Exploration P: 0.0344 Total reward: -5742.089097540366 SOC: -0.0356 Cumulative_SOC_deviation: 573.2059 Fuel Consumption: 10.0304\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.322\n",
      "Episode: 136 Exploration P: 0.0337 Total reward: -5816.454532480485 SOC: -0.0419 Cumulative_SOC_deviation: 580.6806 Fuel Consumption: 9.6486\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.458\n",
      "Episode: 137 Exploration P: 0.0331 Total reward: -5724.663363078096 SOC: -0.0501 Cumulative_SOC_deviation: 571.5448 Fuel Consumption: 9.2153\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.662\n",
      "Episode: 138 Exploration P: 0.0325 Total reward: -5741.222781647766 SOC: -0.0291 Cumulative_SOC_deviation: 573.0398 Fuel Consumption: 10.8249\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.374\n",
      "Episode: 139 Exploration P: 0.0319 Total reward: -5857.924700761678 SOC: -0.0602 Cumulative_SOC_deviation: 584.9690 Fuel Consumption: 8.2350\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.568\n",
      "Episode: 140 Exploration P: 0.0313 Total reward: -5801.402488841379 SOC: -0.0497 Cumulative_SOC_deviation: 579.2115 Fuel Consumption: 9.2875\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.503\n",
      "Episode: 141 Exploration P: 0.0307 Total reward: -5781.826453462069 SOC: -0.0516 Cumulative_SOC_deviation: 577.2539 Fuel Consumption: 9.2875\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.080\n",
      "Episode: 142 Exploration P: 0.0301 Total reward: -5827.091741732283 SOC: -0.0312 Cumulative_SOC_deviation: 581.6174 Fuel Consumption: 10.9177\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.351\n",
      "Episode: 143 Exploration P: 0.0296 Total reward: -5754.504189896518 SOC: -0.0455 Cumulative_SOC_deviation: 574.4917 Fuel Consumption: 9.5867\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.547\n",
      "Episode: 144 Exploration P: 0.0291 Total reward: -5695.003114769709 SOC: -0.0400 Cumulative_SOC_deviation: 568.5045 Fuel Consumption: 9.9582\n",
      "SOC is nan...\n",
      "elapsed_time: 71.302\n",
      "Episode: 145 Exploration P: 0.0286 Total reward: -5721.99529158556 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.7054\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.399\n",
      "Episode: 146 Exploration P: 0.0281 Total reward: -5773.545144086777 SOC: -0.0557 Cumulative_SOC_deviation: 576.4753 Fuel Consumption: 8.7922\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.342\n",
      "Episode: 147 Exploration P: 0.0276 Total reward: -5974.163228150083 SOC: -0.0743 Cumulative_SOC_deviation: 596.6650 Fuel Consumption: 7.5128\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.400\n",
      "Episode: 148 Exploration P: 0.0271 Total reward: -5777.011656101993 SOC: -0.0577 Cumulative_SOC_deviation: 576.8498 Fuel Consumption: 8.5136\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.315\n",
      "Episode: 149 Exploration P: 0.0267 Total reward: -5985.63504341159 SOC: -0.0550 Cumulative_SOC_deviation: 597.6554 Fuel Consumption: 9.0811\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.876\n",
      "Episode: 150 Exploration P: 0.0262 Total reward: -5753.595824134143 SOC: -0.0516 Cumulative_SOC_deviation: 574.4535 Fuel Consumption: 9.0605\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.369\n",
      "Episode: 151 Exploration P: 0.0258 Total reward: -5552.488253917536 SOC: -0.0302 Cumulative_SOC_deviation: 554.1870 Fuel Consumption: 10.6185\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.409\n",
      "Episode: 152 Exploration P: 0.0254 Total reward: -6000.494250476331 SOC: -0.0606 Cumulative_SOC_deviation: 599.2197 Fuel Consumption: 8.2969\n",
      "SOC is nan...\n",
      "elapsed_time: 71.698\n",
      "Episode: 153 Exploration P: 0.0250 Total reward: -5742.0702108047735 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.3443\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.687\n",
      "Episode: 154 Exploration P: 0.0246 Total reward: -5977.60400293661 SOC: -0.0552 Cumulative_SOC_deviation: 596.8626 Fuel Consumption: 8.9779\n",
      "SOC is nan...\n",
      "elapsed_time: 71.448\n",
      "Episode: 155 Exploration P: 0.0243 Total reward: -5663.59019897072 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.0451\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.484\n",
      "Episode: 156 Exploration P: 0.0239 Total reward: -6006.546030554315 SOC: -0.0680 Cumulative_SOC_deviation: 599.8435 Fuel Consumption: 8.1112\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.519\n",
      "Episode: 157 Exploration P: 0.0235 Total reward: -5958.156492200687 SOC: -0.0642 Cumulative_SOC_deviation: 594.9932 Fuel Consumption: 8.2247\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.301\n",
      "Episode: 158 Exploration P: 0.0231 Total reward: -5960.566735912474 SOC: -0.0729 Cumulative_SOC_deviation: 595.2817 Fuel Consumption: 7.7501\n",
      "SOC is nan...\n",
      "elapsed_time: 71.767\n",
      "Episode: 159 Exploration P: 0.0228 Total reward: -5666.996330916007 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.8705\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.506\n",
      "Episode: 160 Exploration P: 0.0225 Total reward: -5938.729276180639 SOC: -0.0717 Cumulative_SOC_deviation: 593.1237 Fuel Consumption: 7.4921\n",
      "SOC is nan...\n",
      "elapsed_time: 71.287\n",
      "Episode: 161 Exploration P: 0.0222 Total reward: -5676.994801653089 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.5403\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.250\n",
      "Episode: 162 Exploration P: 0.0219 Total reward: -5989.3608356202285 SOC: -0.0629 Cumulative_SOC_deviation: 598.0858 Fuel Consumption: 8.5033\n",
      "SOC is nan...\n",
      "elapsed_time: 71.517\n",
      "Episode: 163 Exploration P: 0.0216 Total reward: -5723.242963824079 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 6.3142\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.810\n",
      "Episode: 164 Exploration P: 0.0213 Total reward: -5865.819406201232 SOC: -0.0650 Cumulative_SOC_deviation: 585.7409 Fuel Consumption: 8.4104\n",
      "SOC is nan...\n",
      "elapsed_time: 71.662\n",
      "Episode: 165 Exploration P: 0.0210 Total reward: -5798.836860469232 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.2308\n",
      "SOC is nan...\n",
      "elapsed_time: 71.496\n",
      "Episode: 166 Exploration P: 0.0208 Total reward: -5704.880188885866 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.8189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.363\n",
      "Episode: 167 Exploration P: 0.0205 Total reward: -5972.162873022598 SOC: -0.0627 Cumulative_SOC_deviation: 596.3443 Fuel Consumption: 8.7200\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.674\n",
      "Episode: 168 Exploration P: 0.0202 Total reward: -5949.060622325087 SOC: -0.0751 Cumulative_SOC_deviation: 594.1486 Fuel Consumption: 7.5747\n",
      "SOC is nan...\n",
      "elapsed_time: 71.446\n",
      "Episode: 169 Exploration P: 0.0199 Total reward: -5727.0518613492095 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.4991\n",
      "SOC is nan...\n",
      "elapsed_time: 71.506\n",
      "Episode: 170 Exploration P: 0.0197 Total reward: -5719.9679644231555 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.1998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOC is nan...\n",
      "elapsed_time: 71.562\n",
      "Episode: 171 Exploration P: 0.0195 Total reward: -5877.772589803241 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 4.5292\n",
      "SOC is nan...\n",
      "elapsed_time: 71.326\n",
      "Episode: 172 Exploration P: 0.0193 Total reward: -5817.03948133004 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 4.9728\n",
      "SOC is nan...\n",
      "elapsed_time: 70.744\n",
      "Episode: 173 Exploration P: 0.0190 Total reward: -5778.1291135696565 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.6332\n",
      "SOC is nan...\n",
      "elapsed_time: 71.455\n",
      "Episode: 174 Exploration P: 0.0188 Total reward: -5868.693803453849 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 4.3744\n",
      "SOC is nan...\n",
      "elapsed_time: 71.368\n",
      "Episode: 175 Exploration P: 0.0186 Total reward: -5724.011290142905 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.9015\n",
      "SOC is nan...\n",
      "elapsed_time: 71.458\n",
      "Episode: 176 Exploration P: 0.0184 Total reward: -5795.98350607495 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 4.6839\n",
      "SOC is nan...\n",
      "elapsed_time: 71.351\n",
      "Episode: 177 Exploration P: 0.0182 Total reward: -5793.930554023337 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 4.4260\n",
      "SOC is nan...\n",
      "elapsed_time: 71.585\n",
      "Episode: 178 Exploration P: 0.0180 Total reward: -5761.718158936688 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 4.6839\n",
      "SOC is nan...\n",
      "elapsed_time: 71.943\n",
      "Episode: 179 Exploration P: 0.0179 Total reward: -5687.211351200627 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.3546\n",
      "SOC is nan...\n",
      "elapsed_time: 71.373\n",
      "Episode: 180 Exploration P: 0.0177 Total reward: -5746.6044854835645 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.6642\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.541\n",
      "Episode: 181 Exploration P: 0.0175 Total reward: -5921.19441045637 SOC: -0.0718 Cumulative_SOC_deviation: 591.3465 Fuel Consumption: 7.7294\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.147\n",
      "Episode: 182 Exploration P: 0.0173 Total reward: -5938.524978306168 SOC: -0.0663 Cumulative_SOC_deviation: 593.0383 Fuel Consumption: 8.1422\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.071\n",
      "Episode: 183 Exploration P: 0.0171 Total reward: -6027.663412071962 SOC: -0.0698 Cumulative_SOC_deviation: 601.9521 Fuel Consumption: 8.1422\n",
      "SOC is nan...\n",
      "elapsed_time: 70.802\n",
      "Episode: 184 Exploration P: 0.0169 Total reward: -5736.769074568931 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.5300\n",
      "SOC is nan...\n",
      "elapsed_time: 71.409\n",
      "Episode: 185 Exploration P: 0.0167 Total reward: -5697.9656248627925 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 6.0253\n",
      "SOC is nan...\n",
      "elapsed_time: 71.372\n",
      "Episode: 186 Exploration P: 0.0166 Total reward: -5872.64155792008 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 4.5395\n",
      "SOC is nan...\n",
      "elapsed_time: 71.434\n",
      "Episode: 187 Exploration P: 0.0164 Total reward: -5773.438066025988 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.1586\n",
      "SOC is nan...\n",
      "elapsed_time: 71.695\n",
      "Episode: 188 Exploration P: 0.0163 Total reward: -5704.146384293006 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.0554\n",
      "SOC is nan...\n",
      "elapsed_time: 71.594\n",
      "Episode: 189 Exploration P: 0.0161 Total reward: -5799.983241144971 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 4.7149\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.521\n",
      "Episode: 190 Exploration P: 0.0160 Total reward: -6244.257455145368 SOC: -0.1003 Cumulative_SOC_deviation: 623.8777 Fuel Consumption: 5.4801\n",
      "SOC is nan...\n",
      "elapsed_time: 71.161\n",
      "Episode: 191 Exploration P: 0.0158 Total reward: -5722.631134515902 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.7777\n",
      "SOC is nan...\n",
      "elapsed_time: 71.353\n",
      "Episode: 192 Exploration P: 0.0157 Total reward: -5786.340443079354 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 4.1474\n",
      "SOC is nan...\n",
      "elapsed_time: 70.964\n",
      "Episode: 193 Exploration P: 0.0156 Total reward: -5737.296470639967 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.2721\n",
      "SOC is nan...\n",
      "elapsed_time: 67.497\n",
      "Episode: 194 Exploration P: 0.0154 Total reward: -5728.146570968524 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.1895\n",
      "SOC is nan...\n",
      "elapsed_time: 71.412\n",
      "Episode: 195 Exploration P: 0.0153 Total reward: -5740.297976362849 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.0967\n",
      "SOC is nan...\n",
      "elapsed_time: 71.535\n",
      "Episode: 196 Exploration P: 0.0152 Total reward: -5707.725780090766 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.9943\n",
      "SOC is nan...\n",
      "elapsed_time: 71.713\n",
      "Episode: 197 Exploration P: 0.0151 Total reward: -5810.334419973538 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 5.0657\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.500\n",
      "Episode: 198 Exploration P: 0.0149 Total reward: -5897.411758776797 SOC: -0.0677 Cumulative_SOC_deviation: 588.9414 Fuel Consumption: 7.9977\n",
      "SOC is nan...\n",
      "elapsed_time: 71.573\n",
      "Episode: 199 Exploration P: 0.0148 Total reward: -5796.119403910512 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 4.6427\n",
      "SOC is nan...\n",
      "elapsed_time: 71.260\n",
      "Episode: 200 Exploration P: 0.0147 Total reward: -5822.868981649546 SOC: nan Cumulative_SOC_deviation: nan Fuel Consumption: 4.6014\n",
      "\n",
      "Trial 1\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 30.173\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -4993.719490467837 SOC: 1.0000 Cumulative_SOC_deviation: 484.0515 Fuel Consumption: 153.2049\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 30.490\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -5069.41108582997 SOC: 1.0000 Cumulative_SOC_deviation: 491.5866 Fuel Consumption: 153.5454\n",
      "WARNING:tensorflow:Layer dense_27 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_30 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_21 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_18 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.765\n",
      "Episode: 3 Exploration P: 0.9217 Total reward: -5121.582990160045 SOC: 1.0000 Cumulative_SOC_deviation: 497.9235 Fuel Consumption: 142.3484\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.456\n",
      "Episode: 4 Exploration P: 0.8970 Total reward: -5167.600232949158 SOC: 1.0000 Cumulative_SOC_deviation: 500.0762 Fuel Consumption: 166.8385\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.620\n",
      "Episode: 5 Exploration P: 0.8730 Total reward: -5259.23064641122 SOC: 1.0000 Cumulative_SOC_deviation: 509.0353 Fuel Consumption: 168.8781\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.482\n",
      "Episode: 6 Exploration P: 0.8496 Total reward: -5186.901796290291 SOC: 1.0000 Cumulative_SOC_deviation: 501.6951 Fuel Consumption: 169.9512\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.524\n",
      "Episode: 7 Exploration P: 0.8269 Total reward: -5209.535583285984 SOC: 1.0000 Cumulative_SOC_deviation: 504.0399 Fuel Consumption: 169.1361\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.199\n",
      "Episode: 8 Exploration P: 0.8048 Total reward: -5199.057887107191 SOC: 1.0000 Cumulative_SOC_deviation: 502.4701 Fuel Consumption: 174.3571\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.781\n",
      "Episode: 9 Exploration P: 0.7832 Total reward: -5263.401828694864 SOC: 1.0000 Cumulative_SOC_deviation: 508.4525 Fuel Consumption: 178.8764\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.516\n",
      "Episode: 10 Exploration P: 0.7623 Total reward: -5258.781961417173 SOC: 1.0000 Cumulative_SOC_deviation: 507.5500 Fuel Consumption: 183.2823\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.934\n",
      "Episode: 11 Exploration P: 0.7419 Total reward: -5285.415651218756 SOC: 1.0000 Cumulative_SOC_deviation: 510.8159 Fuel Consumption: 177.2565\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.637\n",
      "Episode: 12 Exploration P: 0.7221 Total reward: -5328.583093143631 SOC: 1.0000 Cumulative_SOC_deviation: 514.5507 Fuel Consumption: 183.0759\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.914\n",
      "Episode: 13 Exploration P: 0.7028 Total reward: -5253.711254045623 SOC: 1.0000 Cumulative_SOC_deviation: 506.7849 Fuel Consumption: 185.8618\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.778\n",
      "Episode: 14 Exploration P: 0.6840 Total reward: -5290.847422569341 SOC: 1.0000 Cumulative_SOC_deviation: 510.1416 Fuel Consumption: 189.4319\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.173\n",
      "Episode: 15 Exploration P: 0.6658 Total reward: -5256.8505752887695 SOC: 1.0000 Cumulative_SOC_deviation: 506.7326 Fuel Consumption: 189.5247\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.992\n",
      "Episode: 16 Exploration P: 0.6480 Total reward: -5345.3576942718155 SOC: 1.0000 Cumulative_SOC_deviation: 514.9869 Fuel Consumption: 195.4886\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.148\n",
      "Episode: 17 Exploration P: 0.6307 Total reward: -5339.7994259762045 SOC: 1.0000 Cumulative_SOC_deviation: 514.4672 Fuel Consumption: 195.1275\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.061\n",
      "Episode: 18 Exploration P: 0.6139 Total reward: -5350.488958014548 SOC: 1.0000 Cumulative_SOC_deviation: 515.1317 Fuel Consumption: 199.1722\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.250\n",
      "Episode: 19 Exploration P: 0.5976 Total reward: -5319.153744164241 SOC: 1.0000 Cumulative_SOC_deviation: 511.9043 Fuel Consumption: 200.1111\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.978\n",
      "Episode: 20 Exploration P: 0.5816 Total reward: -5371.9849459778225 SOC: 1.0000 Cumulative_SOC_deviation: 516.8644 Fuel Consumption: 203.3407\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.163\n",
      "Episode: 21 Exploration P: 0.5662 Total reward: -5388.207881528261 SOC: 1.0000 Cumulative_SOC_deviation: 518.3815 Fuel Consumption: 204.3932\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.739\n",
      "Episode: 22 Exploration P: 0.5511 Total reward: -5365.365834664143 SOC: 1.0000 Cumulative_SOC_deviation: 515.6897 Fuel Consumption: 208.4688\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.387\n",
      "Episode: 23 Exploration P: 0.5364 Total reward: -5351.23635575817 SOC: 1.0000 Cumulative_SOC_deviation: 514.2902 Fuel Consumption: 208.3347\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.142\n",
      "Episode: 24 Exploration P: 0.5222 Total reward: -5373.426533464125 SOC: 1.0000 Cumulative_SOC_deviation: 516.0366 Fuel Consumption: 213.0604\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.119\n",
      "Episode: 25 Exploration P: 0.5083 Total reward: -5386.360843320851 SOC: 1.0000 Cumulative_SOC_deviation: 517.1309 Fuel Consumption: 215.0518\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.134\n",
      "Episode: 26 Exploration P: 0.4948 Total reward: -5377.82756621674 SOC: 1.0000 Cumulative_SOC_deviation: 516.9060 Fuel Consumption: 208.7681\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.527\n",
      "Episode: 27 Exploration P: 0.4817 Total reward: -5401.472753900338 SOC: 1.0000 Cumulative_SOC_deviation: 518.4079 Fuel Consumption: 217.3940\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.056\n",
      "Episode: 28 Exploration P: 0.4689 Total reward: -5410.553876547733 SOC: 1.0000 Cumulative_SOC_deviation: 519.0921 Fuel Consumption: 219.6331\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.012\n",
      "Episode: 29 Exploration P: 0.4565 Total reward: -5390.952583723475 SOC: 1.0000 Cumulative_SOC_deviation: 517.0133 Fuel Consumption: 220.8196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.985\n",
      "Episode: 30 Exploration P: 0.4444 Total reward: -5403.539847334944 SOC: 1.0000 Cumulative_SOC_deviation: 518.1699 Fuel Consumption: 221.8411\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.441\n",
      "Episode: 31 Exploration P: 0.4326 Total reward: -5401.007789987247 SOC: 1.0000 Cumulative_SOC_deviation: 517.8537 Fuel Consumption: 222.4705\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.268\n",
      "Episode: 32 Exploration P: 0.4212 Total reward: -5405.195673264106 SOC: 1.0000 Cumulative_SOC_deviation: 518.3272 Fuel Consumption: 221.9237\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.278\n",
      "Episode: 33 Exploration P: 0.4100 Total reward: -5422.29325630927 SOC: 1.0000 Cumulative_SOC_deviation: 519.5066 Fuel Consumption: 227.2272\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.436\n",
      "Episode: 34 Exploration P: 0.3992 Total reward: -5407.768885784543 SOC: 1.0000 Cumulative_SOC_deviation: 517.9221 Fuel Consumption: 228.5479\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.194\n",
      "Episode: 35 Exploration P: 0.3887 Total reward: -5403.292251372013 SOC: 1.0000 Cumulative_SOC_deviation: 516.9926 Fuel Consumption: 233.3665\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.664\n",
      "Episode: 36 Exploration P: 0.3784 Total reward: -5438.793133320539 SOC: 1.0000 Cumulative_SOC_deviation: 520.4746 Fuel Consumption: 234.0475\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.548\n",
      "Episode: 37 Exploration P: 0.3684 Total reward: -5437.196417976092 SOC: 1.0000 Cumulative_SOC_deviation: 520.3417 Fuel Consumption: 233.7792\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.639\n",
      "Episode: 38 Exploration P: 0.3587 Total reward: -5441.252429929921 SOC: 1.0000 Cumulative_SOC_deviation: 520.9073 Fuel Consumption: 232.1799\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.535\n",
      "Episode: 39 Exploration P: 0.3493 Total reward: -5428.599679344799 SOC: 1.0000 Cumulative_SOC_deviation: 519.5883 Fuel Consumption: 232.7165\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.805\n",
      "Episode: 40 Exploration P: 0.3401 Total reward: -5446.563854253948 SOC: 1.0000 Cumulative_SOC_deviation: 521.0288 Fuel Consumption: 236.2762\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.658\n",
      "Episode: 41 Exploration P: 0.3311 Total reward: -5437.636427078493 SOC: 1.0000 Cumulative_SOC_deviation: 520.0463 Fuel Consumption: 237.1739\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.931\n",
      "Episode: 42 Exploration P: 0.3224 Total reward: -5447.397490914211 SOC: 1.0000 Cumulative_SOC_deviation: 520.7654 Fuel Consumption: 239.7431\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.860\n",
      "Episode: 43 Exploration P: 0.3140 Total reward: -5459.53958116979 SOC: 1.0000 Cumulative_SOC_deviation: 522.0447 Fuel Consumption: 239.0931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.284\n",
      "Episode: 44 Exploration P: 0.3057 Total reward: -5461.390522192836 SOC: 1.0000 Cumulative_SOC_deviation: 522.0358 Fuel Consumption: 241.0329\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.379\n",
      "Episode: 45 Exploration P: 0.2977 Total reward: -5457.509197199758 SOC: 1.0000 Cumulative_SOC_deviation: 521.8261 Fuel Consumption: 239.2478\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.956\n",
      "Episode: 46 Exploration P: 0.2899 Total reward: -5455.330459010511 SOC: 1.0000 Cumulative_SOC_deviation: 521.0377 Fuel Consumption: 244.9538\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.724\n",
      "Episode: 47 Exploration P: 0.2824 Total reward: -5483.8540705524965 SOC: 1.0000 Cumulative_SOC_deviation: 523.6052 Fuel Consumption: 247.8016\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.691\n",
      "Episode: 48 Exploration P: 0.2750 Total reward: -5470.166815586316 SOC: 1.0000 Cumulative_SOC_deviation: 522.4986 Fuel Consumption: 245.1808\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.584\n",
      "Episode: 49 Exploration P: 0.2678 Total reward: -5468.265432809332 SOC: 1.0000 Cumulative_SOC_deviation: 522.1207 Fuel Consumption: 247.0587\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.688\n",
      "Episode: 50 Exploration P: 0.2608 Total reward: -5472.554875160136 SOC: 1.0000 Cumulative_SOC_deviation: 522.2617 Fuel Consumption: 249.9374\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.616\n",
      "Episode: 51 Exploration P: 0.2540 Total reward: -5458.4654043673745 SOC: 1.0000 Cumulative_SOC_deviation: 521.0076 Fuel Consumption: 248.3897\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.759\n",
      "Episode: 52 Exploration P: 0.2474 Total reward: -5465.807443759152 SOC: 1.0000 Cumulative_SOC_deviation: 521.4302 Fuel Consumption: 251.5058\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.795\n",
      "Episode: 53 Exploration P: 0.2410 Total reward: -5451.401692468669 SOC: 1.0000 Cumulative_SOC_deviation: 520.1093 Fuel Consumption: 250.3089\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.847\n",
      "Episode: 54 Exploration P: 0.2347 Total reward: -5474.352776886327 SOC: 1.0000 Cumulative_SOC_deviation: 522.0598 Fuel Consumption: 253.7551\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.386\n",
      "Episode: 55 Exploration P: 0.2286 Total reward: -5479.291962478574 SOC: 1.0000 Cumulative_SOC_deviation: 522.7951 Fuel Consumption: 251.3407\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.628\n",
      "Episode: 56 Exploration P: 0.2227 Total reward: -5480.028356267233 SOC: 1.0000 Cumulative_SOC_deviation: 522.7181 Fuel Consumption: 252.8471\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.809\n",
      "Episode: 57 Exploration P: 0.2170 Total reward: -5465.375567983315 SOC: 1.0000 Cumulative_SOC_deviation: 521.3003 Fuel Consumption: 252.3725\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.703\n",
      "Episode: 58 Exploration P: 0.2114 Total reward: -5480.209128621722 SOC: 1.0000 Cumulative_SOC_deviation: 522.7888 Fuel Consumption: 252.3209\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.692\n",
      "Episode: 59 Exploration P: 0.2059 Total reward: -5482.049844236556 SOC: 1.0000 Cumulative_SOC_deviation: 522.7325 Fuel Consumption: 254.7250\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.825\n",
      "Episode: 60 Exploration P: 0.2006 Total reward: -5473.181550958384 SOC: 1.0000 Cumulative_SOC_deviation: 521.8477 Fuel Consumption: 254.7044\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.781\n",
      "Episode: 61 Exploration P: 0.1954 Total reward: -5479.3773391223895 SOC: 1.0000 Cumulative_SOC_deviation: 522.2682 Fuel Consumption: 256.6958\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.395\n",
      "Episode: 62 Exploration P: 0.1904 Total reward: -5485.576308937834 SOC: 1.0000 Cumulative_SOC_deviation: 522.8798 Fuel Consumption: 256.7784\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.348\n",
      "Episode: 63 Exploration P: 0.1855 Total reward: -5500.784559744965 SOC: 1.0000 Cumulative_SOC_deviation: 524.1747 Fuel Consumption: 259.0380\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.841\n",
      "Episode: 64 Exploration P: 0.1808 Total reward: -5500.364987286684 SOC: 1.0000 Cumulative_SOC_deviation: 524.1337 Fuel Consumption: 259.0277\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.722\n",
      "Episode: 65 Exploration P: 0.1761 Total reward: -5495.8419460069135 SOC: 1.0000 Cumulative_SOC_deviation: 523.3791 Fuel Consumption: 262.0509\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.292\n",
      "Episode: 66 Exploration P: 0.1716 Total reward: -5501.936981397977 SOC: 1.0000 Cumulative_SOC_deviation: 524.1630 Fuel Consumption: 260.3072\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.476\n",
      "Episode: 67 Exploration P: 0.1673 Total reward: -5490.104974252522 SOC: 1.0000 Cumulative_SOC_deviation: 523.0138 Fuel Consumption: 259.9667\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.124\n",
      "Episode: 68 Exploration P: 0.1630 Total reward: -5495.407795183208 SOC: 1.0000 Cumulative_SOC_deviation: 523.4709 Fuel Consumption: 260.6992\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.131\n",
      "Episode: 69 Exploration P: 0.1589 Total reward: -5491.458228736892 SOC: 1.0000 Cumulative_SOC_deviation: 523.3277 Fuel Consumption: 258.1816\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.886\n",
      "Episode: 70 Exploration P: 0.1548 Total reward: -5498.089695370802 SOC: 1.0000 Cumulative_SOC_deviation: 523.7514 Fuel Consumption: 260.5754\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.765\n",
      "Episode: 71 Exploration P: 0.1509 Total reward: -5504.047240232266 SOC: 1.0000 Cumulative_SOC_deviation: 524.0490 Fuel Consumption: 263.5574\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.822\n",
      "Episode: 72 Exploration P: 0.1471 Total reward: -5497.811346997801 SOC: 1.0000 Cumulative_SOC_deviation: 523.6039 Fuel Consumption: 261.7723\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.871\n",
      "Episode: 73 Exploration P: 0.1434 Total reward: -5497.771589188394 SOC: 1.0000 Cumulative_SOC_deviation: 523.5700 Fuel Consumption: 262.0716\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.710\n",
      "Episode: 74 Exploration P: 0.1398 Total reward: -5487.531506124648 SOC: 1.0000 Cumulative_SOC_deviation: 522.6337 Fuel Consumption: 261.1945\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.763\n",
      "Episode: 75 Exploration P: 0.1362 Total reward: -5503.621865377372 SOC: 1.0000 Cumulative_SOC_deviation: 523.9270 Fuel Consumption: 264.3519\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.666\n",
      "Episode: 76 Exploration P: 0.1328 Total reward: -5503.400827015459 SOC: 1.0000 Cumulative_SOC_deviation: 523.8987 Fuel Consumption: 264.4138\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.356\n",
      "Episode: 77 Exploration P: 0.1295 Total reward: -5499.025448711212 SOC: 1.0000 Cumulative_SOC_deviation: 523.1568 Fuel Consumption: 267.4576\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.762\n",
      "Episode: 78 Exploration P: 0.1263 Total reward: -5501.736514362236 SOC: 1.0000 Cumulative_SOC_deviation: 523.5538 Fuel Consumption: 266.1988\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.934\n",
      "Episode: 79 Exploration P: 0.1231 Total reward: -5485.66439195113 SOC: 1.0000 Cumulative_SOC_deviation: 522.0116 Fuel Consumption: 265.5488\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.424\n",
      "Episode: 80 Exploration P: 0.1200 Total reward: -5515.44651374186 SOC: 1.0000 Cumulative_SOC_deviation: 524.5987 Fuel Consumption: 269.4593\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.291\n",
      "Episode: 81 Exploration P: 0.1171 Total reward: -5511.674123288327 SOC: 1.0000 Cumulative_SOC_deviation: 524.6352 Fuel Consumption: 265.3218\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.941\n",
      "Episode: 82 Exploration P: 0.1142 Total reward: -5515.905356160371 SOC: 1.0000 Cumulative_SOC_deviation: 524.7406 Fuel Consumption: 268.4998\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.988\n",
      "Episode: 83 Exploration P: 0.1113 Total reward: -5518.3768150120995 SOC: 1.0000 Cumulative_SOC_deviation: 524.8856 Fuel Consumption: 269.5213\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.883\n",
      "Episode: 84 Exploration P: 0.1086 Total reward: -5508.031162603821 SOC: 1.0000 Cumulative_SOC_deviation: 524.1451 Fuel Consumption: 266.5806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.226\n",
      "Episode: 85 Exploration P: 0.1059 Total reward: -5506.947455343484 SOC: 1.0000 Cumulative_SOC_deviation: 523.9036 Fuel Consumption: 267.9116\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.837\n",
      "Episode: 86 Exploration P: 0.1033 Total reward: -5521.170980374429 SOC: 1.0000 Cumulative_SOC_deviation: 525.1650 Fuel Consumption: 269.5213\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.925\n",
      "Episode: 87 Exploration P: 0.1008 Total reward: -5510.381586451623 SOC: 1.0000 Cumulative_SOC_deviation: 524.1696 Fuel Consumption: 268.6855\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.920\n",
      "Episode: 88 Exploration P: 0.0983 Total reward: -5515.497622263038 SOC: 1.0000 Cumulative_SOC_deviation: 524.8226 Fuel Consumption: 267.2719\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.901\n",
      "Episode: 89 Exploration P: 0.0960 Total reward: -5516.0801730878375 SOC: 1.0000 Cumulative_SOC_deviation: 524.6518 Fuel Consumption: 269.5625\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.675\n",
      "Episode: 90 Exploration P: 0.0936 Total reward: -5522.4323301028335 SOC: 1.0000 Cumulative_SOC_deviation: 525.0342 Fuel Consumption: 272.0905\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.002\n",
      "Episode: 91 Exploration P: 0.0914 Total reward: -5512.295270658481 SOC: 1.0000 Cumulative_SOC_deviation: 524.0473 Fuel Consumption: 271.8222\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.033\n",
      "Episode: 92 Exploration P: 0.0892 Total reward: -5516.176212575173 SOC: 1.0000 Cumulative_SOC_deviation: 524.5664 Fuel Consumption: 270.5118\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.845\n",
      "Episode: 93 Exploration P: 0.0870 Total reward: -5513.93706817397 SOC: 1.0000 Cumulative_SOC_deviation: 524.3714 Fuel Consumption: 270.2229\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.890\n",
      "Episode: 94 Exploration P: 0.0849 Total reward: -5513.812982519636 SOC: 1.0000 Cumulative_SOC_deviation: 524.3188 Fuel Consumption: 270.6253\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.026\n",
      "Episode: 95 Exploration P: 0.0829 Total reward: -5513.612220951491 SOC: 1.0000 Cumulative_SOC_deviation: 524.2223 Fuel Consumption: 271.3888\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.893\n",
      "Episode: 96 Exploration P: 0.0809 Total reward: -5520.701095768362 SOC: 1.0000 Cumulative_SOC_deviation: 524.7837 Fuel Consumption: 272.8643\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.042\n",
      "Episode: 97 Exploration P: 0.0790 Total reward: -5520.178758344594 SOC: 1.0000 Cumulative_SOC_deviation: 524.8532 Fuel Consumption: 271.6468\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.855\n",
      "Episode: 98 Exploration P: 0.0771 Total reward: -5515.4405226977005 SOC: 1.0000 Cumulative_SOC_deviation: 524.3371 Fuel Consumption: 272.0698\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.915\n",
      "Episode: 99 Exploration P: 0.0753 Total reward: -5518.997339795258 SOC: 1.0000 Cumulative_SOC_deviation: 524.5483 Fuel Consumption: 273.5144\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.141\n",
      "Episode: 100 Exploration P: 0.0735 Total reward: -5520.571163166431 SOC: 1.0000 Cumulative_SOC_deviation: 524.9089 Fuel Consumption: 271.4817\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.096\n",
      "Episode: 101 Exploration P: 0.0718 Total reward: -5521.497009311216 SOC: 1.0000 Cumulative_SOC_deviation: 524.8045 Fuel Consumption: 273.4525\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.951\n",
      "Episode: 102 Exploration P: 0.0701 Total reward: -5512.543174755006 SOC: 1.0000 Cumulative_SOC_deviation: 523.9792 Fuel Consumption: 272.7508\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.993\n",
      "Episode: 103 Exploration P: 0.0685 Total reward: -5511.92811290131 SOC: 1.0000 Cumulative_SOC_deviation: 523.8249 Fuel Consumption: 273.6795\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.948\n",
      "Episode: 104 Exploration P: 0.0669 Total reward: -5523.2439336163125 SOC: 1.0000 Cumulative_SOC_deviation: 525.0844 Fuel Consumption: 272.4000\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.210\n",
      "Episode: 105 Exploration P: 0.0654 Total reward: -5524.355764792474 SOC: 1.0000 Cumulative_SOC_deviation: 524.9737 Fuel Consumption: 274.6184\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.968\n",
      "Episode: 106 Exploration P: 0.0639 Total reward: -5525.940443203857 SOC: 1.0000 Cumulative_SOC_deviation: 525.1673 Fuel Consumption: 274.2676\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.962\n",
      "Episode: 107 Exploration P: 0.0624 Total reward: -5522.754794492963 SOC: 1.0000 Cumulative_SOC_deviation: 524.7507 Fuel Consumption: 275.2478\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.957\n",
      "Episode: 108 Exploration P: 0.0610 Total reward: -5525.4588306438345 SOC: 1.0000 Cumulative_SOC_deviation: 525.0087 Fuel Consumption: 275.3716\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.692\n",
      "Episode: 109 Exploration P: 0.0596 Total reward: -5514.32579825548 SOC: 1.0000 Cumulative_SOC_deviation: 524.0595 Fuel Consumption: 273.7311\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.891\n",
      "Episode: 110 Exploration P: 0.0583 Total reward: -5521.940624935447 SOC: 1.0000 Cumulative_SOC_deviation: 524.6610 Fuel Consumption: 275.3304\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.230\n",
      "Episode: 111 Exploration P: 0.0570 Total reward: -5525.616602041121 SOC: 1.0000 Cumulative_SOC_deviation: 524.9554 Fuel Consumption: 276.0630\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.875\n",
      "Episode: 112 Exploration P: 0.0557 Total reward: -5524.708586513294 SOC: 1.0000 Cumulative_SOC_deviation: 524.8037 Fuel Consumption: 276.6717\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.963\n",
      "Episode: 113 Exploration P: 0.0545 Total reward: -5524.132712575676 SOC: 1.0000 Cumulative_SOC_deviation: 524.9215 Fuel Consumption: 274.9176\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.836\n",
      "Episode: 114 Exploration P: 0.0533 Total reward: -5528.643768486599 SOC: 1.0000 Cumulative_SOC_deviation: 525.2220 Fuel Consumption: 276.4241\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.192\n",
      "Episode: 115 Exploration P: 0.0521 Total reward: -5523.522261098973 SOC: 1.0000 Cumulative_SOC_deviation: 524.8625 Fuel Consumption: 274.8970\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.607\n",
      "Episode: 116 Exploration P: 0.0510 Total reward: -5526.13046850121 SOC: 1.0000 Cumulative_SOC_deviation: 525.0945 Fuel Consumption: 275.1859\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.799\n",
      "Episode: 117 Exploration P: 0.0498 Total reward: -5528.336416414429 SOC: 1.0000 Cumulative_SOC_deviation: 525.2304 Fuel Consumption: 276.0320\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.898\n",
      "Episode: 118 Exploration P: 0.0488 Total reward: -5528.227053040001 SOC: 1.0000 Cumulative_SOC_deviation: 525.1782 Fuel Consumption: 276.4447\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.938\n",
      "Episode: 119 Exploration P: 0.0477 Total reward: -5527.84666129032 SOC: 1.0000 Cumulative_SOC_deviation: 525.0133 Fuel Consumption: 277.7139\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.339\n",
      "Episode: 120 Exploration P: 0.0467 Total reward: -5531.350297713022 SOC: 1.0000 Cumulative_SOC_deviation: 525.4183 Fuel Consumption: 277.1670\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.028\n",
      "Episode: 121 Exploration P: 0.0457 Total reward: -5526.042949722856 SOC: 1.0000 Cumulative_SOC_deviation: 525.0104 Fuel Consumption: 275.9391\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.085\n",
      "Episode: 122 Exploration P: 0.0447 Total reward: -5525.957856478983 SOC: 1.0000 Cumulative_SOC_deviation: 524.8677 Fuel Consumption: 277.2805\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.136\n",
      "Episode: 123 Exploration P: 0.0438 Total reward: -5531.574685453716 SOC: 1.0000 Cumulative_SOC_deviation: 525.5078 Fuel Consumption: 276.4963\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.075\n",
      "Episode: 124 Exploration P: 0.0429 Total reward: -5528.724976149298 SOC: 1.0000 Cumulative_SOC_deviation: 525.2528 Fuel Consumption: 276.1971\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.994\n",
      "Episode: 125 Exploration P: 0.0420 Total reward: -5527.557230236419 SOC: 1.0000 Cumulative_SOC_deviation: 525.1855 Fuel Consumption: 275.7018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.015\n",
      "Episode: 126 Exploration P: 0.0411 Total reward: -5531.06171708217 SOC: 1.0000 Cumulative_SOC_deviation: 525.3379 Fuel Consumption: 277.6829\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.421\n",
      "Episode: 127 Exploration P: 0.0403 Total reward: -5523.915355702206 SOC: 1.0000 Cumulative_SOC_deviation: 524.6274 Fuel Consumption: 277.6416\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.569\n",
      "Episode: 128 Exploration P: 0.0395 Total reward: -5528.971200309955 SOC: 1.0000 Cumulative_SOC_deviation: 525.0896 Fuel Consumption: 278.0750\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.022\n",
      "Episode: 129 Exploration P: 0.0387 Total reward: -5531.885435497399 SOC: 1.0000 Cumulative_SOC_deviation: 525.4306 Fuel Consumption: 277.5797\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.993\n",
      "Episode: 130 Exploration P: 0.0379 Total reward: -5528.882774227986 SOC: 1.0000 Cumulative_SOC_deviation: 525.1024 Fuel Consumption: 277.8583\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.974\n",
      "Episode: 131 Exploration P: 0.0371 Total reward: -5527.930293198958 SOC: 1.0000 Cumulative_SOC_deviation: 524.9474 Fuel Consumption: 278.4568\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.555\n",
      "Episode: 132 Exploration P: 0.0364 Total reward: -5527.957993150697 SOC: 1.0000 Cumulative_SOC_deviation: 525.1162 Fuel Consumption: 276.7955\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.096\n",
      "Episode: 133 Exploration P: 0.0357 Total reward: -5530.933450761251 SOC: 1.0000 Cumulative_SOC_deviation: 525.2219 Fuel Consumption: 278.7147\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.027\n",
      "Episode: 134 Exploration P: 0.0350 Total reward: -5531.775043252097 SOC: 1.0000 Cumulative_SOC_deviation: 525.2895 Fuel Consumption: 278.8798\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.666\n",
      "Episode: 135 Exploration P: 0.0343 Total reward: -5525.816258971119 SOC: 1.0000 Cumulative_SOC_deviation: 524.9846 Fuel Consumption: 275.9701\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.971\n",
      "Episode: 136 Exploration P: 0.0336 Total reward: -5530.600273813864 SOC: 1.0000 Cumulative_SOC_deviation: 525.2340 Fuel Consumption: 278.2607\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.215\n",
      "Episode: 137 Exploration P: 0.0330 Total reward: -5529.491292344193 SOC: 1.0000 Cumulative_SOC_deviation: 525.1354 Fuel Consumption: 278.1369\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.100\n",
      "Episode: 138 Exploration P: 0.0324 Total reward: -5532.606997087821 SOC: 1.0000 Cumulative_SOC_deviation: 525.2592 Fuel Consumption: 280.0148\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.751\n",
      "Episode: 139 Exploration P: 0.0318 Total reward: -5531.990728524358 SOC: 1.0000 Cumulative_SOC_deviation: 525.4236 Fuel Consumption: 277.7551\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.805\n",
      "Episode: 140 Exploration P: 0.0312 Total reward: -5525.913728714946 SOC: 1.0000 Cumulative_SOC_deviation: 524.7240 Fuel Consumption: 278.6734\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.760\n",
      "Episode: 141 Exploration P: 0.0306 Total reward: -5529.389614153253 SOC: 1.0000 Cumulative_SOC_deviation: 525.1160 Fuel Consumption: 278.2298\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.160\n",
      "Episode: 142 Exploration P: 0.0301 Total reward: -5530.01617179795 SOC: 1.0000 Cumulative_SOC_deviation: 525.0796 Fuel Consumption: 279.2203\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.700\n",
      "Episode: 143 Exploration P: 0.0295 Total reward: -5532.975804796198 SOC: 1.0000 Cumulative_SOC_deviation: 525.3766 Fuel Consumption: 279.2100\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.830\n",
      "Episode: 144 Exploration P: 0.0290 Total reward: -5527.1406882062465 SOC: 1.0000 Cumulative_SOC_deviation: 524.8426 Fuel Consumption: 278.7147\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.636\n",
      "Episode: 145 Exploration P: 0.0285 Total reward: -5529.931839878477 SOC: 1.0000 Cumulative_SOC_deviation: 525.1537 Fuel Consumption: 278.3949\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.426\n",
      "Episode: 146 Exploration P: 0.0280 Total reward: -5530.1737981444285 SOC: 1.0000 Cumulative_SOC_deviation: 525.1284 Fuel Consumption: 278.8901\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.764\n",
      "Episode: 147 Exploration P: 0.0275 Total reward: -5531.794527136357 SOC: 1.0000 Cumulative_SOC_deviation: 525.3544 Fuel Consumption: 278.2504\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.867\n",
      "Episode: 148 Exploration P: 0.0270 Total reward: -5532.493381719055 SOC: 1.0000 Cumulative_SOC_deviation: 525.3583 Fuel Consumption: 278.9108\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.879\n",
      "Episode: 149 Exploration P: 0.0265 Total reward: -5531.981032919609 SOC: 1.0000 Cumulative_SOC_deviation: 525.3927 Fuel Consumption: 278.0544\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.088\n",
      "Episode: 150 Exploration P: 0.0261 Total reward: -5528.939667152997 SOC: 1.0000 Cumulative_SOC_deviation: 524.8822 Fuel Consumption: 280.1180\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.695\n",
      "Episode: 151 Exploration P: 0.0257 Total reward: -5533.64441326125 SOC: 1.0000 Cumulative_SOC_deviation: 525.5208 Fuel Consumption: 278.4361\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.799\n",
      "Episode: 152 Exploration P: 0.0252 Total reward: -5528.681565338051 SOC: 1.0000 Cumulative_SOC_deviation: 524.9121 Fuel Consumption: 279.5608\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.188\n",
      "Episode: 153 Exploration P: 0.0248 Total reward: -5530.935665533511 SOC: 1.0000 Cumulative_SOC_deviation: 525.0591 Fuel Consumption: 280.3450\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.277\n",
      "Episode: 154 Exploration P: 0.0244 Total reward: -5536.087500381504 SOC: 1.0000 Cumulative_SOC_deviation: 525.5443 Fuel Consumption: 280.6442\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.014\n",
      "Episode: 155 Exploration P: 0.0240 Total reward: -5535.967119215975 SOC: 1.0000 Cumulative_SOC_deviation: 525.5292 Fuel Consumption: 280.6752\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.789\n",
      "Episode: 156 Exploration P: 0.0237 Total reward: -5532.932824706476 SOC: 1.0000 Cumulative_SOC_deviation: 525.3207 Fuel Consumption: 279.7259\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.523\n",
      "Episode: 157 Exploration P: 0.0233 Total reward: -5532.9665912679975 SOC: 1.0000 Cumulative_SOC_deviation: 525.2415 Fuel Consumption: 280.5513\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.824\n",
      "Episode: 158 Exploration P: 0.0229 Total reward: -5534.522998020878 SOC: 1.0000 Cumulative_SOC_deviation: 525.3889 Fuel Consumption: 280.6339\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.623\n",
      "Episode: 159 Exploration P: 0.0226 Total reward: -5536.304223305551 SOC: 1.0000 Cumulative_SOC_deviation: 525.5825 Fuel Consumption: 280.4791\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.744\n",
      "Episode: 160 Exploration P: 0.0222 Total reward: -5531.45406503253 SOC: 1.0000 Cumulative_SOC_deviation: 525.1708 Fuel Consumption: 279.7465\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.023\n",
      "Episode: 161 Exploration P: 0.0219 Total reward: -5535.5544140110505 SOC: 1.0000 Cumulative_SOC_deviation: 525.5591 Fuel Consumption: 279.9632\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.761\n",
      "Episode: 162 Exploration P: 0.0216 Total reward: -5533.428474349155 SOC: 1.0000 Cumulative_SOC_deviation: 525.3228 Fuel Consumption: 280.2005\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.040\n",
      "Episode: 163 Exploration P: 0.0213 Total reward: -5532.094902114368 SOC: 1.0000 Cumulative_SOC_deviation: 525.2998 Fuel Consumption: 279.0965\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.520\n",
      "Episode: 164 Exploration P: 0.0210 Total reward: -5532.638518150971 SOC: 1.0000 Cumulative_SOC_deviation: 525.2531 Fuel Consumption: 280.1077\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.079\n",
      "Episode: 165 Exploration P: 0.0207 Total reward: -5535.3287508851445 SOC: 1.0000 Cumulative_SOC_deviation: 525.4519 Fuel Consumption: 280.8093\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.964\n",
      "Episode: 166 Exploration P: 0.0204 Total reward: -5531.234746672567 SOC: 1.0000 Cumulative_SOC_deviation: 525.0591 Fuel Consumption: 280.6442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.981\n",
      "Episode: 167 Exploration P: 0.0201 Total reward: -5529.352572063793 SOC: 1.0000 Cumulative_SOC_deviation: 524.9523 Fuel Consumption: 279.8291\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.847\n",
      "Episode: 168 Exploration P: 0.0198 Total reward: -5536.49907393348 SOC: 1.0000 Cumulative_SOC_deviation: 525.5834 Fuel Consumption: 280.6648\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.167\n",
      "Episode: 169 Exploration P: 0.0196 Total reward: -5529.200967798601 SOC: 1.0000 Cumulative_SOC_deviation: 525.0249 Fuel Consumption: 278.9520\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.153\n",
      "Episode: 170 Exploration P: 0.0193 Total reward: -5534.7625793886555 SOC: 1.0000 Cumulative_SOC_deviation: 525.5326 Fuel Consumption: 279.4370\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.896\n",
      "Episode: 171 Exploration P: 0.0190 Total reward: -5532.548838279656 SOC: 1.0000 Cumulative_SOC_deviation: 525.2421 Fuel Consumption: 280.1283\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.279\n",
      "Episode: 172 Exploration P: 0.0188 Total reward: -5534.599833243134 SOC: 1.0000 Cumulative_SOC_deviation: 525.4379 Fuel Consumption: 280.2212\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.740\n",
      "Episode: 173 Exploration P: 0.0186 Total reward: -5536.509851369217 SOC: 1.0000 Cumulative_SOC_deviation: 525.5855 Fuel Consumption: 280.6545\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.751\n",
      "Episode: 174 Exploration P: 0.0183 Total reward: -5534.173343232921 SOC: 1.0000 Cumulative_SOC_deviation: 525.2962 Fuel Consumption: 281.2117\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.842\n",
      "Episode: 175 Exploration P: 0.0181 Total reward: -5533.0095470157785 SOC: 1.0000 Cumulative_SOC_deviation: 525.3263 Fuel Consumption: 279.7465\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.071\n",
      "Episode: 176 Exploration P: 0.0179 Total reward: -5533.249046742943 SOC: 1.0000 Cumulative_SOC_deviation: 525.3802 Fuel Consumption: 279.4473\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.004\n",
      "Episode: 177 Exploration P: 0.0177 Total reward: -5534.061346147152 SOC: 1.0000 Cumulative_SOC_deviation: 525.3850 Fuel Consumption: 280.2108\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.034\n",
      "Episode: 178 Exploration P: 0.0175 Total reward: -5533.432106125955 SOC: 1.0000 Cumulative_SOC_deviation: 525.2747 Fuel Consumption: 280.6855\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.079\n",
      "Episode: 179 Exploration P: 0.0173 Total reward: -5534.512077168679 SOC: 1.0000 Cumulative_SOC_deviation: 525.4662 Fuel Consumption: 279.8497\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.134\n",
      "Episode: 180 Exploration P: 0.0171 Total reward: -5533.509074517161 SOC: 1.0000 Cumulative_SOC_deviation: 525.2782 Fuel Consumption: 280.7268\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.773\n",
      "Episode: 181 Exploration P: 0.0169 Total reward: -5531.99808924881 SOC: 1.0000 Cumulative_SOC_deviation: 525.3149 Fuel Consumption: 278.8489\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.889\n",
      "Episode: 182 Exploration P: 0.0167 Total reward: -5536.579359718457 SOC: 1.0000 Cumulative_SOC_deviation: 525.5213 Fuel Consumption: 281.3665\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.247\n",
      "Episode: 183 Exploration P: 0.0165 Total reward: -5534.813455421594 SOC: 1.0000 Cumulative_SOC_deviation: 525.3457 Fuel Consumption: 281.3562\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.957\n",
      "Episode: 184 Exploration P: 0.0163 Total reward: -5533.707750336221 SOC: 1.0000 Cumulative_SOC_deviation: 525.3579 Fuel Consumption: 280.1283\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.056\n",
      "Episode: 185 Exploration P: 0.0162 Total reward: -5532.143194384466 SOC: 1.0000 Cumulative_SOC_deviation: 525.1055 Fuel Consumption: 281.0879\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.147\n",
      "Episode: 186 Exploration P: 0.0160 Total reward: -5534.741062964254 SOC: 1.0000 Cumulative_SOC_deviation: 525.3302 Fuel Consumption: 281.4387\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.111\n",
      "Episode: 187 Exploration P: 0.0158 Total reward: -5536.155565447904 SOC: 1.0000 Cumulative_SOC_deviation: 525.5625 Fuel Consumption: 280.5307\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.195\n",
      "Episode: 188 Exploration P: 0.0157 Total reward: -5535.19998811443 SOC: 1.0000 Cumulative_SOC_deviation: 525.5763 Fuel Consumption: 279.4370\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.218\n",
      "Episode: 189 Exploration P: 0.0155 Total reward: -5533.157541669111 SOC: 1.0000 Cumulative_SOC_deviation: 525.2988 Fuel Consumption: 280.1696\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.837\n",
      "Episode: 190 Exploration P: 0.0154 Total reward: -5536.134021418983 SOC: 1.0000 Cumulative_SOC_deviation: 525.5418 Fuel Consumption: 280.7164\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.948\n",
      "Episode: 191 Exploration P: 0.0152 Total reward: -5535.383262645403 SOC: 1.0000 Cumulative_SOC_deviation: 525.4502 Fuel Consumption: 280.8815\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.585\n",
      "Episode: 192 Exploration P: 0.0151 Total reward: -5535.9466933798385 SOC: 1.0000 Cumulative_SOC_deviation: 525.5695 Fuel Consumption: 280.2521\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.893\n",
      "Episode: 193 Exploration P: 0.0149 Total reward: -5535.801145091952 SOC: 1.0000 Cumulative_SOC_deviation: 525.5353 Fuel Consumption: 280.4482\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.812\n",
      "Episode: 194 Exploration P: 0.0148 Total reward: -5530.9768097941815 SOC: 1.0000 Cumulative_SOC_deviation: 525.0549 Fuel Consumption: 280.4275\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.874\n",
      "Episode: 195 Exploration P: 0.0147 Total reward: -5537.085142030455 SOC: 1.0000 Cumulative_SOC_deviation: 525.5791 Fuel Consumption: 281.2943\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.143\n",
      "Episode: 196 Exploration P: 0.0146 Total reward: -5536.105643496524 SOC: 1.0000 Cumulative_SOC_deviation: 525.5296 Fuel Consumption: 280.8093\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.043\n",
      "Episode: 197 Exploration P: 0.0144 Total reward: -5535.878725836291 SOC: 1.0000 Cumulative_SOC_deviation: 525.4863 Fuel Consumption: 281.0157\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.148\n",
      "Episode: 198 Exploration P: 0.0143 Total reward: -5532.708149245559 SOC: 1.0000 Cumulative_SOC_deviation: 525.1899 Fuel Consumption: 280.8093\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.277\n",
      "Episode: 199 Exploration P: 0.0142 Total reward: -5535.622972337792 SOC: 1.0000 Cumulative_SOC_deviation: 525.4184 Fuel Consumption: 281.4387\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.843\n",
      "Episode: 200 Exploration P: 0.0141 Total reward: -5535.328773213948 SOC: 1.0000 Cumulative_SOC_deviation: 525.4963 Fuel Consumption: 280.3656\n",
      "\n",
      "Trial 2\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 29.889\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -5120.79774328705 SOC: 1.0000 Cumulative_SOC_deviation: 497.0523 Fuel Consumption: 150.2745\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 30.059\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -5083.987564583008 SOC: 1.0000 Cumulative_SOC_deviation: 493.1567 Fuel Consumption: 152.4207\n",
      "WARNING:tensorflow:Layer dense_45 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_48 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_39 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_36 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.726\n",
      "Episode: 3 Exploration P: 0.9217 Total reward: -5093.735867465697 SOC: 1.0000 Cumulative_SOC_deviation: 494.9786 Fuel Consumption: 143.9499\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.167\n",
      "Episode: 4 Exploration P: 0.8970 Total reward: -5155.315876112356 SOC: 1.0000 Cumulative_SOC_deviation: 499.1959 Fuel Consumption: 163.3567\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.078\n",
      "Episode: 5 Exploration P: 0.8730 Total reward: -5218.197898136446 SOC: 1.0000 Cumulative_SOC_deviation: 505.5407 Fuel Consumption: 162.7904\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.218\n",
      "Episode: 6 Exploration P: 0.8496 Total reward: -5208.935012636977 SOC: 1.0000 Cumulative_SOC_deviation: 504.5649 Fuel Consumption: 163.2857\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.214\n",
      "Episode: 7 Exploration P: 0.8269 Total reward: -5206.586160648504 SOC: 1.0000 Cumulative_SOC_deviation: 503.6779 Fuel Consumption: 169.8068\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.458\n",
      "Episode: 8 Exploration P: 0.8048 Total reward: -5252.9151685454335 SOC: 1.0000 Cumulative_SOC_deviation: 507.8537 Fuel Consumption: 174.3777\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.314\n",
      "Episode: 9 Exploration P: 0.7832 Total reward: -5204.579052465739 SOC: 1.0000 Cumulative_SOC_deviation: 503.1976 Fuel Consumption: 172.6030\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.262\n",
      "Episode: 10 Exploration P: 0.7623 Total reward: -5277.4868523917075 SOC: 1.0000 Cumulative_SOC_deviation: 509.6960 Fuel Consumption: 180.5273\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.684\n",
      "Episode: 11 Exploration P: 0.7419 Total reward: -5253.479617658878 SOC: 1.0000 Cumulative_SOC_deviation: 507.0620 Fuel Consumption: 182.8592\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.110\n",
      "Episode: 12 Exploration P: 0.7221 Total reward: -5302.019667251947 SOC: 1.0000 Cumulative_SOC_deviation: 511.5642 Fuel Consumption: 186.3777\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.400\n",
      "Episode: 13 Exploration P: 0.7028 Total reward: -5270.2246045019965 SOC: 1.0000 Cumulative_SOC_deviation: 508.2134 Fuel Consumption: 188.0905\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.470\n",
      "Episode: 14 Exploration P: 0.6840 Total reward: -5348.930870750018 SOC: 1.0000 Cumulative_SOC_deviation: 515.6342 Fuel Consumption: 192.5892\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.006\n",
      "Episode: 15 Exploration P: 0.6658 Total reward: -5293.52349265549 SOC: 1.0000 Cumulative_SOC_deviation: 509.7921 Fuel Consumption: 195.6021\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.822\n",
      "Episode: 16 Exploration P: 0.6480 Total reward: -5327.542222727035 SOC: 1.0000 Cumulative_SOC_deviation: 513.6274 Fuel Consumption: 191.2685\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.917\n",
      "Episode: 17 Exploration P: 0.6307 Total reward: -5324.920045961977 SOC: 1.0000 Cumulative_SOC_deviation: 513.2940 Fuel Consumption: 191.9804\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.568\n",
      "Episode: 18 Exploration P: 0.6139 Total reward: -5324.415849599104 SOC: 1.0000 Cumulative_SOC_deviation: 512.3840 Fuel Consumption: 200.5755\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.969\n",
      "Episode: 19 Exploration P: 0.5976 Total reward: -5349.827952881288 SOC: 1.0000 Cumulative_SOC_deviation: 515.1615 Fuel Consumption: 198.2126\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.712\n",
      "Episode: 20 Exploration P: 0.5816 Total reward: -5315.307799244355 SOC: 1.0000 Cumulative_SOC_deviation: 511.6682 Fuel Consumption: 198.6253\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.080\n",
      "Episode: 21 Exploration P: 0.5662 Total reward: -5363.936157741171 SOC: 1.0000 Cumulative_SOC_deviation: 515.8934 Fuel Consumption: 205.0019\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.930\n",
      "Episode: 22 Exploration P: 0.5511 Total reward: -5381.315654433135 SOC: 1.0000 Cumulative_SOC_deviation: 516.9277 Fuel Consumption: 212.0389\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.269\n",
      "Episode: 23 Exploration P: 0.5364 Total reward: -5346.721511721247 SOC: 1.0000 Cumulative_SOC_deviation: 513.9315 Fuel Consumption: 207.4061\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.157\n",
      "Episode: 24 Exploration P: 0.5222 Total reward: -5388.7082979185725 SOC: 1.0000 Cumulative_SOC_deviation: 517.3079 Fuel Consumption: 215.6296\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.205\n",
      "Episode: 25 Exploration P: 0.5083 Total reward: -5375.713762443153 SOC: 1.0000 Cumulative_SOC_deviation: 516.5439 Fuel Consumption: 210.2745\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.023\n",
      "Episode: 26 Exploration P: 0.4948 Total reward: -5405.716554815057 SOC: 1.0000 Cumulative_SOC_deviation: 518.7435 Fuel Consumption: 218.2814\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.070\n",
      "Episode: 27 Exploration P: 0.4817 Total reward: -5409.7268838330965 SOC: 1.0000 Cumulative_SOC_deviation: 519.1745 Fuel Consumption: 217.9822\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.911\n",
      "Episode: 28 Exploration P: 0.4689 Total reward: -5378.532293379183 SOC: 1.0000 Cumulative_SOC_deviation: 515.9271 Fuel Consumption: 219.2616\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.418\n",
      "Episode: 29 Exploration P: 0.4565 Total reward: -5398.03519965466 SOC: 1.0000 Cumulative_SOC_deviation: 518.3066 Fuel Consumption: 214.9693\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.006\n",
      "Episode: 30 Exploration P: 0.4444 Total reward: -5414.864088641309 SOC: 1.0000 Cumulative_SOC_deviation: 518.8266 Fuel Consumption: 226.5978\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.317\n",
      "Episode: 31 Exploration P: 0.4326 Total reward: -5422.173274095892 SOC: 1.0000 Cumulative_SOC_deviation: 519.8062 Fuel Consumption: 224.1111\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.149\n",
      "Episode: 32 Exploration P: 0.4212 Total reward: -5411.306558032064 SOC: 1.0000 Cumulative_SOC_deviation: 518.6876 Fuel Consumption: 224.4310\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.298\n",
      "Episode: 33 Exploration P: 0.4100 Total reward: -5409.2604087556865 SOC: 1.0000 Cumulative_SOC_deviation: 518.1786 Fuel Consumption: 227.4748\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.247\n",
      "Episode: 34 Exploration P: 0.3992 Total reward: -5428.10150968641 SOC: 1.0000 Cumulative_SOC_deviation: 520.1204 Fuel Consumption: 226.8970\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.254\n",
      "Episode: 35 Exploration P: 0.3887 Total reward: -5426.634318849497 SOC: 1.0000 Cumulative_SOC_deviation: 519.6074 Fuel Consumption: 230.5600\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.324\n",
      "Episode: 36 Exploration P: 0.3784 Total reward: -5432.777681385362 SOC: 1.0000 Cumulative_SOC_deviation: 520.1475 Fuel Consumption: 231.3029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.178\n",
      "Episode: 37 Exploration P: 0.3684 Total reward: -5414.105208193595 SOC: 1.0000 Cumulative_SOC_deviation: 518.5939 Fuel Consumption: 228.1662\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.297\n",
      "Episode: 38 Exploration P: 0.3587 Total reward: -5427.860576001921 SOC: 1.0000 Cumulative_SOC_deviation: 519.5144 Fuel Consumption: 232.7165\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.462\n",
      "Episode: 39 Exploration P: 0.3493 Total reward: -5445.046148814093 SOC: 1.0000 Cumulative_SOC_deviation: 520.5313 Fuel Consumption: 239.7328\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.359\n",
      "Episode: 40 Exploration P: 0.3401 Total reward: -5432.87404998937 SOC: 1.0000 Cumulative_SOC_deviation: 519.9095 Fuel Consumption: 233.7792\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.396\n",
      "Episode: 41 Exploration P: 0.3311 Total reward: -5444.801495835519 SOC: 1.0000 Cumulative_SOC_deviation: 520.3253 Fuel Consumption: 241.5488\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.381\n",
      "Episode: 42 Exploration P: 0.3224 Total reward: -5467.1054572315215 SOC: 1.0000 Cumulative_SOC_deviation: 522.7703 Fuel Consumption: 239.4026\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.604\n",
      "Episode: 43 Exploration P: 0.3140 Total reward: -5455.66453662961 SOC: 1.0000 Cumulative_SOC_deviation: 521.4064 Fuel Consumption: 241.6004\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.339\n",
      "Episode: 44 Exploration P: 0.3057 Total reward: -5446.332121521925 SOC: 1.0000 Cumulative_SOC_deviation: 520.5114 Fuel Consumption: 241.2186\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.451\n",
      "Episode: 45 Exploration P: 0.2977 Total reward: -5463.029576467983 SOC: 1.0000 Cumulative_SOC_deviation: 522.2048 Fuel Consumption: 240.9813\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.517\n",
      "Episode: 46 Exploration P: 0.2899 Total reward: -5460.840015762845 SOC: 1.0000 Cumulative_SOC_deviation: 521.4555 Fuel Consumption: 246.2848\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.770\n",
      "Episode: 47 Exploration P: 0.2824 Total reward: -5440.8725981535845 SOC: 1.0000 Cumulative_SOC_deviation: 519.6651 Fuel Consumption: 244.2212\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.324\n",
      "Episode: 48 Exploration P: 0.2750 Total reward: -5474.589954686856 SOC: 1.0000 Cumulative_SOC_deviation: 522.6242 Fuel Consumption: 248.3484\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.585\n",
      "Episode: 49 Exploration P: 0.2678 Total reward: -5465.380364463609 SOC: 1.0000 Cumulative_SOC_deviation: 521.8703 Fuel Consumption: 246.6769\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.717\n",
      "Episode: 50 Exploration P: 0.2608 Total reward: -5476.4627950464965 SOC: 1.0000 Cumulative_SOC_deviation: 522.8259 Fuel Consumption: 248.2040\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.095\n",
      "Episode: 51 Exploration P: 0.2540 Total reward: -5474.344911876742 SOC: 1.0000 Cumulative_SOC_deviation: 522.5212 Fuel Consumption: 249.1326\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.552\n",
      "Episode: 52 Exploration P: 0.2474 Total reward: -5468.655595976487 SOC: 1.0000 Cumulative_SOC_deviation: 522.1483 Fuel Consumption: 247.1722\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.681\n",
      "Episode: 53 Exploration P: 0.2410 Total reward: -5458.650838969012 SOC: 1.0000 Cumulative_SOC_deviation: 521.3346 Fuel Consumption: 245.3046\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.971\n",
      "Episode: 54 Exploration P: 0.2347 Total reward: -5478.360799312286 SOC: 1.0000 Cumulative_SOC_deviation: 522.7299 Fuel Consumption: 251.0621\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.827\n",
      "Episode: 55 Exploration P: 0.2286 Total reward: -5476.583301581657 SOC: 1.0000 Cumulative_SOC_deviation: 522.4066 Fuel Consumption: 252.5170\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.521\n",
      "Episode: 56 Exploration P: 0.2227 Total reward: -5478.299297467948 SOC: 1.0000 Cumulative_SOC_deviation: 522.7278 Fuel Consumption: 251.0208\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.506\n",
      "Episode: 57 Exploration P: 0.2170 Total reward: -5479.1826283240825 SOC: 1.0000 Cumulative_SOC_deviation: 522.3054 Fuel Consumption: 256.1283\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.119\n",
      "Episode: 58 Exploration P: 0.2114 Total reward: -5474.467288035432 SOC: 1.0000 Cumulative_SOC_deviation: 521.8824 Fuel Consumption: 255.6434\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.908\n",
      "Episode: 59 Exploration P: 0.2059 Total reward: -5477.19900442261 SOC: 1.0000 Cumulative_SOC_deviation: 522.1246 Fuel Consumption: 255.9529\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.935\n",
      "Episode: 60 Exploration P: 0.2006 Total reward: -5490.957178234381 SOC: 1.0000 Cumulative_SOC_deviation: 523.4674 Fuel Consumption: 256.2831\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.664\n",
      "Episode: 61 Exploration P: 0.1954 Total reward: -5492.2551148897965 SOC: 1.0000 Cumulative_SOC_deviation: 523.4280 Fuel Consumption: 257.9753\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.943\n",
      "Episode: 62 Exploration P: 0.1904 Total reward: -5494.997339209093 SOC: 1.0000 Cumulative_SOC_deviation: 523.5154 Fuel Consumption: 259.8428\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.848\n",
      "Episode: 63 Exploration P: 0.1855 Total reward: -5494.455922273722 SOC: 1.0000 Cumulative_SOC_deviation: 523.5893 Fuel Consumption: 258.5634\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.644\n",
      "Episode: 64 Exploration P: 0.1808 Total reward: -5487.4203382367805 SOC: 1.0000 Cumulative_SOC_deviation: 522.9043 Fuel Consumption: 258.3777\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.760\n",
      "Episode: 65 Exploration P: 0.1761 Total reward: -5495.572550250812 SOC: 1.0000 Cumulative_SOC_deviation: 523.7546 Fuel Consumption: 258.0268\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.354\n",
      "Episode: 66 Exploration P: 0.1716 Total reward: -5499.699301598276 SOC: 1.0000 Cumulative_SOC_deviation: 523.7917 Fuel Consumption: 261.7827\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.880\n",
      "Episode: 67 Exploration P: 0.1673 Total reward: -5485.375496596539 SOC: 1.0000 Cumulative_SOC_deviation: 522.6162 Fuel Consumption: 259.2134\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.203\n",
      "Episode: 68 Exploration P: 0.1630 Total reward: -5493.084609465455 SOC: 1.0000 Cumulative_SOC_deviation: 523.4645 Fuel Consumption: 258.4396\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.779\n",
      "Episode: 69 Exploration P: 0.1589 Total reward: -5506.418491940103 SOC: 1.0000 Cumulative_SOC_deviation: 524.3903 Fuel Consumption: 262.5152\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.786\n",
      "Episode: 70 Exploration P: 0.1548 Total reward: -5500.49710039734 SOC: 1.0000 Cumulative_SOC_deviation: 524.0788 Fuel Consumption: 259.7087\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.811\n",
      "Episode: 71 Exploration P: 0.1509 Total reward: -5497.833708850038 SOC: 1.0000 Cumulative_SOC_deviation: 523.6773 Fuel Consumption: 261.0604\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.807\n",
      "Episode: 72 Exploration P: 0.1471 Total reward: -5496.3726806026625 SOC: 1.0000 Cumulative_SOC_deviation: 523.4260 Fuel Consumption: 262.1128\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.641\n",
      "Episode: 73 Exploration P: 0.1434 Total reward: -5501.628072994053 SOC: 1.0000 Cumulative_SOC_deviation: 523.5501 Fuel Consumption: 266.1266\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.048\n",
      "Episode: 74 Exploration P: 0.1398 Total reward: -5497.524459462271 SOC: 1.0000 Cumulative_SOC_deviation: 523.4793 Fuel Consumption: 262.7319\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.752\n",
      "Episode: 75 Exploration P: 0.1362 Total reward: -5509.089474272929 SOC: 1.0000 Cumulative_SOC_deviation: 524.3334 Fuel Consumption: 265.7551\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.391\n",
      "Episode: 76 Exploration P: 0.1328 Total reward: -5506.2267672974 SOC: 1.0000 Cumulative_SOC_deviation: 524.2040 Fuel Consumption: 264.1868\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.840\n",
      "Episode: 77 Exploration P: 0.1295 Total reward: -5506.487561846447 SOC: 1.0000 Cumulative_SOC_deviation: 524.2456 Fuel Consumption: 264.0320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.589\n",
      "Episode: 78 Exploration P: 0.1263 Total reward: -5509.687944189425 SOC: 1.0000 Cumulative_SOC_deviation: 524.3541 Fuel Consumption: 266.1472\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.494\n",
      "Episode: 79 Exploration P: 0.1231 Total reward: -5502.536295501358 SOC: 1.0000 Cumulative_SOC_deviation: 523.4171 Fuel Consumption: 268.3656\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.673\n",
      "Episode: 80 Exploration P: 0.1200 Total reward: -5509.761208470478 SOC: 1.0000 Cumulative_SOC_deviation: 524.3655 Fuel Consumption: 266.1060\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.560\n",
      "Episode: 81 Exploration P: 0.1171 Total reward: -5496.313305685103 SOC: 1.0000 Cumulative_SOC_deviation: 522.8897 Fuel Consumption: 267.4164\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.525\n",
      "Episode: 82 Exploration P: 0.1142 Total reward: -5514.020083652937 SOC: 1.0000 Cumulative_SOC_deviation: 524.5706 Fuel Consumption: 268.3140\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.336\n",
      "Episode: 83 Exploration P: 0.1113 Total reward: -5513.9922014492395 SOC: 1.0000 Cumulative_SOC_deviation: 524.5802 Fuel Consumption: 268.1902\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.926\n",
      "Episode: 84 Exploration P: 0.1086 Total reward: -5494.599806253552 SOC: 1.0000 Cumulative_SOC_deviation: 523.0413 Fuel Consumption: 264.1868\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.688\n",
      "Episode: 85 Exploration P: 0.1059 Total reward: -5517.80258157382 SOC: 1.0000 Cumulative_SOC_deviation: 524.8828 Fuel Consumption: 268.9744\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.305\n",
      "Episode: 86 Exploration P: 0.1033 Total reward: -5507.028638694121 SOC: 1.0000 Cumulative_SOC_deviation: 524.2047 Fuel Consumption: 264.9813\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.518\n",
      "Episode: 87 Exploration P: 0.1008 Total reward: -5516.665915129785 SOC: 1.0000 Cumulative_SOC_deviation: 524.7557 Fuel Consumption: 269.1085\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.218\n",
      "Episode: 88 Exploration P: 0.0983 Total reward: -5515.131521567985 SOC: 1.0000 Cumulative_SOC_deviation: 524.7014 Fuel Consumption: 268.1180\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.376\n",
      "Episode: 89 Exploration P: 0.0960 Total reward: -5508.8799148882745 SOC: 1.0000 Cumulative_SOC_deviation: 524.0143 Fuel Consumption: 268.7371\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.409\n",
      "Episode: 90 Exploration P: 0.0936 Total reward: -5514.197140134933 SOC: 1.0000 Cumulative_SOC_deviation: 524.3427 Fuel Consumption: 270.7697\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.458\n",
      "Episode: 91 Exploration P: 0.0914 Total reward: -5507.401273561293 SOC: 1.0000 Cumulative_SOC_deviation: 523.7343 Fuel Consumption: 270.0578\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.691\n",
      "Episode: 92 Exploration P: 0.0892 Total reward: -5515.821607953225 SOC: 1.0000 Cumulative_SOC_deviation: 524.7136 Fuel Consumption: 268.6855\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.483\n",
      "Episode: 93 Exploration P: 0.0870 Total reward: -5518.458745184847 SOC: 1.0000 Cumulative_SOC_deviation: 524.6379 Fuel Consumption: 272.0802\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.334\n",
      "Episode: 94 Exploration P: 0.0849 Total reward: -5522.1551805182435 SOC: 1.0000 Cumulative_SOC_deviation: 524.8434 Fuel Consumption: 273.7207\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.584\n",
      "Episode: 95 Exploration P: 0.0829 Total reward: -5517.52954630887 SOC: 1.0000 Cumulative_SOC_deviation: 524.7823 Fuel Consumption: 269.7070\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.548\n",
      "Episode: 96 Exploration P: 0.0809 Total reward: -5521.414159994787 SOC: 1.0000 Cumulative_SOC_deviation: 524.7838 Fuel Consumption: 273.5763\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.504\n",
      "Episode: 97 Exploration P: 0.0790 Total reward: -5523.782933996189 SOC: 1.0000 Cumulative_SOC_deviation: 525.1383 Fuel Consumption: 272.4000\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.086\n",
      "Episode: 98 Exploration P: 0.0771 Total reward: -5519.307885702543 SOC: 1.0000 Cumulative_SOC_deviation: 524.7785 Fuel Consumption: 271.5230\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.273\n",
      "Episode: 99 Exploration P: 0.0753 Total reward: -5518.678656225288 SOC: 1.0000 Cumulative_SOC_deviation: 524.5897 Fuel Consumption: 272.7818\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.515\n",
      "Episode: 100 Exploration P: 0.0735 Total reward: -5520.107225514341 SOC: 1.0000 Cumulative_SOC_deviation: 524.6768 Fuel Consumption: 273.3390\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.589\n",
      "Episode: 101 Exploration P: 0.0718 Total reward: -5521.467129623431 SOC: 1.0000 Cumulative_SOC_deviation: 524.8448 Fuel Consumption: 273.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.627\n",
      "Episode: 102 Exploration P: 0.0701 Total reward: -5524.6977850308085 SOC: 1.0000 Cumulative_SOC_deviation: 525.1204 Fuel Consumption: 273.4937\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.889\n",
      "Episode: 103 Exploration P: 0.0685 Total reward: -5524.005690889861 SOC: 1.0000 Cumulative_SOC_deviation: 524.9583 Fuel Consumption: 274.4224\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.233\n",
      "Episode: 104 Exploration P: 0.0669 Total reward: -5519.86537401854 SOC: 1.0000 Cumulative_SOC_deviation: 524.6279 Fuel Consumption: 273.5866\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.454\n",
      "Episode: 105 Exploration P: 0.0654 Total reward: -5520.295546398356 SOC: 1.0000 Cumulative_SOC_deviation: 524.7215 Fuel Consumption: 273.0810\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.382\n",
      "Episode: 106 Exploration P: 0.0639 Total reward: -5522.839511831686 SOC: 1.0000 Cumulative_SOC_deviation: 524.7416 Fuel Consumption: 275.4232\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.365\n",
      "Episode: 107 Exploration P: 0.0624 Total reward: -5525.976696650891 SOC: 1.0000 Cumulative_SOC_deviation: 525.1709 Fuel Consumption: 274.2676\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 126.237\n",
      "Episode: 108 Exploration P: 0.0610 Total reward: -5524.702355467862 SOC: 1.0000 Cumulative_SOC_deviation: 524.9847 Fuel Consumption: 274.8557\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.681\n",
      "Episode: 109 Exploration P: 0.0596 Total reward: -5531.707057088268 SOC: 1.0000 Cumulative_SOC_deviation: 525.5097 Fuel Consumption: 276.6098\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.851\n",
      "Episode: 110 Exploration P: 0.0583 Total reward: -5525.095330686311 SOC: 1.0000 Cumulative_SOC_deviation: 524.9930 Fuel Consumption: 275.1653\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.117\n",
      "Episode: 111 Exploration P: 0.0570 Total reward: -5524.797612270498 SOC: 1.0000 Cumulative_SOC_deviation: 524.8023 Fuel Consumption: 276.7749\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.871\n",
      "Episode: 112 Exploration P: 0.0557 Total reward: -5526.858458201664 SOC: 1.0000 Cumulative_SOC_deviation: 525.0754 Fuel Consumption: 276.1042\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 195.919\n",
      "Episode: 113 Exploration P: 0.0545 Total reward: -5526.165015147555 SOC: 1.0000 Cumulative_SOC_deviation: 525.0659 Fuel Consumption: 275.5058\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 192.427\n",
      "Episode: 114 Exploration P: 0.0533 Total reward: -5522.224855589472 SOC: 1.0000 Cumulative_SOC_deviation: 524.7070 Fuel Consumption: 275.1550\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.756\n",
      "Episode: 115 Exploration P: 0.0521 Total reward: -5524.063251568694 SOC: 1.0000 Cumulative_SOC_deviation: 524.9321 Fuel Consumption: 274.7422\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 199.396\n",
      "Episode: 116 Exploration P: 0.0510 Total reward: -5527.8224463953275 SOC: 1.0000 Cumulative_SOC_deviation: 525.2564 Fuel Consumption: 275.2581\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 199.259\n",
      "Episode: 117 Exploration P: 0.0498 Total reward: -5527.262196327391 SOC: 1.0000 Cumulative_SOC_deviation: 525.0002 Fuel Consumption: 277.2599\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.685\n",
      "Episode: 118 Exploration P: 0.0488 Total reward: -5528.857440833402 SOC: 1.0000 Cumulative_SOC_deviation: 525.1247 Fuel Consumption: 277.6107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 199.217\n",
      "Episode: 119 Exploration P: 0.0477 Total reward: -5525.700906921023 SOC: 1.0000 Cumulative_SOC_deviation: 524.9452 Fuel Consumption: 276.2487\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.465\n",
      "Episode: 120 Exploration P: 0.0467 Total reward: -5529.3892674381905 SOC: 1.0000 Cumulative_SOC_deviation: 525.3646 Fuel Consumption: 275.7431\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 199.061\n",
      "Episode: 121 Exploration P: 0.0457 Total reward: -5527.54772743875 SOC: 1.0000 Cumulative_SOC_deviation: 525.1629 Fuel Consumption: 275.9185\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 198.716\n",
      "Episode: 122 Exploration P: 0.0447 Total reward: -5527.540426735246 SOC: 1.0000 Cumulative_SOC_deviation: 525.1622 Fuel Consumption: 275.9185\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 175.638\n",
      "Episode: 123 Exploration P: 0.0438 Total reward: -5533.302303468804 SOC: 1.0000 Cumulative_SOC_deviation: 525.5857 Fuel Consumption: 277.4456\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.717\n",
      "Episode: 124 Exploration P: 0.0429 Total reward: -5526.268791771022 SOC: 1.0000 Cumulative_SOC_deviation: 524.9618 Fuel Consumption: 276.6511\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.710\n",
      "Episode: 125 Exploration P: 0.0420 Total reward: -5524.737311363163 SOC: 1.0000 Cumulative_SOC_deviation: 524.9025 Fuel Consumption: 275.7121\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.086\n",
      "Episode: 126 Exploration P: 0.0411 Total reward: -5532.398816251513 SOC: 1.0000 Cumulative_SOC_deviation: 525.3395 Fuel Consumption: 279.0036\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.186\n",
      "Episode: 127 Exploration P: 0.0403 Total reward: -5528.367533927591 SOC: 1.0000 Cumulative_SOC_deviation: 525.0891 Fuel Consumption: 277.4765\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.817\n",
      "Episode: 128 Exploration P: 0.0395 Total reward: -5533.594107568467 SOC: 1.0000 Cumulative_SOC_deviation: 525.5653 Fuel Consumption: 277.9409\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.082\n",
      "Episode: 129 Exploration P: 0.0387 Total reward: -5526.098651588065 SOC: 1.0000 Cumulative_SOC_deviation: 524.9499 Fuel Consumption: 276.5995\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.248\n",
      "Episode: 130 Exploration P: 0.0379 Total reward: -5529.537952608082 SOC: 1.0000 Cumulative_SOC_deviation: 525.1401 Fuel Consumption: 278.1369\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.070\n",
      "Episode: 131 Exploration P: 0.0371 Total reward: -5524.266726760788 SOC: 1.0000 Cumulative_SOC_deviation: 524.7316 Fuel Consumption: 276.9503\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.066\n",
      "Episode: 132 Exploration P: 0.0364 Total reward: -5527.130987573867 SOC: 1.0000 Cumulative_SOC_deviation: 525.0119 Fuel Consumption: 277.0122\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.975\n",
      "Episode: 133 Exploration P: 0.0357 Total reward: -5531.6512850034 SOC: 1.0000 Cumulative_SOC_deviation: 525.4495 Fuel Consumption: 277.1567\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.085\n",
      "Episode: 134 Exploration P: 0.0350 Total reward: -5529.967431402592 SOC: 1.0000 Cumulative_SOC_deviation: 525.1201 Fuel Consumption: 278.7663\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.253\n",
      "Episode: 135 Exploration P: 0.0343 Total reward: -5530.855034531131 SOC: 1.0000 Cumulative_SOC_deviation: 525.3110 Fuel Consumption: 277.7448\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.718\n",
      "Episode: 136 Exploration P: 0.0336 Total reward: -5531.519292401788 SOC: 1.0000 Cumulative_SOC_deviation: 525.4280 Fuel Consumption: 277.2392\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.676\n",
      "Episode: 137 Exploration P: 0.0330 Total reward: -5532.049183752378 SOC: 1.0000 Cumulative_SOC_deviation: 525.3324 Fuel Consumption: 278.7250\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.001\n",
      "Episode: 138 Exploration P: 0.0324 Total reward: -5526.410193298368 SOC: 1.0000 Cumulative_SOC_deviation: 524.7520 Fuel Consumption: 278.8901\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.960\n",
      "Episode: 139 Exploration P: 0.0318 Total reward: -5526.080560770111 SOC: 1.0000 Cumulative_SOC_deviation: 524.7779 Fuel Consumption: 278.3020\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.501\n",
      "Episode: 140 Exploration P: 0.0312 Total reward: -5530.863499712395 SOC: 1.0000 Cumulative_SOC_deviation: 525.2799 Fuel Consumption: 278.0647\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.153\n",
      "Episode: 141 Exploration P: 0.0306 Total reward: -5531.203860792261 SOC: 1.0000 Cumulative_SOC_deviation: 525.2613 Fuel Consumption: 278.5909\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.144\n",
      "Episode: 142 Exploration P: 0.0301 Total reward: -5529.574768584759 SOC: 1.0000 Cumulative_SOC_deviation: 525.0385 Fuel Consumption: 279.1894\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.928\n",
      "Episode: 143 Exploration P: 0.0295 Total reward: -5531.395583737537 SOC: 1.0000 Cumulative_SOC_deviation: 525.2908 Fuel Consumption: 278.4877\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.900\n",
      "Episode: 144 Exploration P: 0.0290 Total reward: -5530.18083914357 SOC: 1.0000 Cumulative_SOC_deviation: 525.1786 Fuel Consumption: 278.3949\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.366\n",
      "Episode: 145 Exploration P: 0.0285 Total reward: -5531.861786634175 SOC: 1.0000 Cumulative_SOC_deviation: 525.3126 Fuel Consumption: 278.7354\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.938\n",
      "Episode: 146 Exploration P: 0.0280 Total reward: -5535.204428769263 SOC: 1.0000 Cumulative_SOC_deviation: 525.5190 Fuel Consumption: 280.0148\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.008\n",
      "Episode: 147 Exploration P: 0.0275 Total reward: -5534.396219848558 SOC: 1.0000 Cumulative_SOC_deviation: 525.4980 Fuel Consumption: 279.4163\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.998\n",
      "Episode: 148 Exploration P: 0.0270 Total reward: -5528.036990706 SOC: 1.0000 Cumulative_SOC_deviation: 524.9333 Fuel Consumption: 278.7044\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.663\n",
      "Episode: 149 Exploration P: 0.0265 Total reward: -5529.112745344109 SOC: 1.0000 Cumulative_SOC_deviation: 524.9696 Fuel Consumption: 279.4163\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.077\n",
      "Episode: 150 Exploration P: 0.0261 Total reward: -5533.093356705843 SOC: 1.0000 Cumulative_SOC_deviation: 525.3956 Fuel Consumption: 279.1378\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.829\n",
      "Episode: 151 Exploration P: 0.0257 Total reward: -5531.030810325527 SOC: 1.0000 Cumulative_SOC_deviation: 525.3038 Fuel Consumption: 277.9924\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.785\n",
      "Episode: 152 Exploration P: 0.0252 Total reward: -5533.878967967324 SOC: 1.0000 Cumulative_SOC_deviation: 525.4050 Fuel Consumption: 279.8291\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.037\n",
      "Episode: 153 Exploration P: 0.0248 Total reward: -5531.706979620016 SOC: 1.0000 Cumulative_SOC_deviation: 525.2538 Fuel Consumption: 279.1687\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.114\n",
      "Episode: 154 Exploration P: 0.0244 Total reward: -5534.0216964234805 SOC: 1.0000 Cumulative_SOC_deviation: 525.4327 Fuel Consumption: 279.6949\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.732\n",
      "Episode: 155 Exploration P: 0.0240 Total reward: -5530.218467358018 SOC: 1.0000 Cumulative_SOC_deviation: 525.1421 Fuel Consumption: 278.7973\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.048\n",
      "Episode: 156 Exploration P: 0.0237 Total reward: -5533.65806067414 SOC: 1.0000 Cumulative_SOC_deviation: 525.3695 Fuel Consumption: 279.9632\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.063\n",
      "Episode: 157 Exploration P: 0.0233 Total reward: -5536.6754275852345 SOC: 1.0000 Cumulative_SOC_deviation: 525.5856 Fuel Consumption: 280.8196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.857\n",
      "Episode: 158 Exploration P: 0.0229 Total reward: -5528.1679024434925 SOC: 1.0000 Cumulative_SOC_deviation: 524.8339 Fuel Consumption: 279.8291\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.920\n",
      "Episode: 159 Exploration P: 0.0226 Total reward: -5534.526915150603 SOC: 1.0000 Cumulative_SOC_deviation: 525.5637 Fuel Consumption: 278.8901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.513\n",
      "Episode: 160 Exploration P: 0.0222 Total reward: -5529.276922940431 SOC: 1.0000 Cumulative_SOC_deviation: 524.9830 Fuel Consumption: 279.4473\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.740\n",
      "Episode: 161 Exploration P: 0.0219 Total reward: -5533.267272914158 SOC: 1.0000 Cumulative_SOC_deviation: 525.3975 Fuel Consumption: 279.2925\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.432\n",
      "Episode: 162 Exploration P: 0.0216 Total reward: -5529.223035675594 SOC: 1.0000 Cumulative_SOC_deviation: 525.0498 Fuel Consumption: 278.7250\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.140\n",
      "Episode: 163 Exploration P: 0.0213 Total reward: -5531.74314405228 SOC: 1.0000 Cumulative_SOC_deviation: 525.1832 Fuel Consumption: 279.9116\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.141\n",
      "Episode: 164 Exploration P: 0.0210 Total reward: -5534.889735037528 SOC: 1.0000 Cumulative_SOC_deviation: 525.5267 Fuel Consumption: 279.6227\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.064\n",
      "Episode: 165 Exploration P: 0.0207 Total reward: -5535.180358627096 SOC: 1.0000 Cumulative_SOC_deviation: 525.4206 Fuel Consumption: 280.9744\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.173\n",
      "Episode: 166 Exploration P: 0.0204 Total reward: -5532.883465748557 SOC: 1.0000 Cumulative_SOC_deviation: 525.3436 Fuel Consumption: 279.4473\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.873\n",
      "Episode: 167 Exploration P: 0.0201 Total reward: -5536.354140746654 SOC: 1.0000 Cumulative_SOC_deviation: 525.5277 Fuel Consumption: 281.0776\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.776\n",
      "Episode: 168 Exploration P: 0.0198 Total reward: -5536.162843782853 SOC: 1.0000 Cumulative_SOC_deviation: 525.5849 Fuel Consumption: 280.3140\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.873\n",
      "Episode: 169 Exploration P: 0.0196 Total reward: -5532.417050501759 SOC: 1.0000 Cumulative_SOC_deviation: 525.3506 Fuel Consumption: 278.9108\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.111\n",
      "Episode: 170 Exploration P: 0.0193 Total reward: -5532.166428133806 SOC: 1.0000 Cumulative_SOC_deviation: 525.1770 Fuel Consumption: 280.3966\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.215\n",
      "Episode: 171 Exploration P: 0.0190 Total reward: -5530.970257682661 SOC: 1.0000 Cumulative_SOC_deviation: 525.0759 Fuel Consumption: 280.2108\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.783\n",
      "Episode: 172 Exploration P: 0.0188 Total reward: -5535.200839500257 SOC: 1.0000 Cumulative_SOC_deviation: 525.4773 Fuel Consumption: 280.4275\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.016\n",
      "Episode: 173 Exploration P: 0.0186 Total reward: -5530.8454659922645 SOC: 1.0000 Cumulative_SOC_deviation: 525.0304 Fuel Consumption: 280.5410\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.046\n",
      "Episode: 174 Exploration P: 0.0183 Total reward: -5535.169110219173 SOC: 1.0000 Cumulative_SOC_deviation: 525.3988 Fuel Consumption: 281.1808\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.524\n",
      "Episode: 175 Exploration P: 0.0181 Total reward: -5532.371606643478 SOC: 1.0000 Cumulative_SOC_deviation: 525.2831 Fuel Consumption: 279.5402\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.242\n",
      "Episode: 176 Exploration P: 0.0179 Total reward: -5528.207930127836 SOC: 1.0000 Cumulative_SOC_deviation: 524.7502 Fuel Consumption: 280.7061\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.834\n",
      "Episode: 177 Exploration P: 0.0177 Total reward: -5534.113759103466 SOC: 1.0000 Cumulative_SOC_deviation: 525.4594 Fuel Consumption: 279.5195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.915\n",
      "Episode: 178 Exploration P: 0.0175 Total reward: -5536.927578078169 SOC: 1.0000 Cumulative_SOC_deviation: 525.5871 Fuel Consumption: 281.0569\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.017\n",
      "Episode: 179 Exploration P: 0.0173 Total reward: -5535.713199195247 SOC: 1.0000 Cumulative_SOC_deviation: 525.5636 Fuel Consumption: 280.0767\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.255\n",
      "Episode: 180 Exploration P: 0.0171 Total reward: -5535.692763226338 SOC: 1.0000 Cumulative_SOC_deviation: 525.5554 Fuel Consumption: 280.1386\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.367\n",
      "Episode: 181 Exploration P: 0.0169 Total reward: -5535.855056719959 SOC: 1.0000 Cumulative_SOC_deviation: 525.5448 Fuel Consumption: 280.4069\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.943\n",
      "Episode: 182 Exploration P: 0.0167 Total reward: -5535.803788763452 SOC: 1.0000 Cumulative_SOC_deviation: 525.5139 Fuel Consumption: 280.6648\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.171\n",
      "Episode: 183 Exploration P: 0.0165 Total reward: -5534.145582422702 SOC: 1.0000 Cumulative_SOC_deviation: 525.3739 Fuel Consumption: 280.4069\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.864\n",
      "Episode: 184 Exploration P: 0.0163 Total reward: -5533.963069691544 SOC: 1.0000 Cumulative_SOC_deviation: 525.3835 Fuel Consumption: 280.1283\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.856\n",
      "Episode: 185 Exploration P: 0.0162 Total reward: -5536.5126266789175 SOC: 1.0000 Cumulative_SOC_deviation: 525.5837 Fuel Consumption: 280.6752\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.439\n",
      "Episode: 186 Exploration P: 0.0160 Total reward: -5529.612668574091 SOC: 1.0000 Cumulative_SOC_deviation: 524.9350 Fuel Consumption: 280.2624\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.265\n",
      "Episode: 187 Exploration P: 0.0158 Total reward: -5536.347423657576 SOC: 1.0000 Cumulative_SOC_deviation: 525.5414 Fuel Consumption: 280.9331\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.413\n",
      "Episode: 188 Exploration P: 0.0157 Total reward: -5535.566079888614 SOC: 1.0000 Cumulative_SOC_deviation: 525.5778 Fuel Consumption: 279.7878\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.189\n",
      "Episode: 189 Exploration P: 0.0155 Total reward: -5536.779133576824 SOC: 1.0000 Cumulative_SOC_deviation: 525.5867 Fuel Consumption: 280.9125\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.464\n",
      "Episode: 190 Exploration P: 0.0154 Total reward: -5531.445516921188 SOC: 1.0000 Cumulative_SOC_deviation: 525.1338 Fuel Consumption: 280.1077\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.266\n",
      "Episode: 191 Exploration P: 0.0152 Total reward: -5536.602258195248 SOC: 1.0000 Cumulative_SOC_deviation: 525.5845 Fuel Consumption: 280.7577\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.268\n",
      "Episode: 192 Exploration P: 0.0151 Total reward: -5535.4183060509 SOC: 1.0000 Cumulative_SOC_deviation: 525.5465 Fuel Consumption: 279.9529\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.328\n",
      "Episode: 193 Exploration P: 0.0149 Total reward: -5534.647567665454 SOC: 1.0000 Cumulative_SOC_deviation: 525.4395 Fuel Consumption: 280.2521\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.245\n",
      "Episode: 194 Exploration P: 0.0148 Total reward: -5536.373509980172 SOC: 1.0000 Cumulative_SOC_deviation: 525.5781 Fuel Consumption: 280.5926\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.398\n",
      "Episode: 195 Exploration P: 0.0147 Total reward: -5533.240369181155 SOC: 1.0000 Cumulative_SOC_deviation: 525.2596 Fuel Consumption: 280.6442\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.213\n",
      "Episode: 196 Exploration P: 0.0146 Total reward: -5531.899965835196 SOC: 1.0000 Cumulative_SOC_deviation: 525.1565 Fuel Consumption: 280.3347\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.434\n",
      "Episode: 197 Exploration P: 0.0144 Total reward: -5534.949887036713 SOC: 1.0000 Cumulative_SOC_deviation: 525.5038 Fuel Consumption: 279.9116\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.217\n",
      "Episode: 198 Exploration P: 0.0143 Total reward: -5537.416062900436 SOC: 1.0000 Cumulative_SOC_deviation: 525.5864 Fuel Consumption: 281.5522\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.454\n",
      "Episode: 199 Exploration P: 0.0142 Total reward: -5529.733214503706 SOC: 1.0000 Cumulative_SOC_deviation: 524.9863 Fuel Consumption: 279.8703\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.279\n",
      "Episode: 200 Exploration P: 0.0141 Total reward: -5534.881576324452 SOC: 1.0000 Cumulative_SOC_deviation: 525.4196 Fuel Consumption: 280.6855\n"
     ]
    }
   ],
   "source": [
    "print(env.version)\n",
    "\n",
    "num_trials = 3\n",
    "reward_factor = 10\n",
    "results_dict = {} \n",
    "for trial in range(num_trials): \n",
    "    print()\n",
    "    print(\"Trial {}\".format(trial))\n",
    "    \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer, env = initialization(\n",
    "        reward_factor\n",
    "    )\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    for ep in range(total_episodes): \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * steps)\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_SOCs.append(env.SOC)\n",
    "        episode_FCs.append(env.fuel_consumption) \n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        print(\n",
    "              'Episode: {}'.format(ep + 1),\n",
    "              \"Exploration P: {:.4f}\".format(eps),\n",
    "              'Total reward: {}'.format(episodic_reward), \n",
    "              \"SOC: {:.4f}\".format(env.SOC), \n",
    "              \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "              \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "        )\n",
    "    \n",
    "#     root = \"DDPG1_trial{}\".format(trial+1)\n",
    "#     save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "    \n",
    "    results_dict[trial + 1] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDPG1_mass1200.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
